{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "03-models_pretrained_and_more (1).ipynb",
      "provenance": [],
      "collapsed_sections": [
        "tjJOOaifAfG9",
        "E7PXgX4v_zaB"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaorisugi/diveintocode-ml/blob/master/sprint20_03_models_pretrained_and_more_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvXXlmKbAmWj",
        "colab_type": "code",
        "outputId": "18700d87-f485-4144-dd8d-9cff3d9f712f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMIuPNXiZe2n",
        "colab_type": "text"
      },
      "source": [
        "# sprint20 セグメンテーション２"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KRkbZ7YZsCC",
        "colab_type": "text"
      },
      "source": [
        "# 【問題1】コードレビュー\n",
        "転移学習を使用してセグメンテーションの精度を改善したコードを提示するので、レビューを行ってください。\n",
        "\n",
        "《視点例》\n",
        "\n",
        "前回使用した実装とはどのように違うのか\n",
        "転移学習をどのように行っているか"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7lFZDHoDTab",
        "colab_type": "text"
      },
      "source": [
        "＊　提示されたコードは問３の下で実行"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiwE2mU4oG-G",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "前回のUnetの実装と違う点\n",
        "*   BatchNormalizationで過学習を防いでいる\n",
        "*   ReduceLROnPlateauメソッドを使い、学習率の最適化を行っている\n",
        "*   エンコーダーのResNet50は50層あり、前回のシンプルなUnetよりもたくさんの畳み込みを行うことで精度を高めている。\n",
        "*   デコーダーブロックタイプを変更することで、BCE、Dice、BCEとDice、Lovashの損失を組み合わせて、さまざまな損失を試すことができるようになっている\n",
        " \n",
        "転移学習をどのように行っているか\n",
        "*   重みは、imagenetで学習した物を使っている。\n",
        "*   全結合層のない学習済みの重みを持ったモデルでエンコードを行い、既存のUnetに接続してデコードする\n",
        "\n",
        "前回のUnetの構造との整合性\n",
        "*   入力画像を畳みこみ、プーリングして得たボトルネック特徴量を備えた最初のレイヤーが、Uの下から数えて5番目のブロックとして機能し、４ブロック構成のResNetへと特徴量を渡すことで、標準UNetの５ブロック構造との整合性を実現している。\n",
        "*   ResNet50の各ブロックはプーリングレイヤーで終了する。プーリングの直前のレイヤーから特徴量を抽出し、同じ階層のデコーダーブロックに連結することで、スキップ接続を行う。\n",
        "*   その後、デコーダ出力はエンコーダ出力部と等しい寸法にアップサンプリングされる。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XrF3UMVEX7U",
        "colab_type": "text"
      },
      "source": [
        "# 【問題２】コードの書き換え\n",
        "エンコーダーにResNetが使用されていたコードをVGGに変更してください。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Jnc3sN8KKeA",
        "colab_type": "text"
      },
      "source": [
        "＊問３の下でVGGに変更したコードを実行"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsws2CWkZ2n6",
        "colab_type": "text"
      },
      "source": [
        "# 【問題3】学習・推定\n",
        "ResNetとVGG双方のコードで学習・推定を行い、結果を比較してください。\n",
        "\n",
        "＊双方のコードの実行は問３の下"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQ5lffTOD3TC",
        "colab_type": "text"
      },
      "source": [
        "### ResNetの学習、推定結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p31pdxcYD63k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Best IoU: 0.5515 at threshold: 0.660\n",
        "Out[69]:\n",
        "threshold\tiou\n",
        "count\t35.000000\t35.000000\n",
        "mean\t0.540000\t0.537239\n",
        "std\t0.204939\t0.015830\n",
        "min\t0.200000\t0.492910\n",
        "25%\t0.370000\t0.533769\n",
        "50%\t0.540000\t0.544154\n",
        "75%\t0.710000\t0.549192\n",
        "max\t0.880000\t0.551493"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEcTYaE9Dw7Z",
        "colab_type": "text"
      },
      "source": [
        "### VGGの学習、推定結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zj4k4whREeyv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Best IoU: 0.4286 at threshold: 0.880\n",
        "threshold\tiou\n",
        "count\t35.000000\t35.000000\n",
        "mean\t0.540000\t0.361130\n",
        "std\t0.204939\t0.050776\n",
        "min\t0.200000\t0.244403\n",
        "25%\t0.370000\t0.330100\n",
        "50%\t0.540000\t0.371269\n",
        "75%\t0.710000\t0.399316\n",
        "max\t0.880000\t0.428607"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rx6CSb-Udak",
        "colab_type": "text"
      },
      "source": [
        "### 比較\n",
        "しきい値を変えて推定を行ったところ、ベストIoUにおいては、VGG１６よりResNET５０の方が、わずかに精度が高かった"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Guh-Pqr3Dfsx",
        "colab_type": "text"
      },
      "source": [
        "# 提示されたコードの実行（ResNet50のUNet）\n",
        "kaggleの塩コンペデータで学習、推定を行う"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjJOOaifAfG9",
        "colab_type": "text"
      },
      "source": [
        "### コードの実行準備"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DvtecjtB6kk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv \"/content/drive/My Drive/Colab Notebooks/03-models_pretrained_and_more (1).ipynb\" \"/content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovBDdNHfCWa6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv \"/content/drive/My Drive/Colab Notebooks/clean-workflow-in-keras (1).ipynb\" \"/content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHxbS_JJCqAQ",
        "colab_type": "code",
        "outputId": "2acdab8c-e09f-486d-8f31-62de039a58fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd \"/content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gc_zMC6ppW42",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir .kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NLc1BpPze-Q",
        "colab_type": "code",
        "outputId": "943abde1-b515-44a0-e1e3-db6db1851380",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!ls -a"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'03-models_pretrained_and_more (1).ipynb'   .kaggle\n",
            "'clean-workflow-in-keras (1).ipynb'\t    kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zI-Y6U5Czqsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv \"/content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20/kaggle.json\" \"/content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20/.kaggle\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IDhP0eCq6SS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv \"/content/kaggle.json\" \"/content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0Y_I8q2pzOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!chmod 600 \"/content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20/.kaggle/kaggle.json\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaFsCnWHqPsH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "\n",
        "token = {'username':'kaorisugi','key':'def696cfe4d461409a7f8be05a5941fa'}\n",
        "with open('/content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tl7lg5tG0kKz",
        "colab_type": "code",
        "outputId": "a69d56ae-2e3c-4d3d-fe96-d78b457a44a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /root"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uza4fgWFqPp6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp .kaggle/kaggle.json /root/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4bo_wOHqPnA",
        "colab_type": "code",
        "outputId": "4db3bee4-c56c-4e7c-9aae-70a5832d4dc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "!kaggle competitions download -c tgs-salt-identification-challenge"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading depths.csv to /content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20\n",
            "  0% 0.00/322k [00:00<?, ?B/s]\n",
            "100% 322k/322k [00:00<00:00, 22.0MB/s]\n",
            "Downloading sample_submission.csv to /content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20\n",
            "  0% 0.00/264k [00:00<?, ?B/s]\n",
            "100% 264k/264k [00:00<00:00, 36.3MB/s]\n",
            "Downloading train.csv to /content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20\n",
            "  0% 0.00/922k [00:00<?, ?B/s]\n",
            "100% 922k/922k [00:00<00:00, 60.4MB/s]\n",
            "Downloading test.zip to /content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20\n",
            " 95% 155M/163M [00:02<00:00, 66.0MB/s]\n",
            "100% 163M/163M [00:02<00:00, 62.9MB/s]\n",
            "Downloading train.zip to /content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20\n",
            " 95% 36.0M/37.9M [00:00<00:00, 49.5MB/s]\n",
            "100% 37.9M/37.9M [00:00<00:00, 94.7MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjV3nUcN1D7V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip \"/content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20/train.zip\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXEE5qyG1nd3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip \"/content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20/test.zip\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sd-KfI472kOd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv \"/content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20/train.csv\" \"/content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20/input\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-38I6CtP2vYM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv \"/content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20/depths.csv\" \"/content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20/input\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OaVwL212-UQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv \"/content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20/sample_submission.csv\" \"/content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20/input\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_B0KYbve_zZq",
        "colab_type": "text"
      },
      "source": [
        "### Model architecture tuning & score optimization\n",
        "\n",
        "\n",
        "Some ideas and code taken from ealier [kernel](https://www.kaggle.com/wrosinski/clean-workflow-in-keras) and last prepared notebook.\n",
        "\n",
        "Having dealt with data processing & engineering of channel features, next step of modeling is preparation and tuning of model architecture. Earlier notebooks provided a way to create images with three channels, which will facilitate usage of pretrained models.\n",
        "\n",
        "For segmentation tasks, a pretrained model can be used as encoder part of the final architecture. \n",
        "In order to use pretrained models, we will have to extract features from a few intermediate layers, which will then serve as a basis for layers coming afterwards and for skip connections between encoder and decoder part.\n",
        "\n",
        "ResNet50 is a good starting point, because it consists of 4 blocks, where each one of them can serve as feature extractor with first layer serving as the 5th extractor to achieve consistency with standard UNet architecture."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaFUUL6o_zZr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gc\n",
        "import glob\n",
        "import os\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from tqdm import tqdm\n",
        "\n",
        "from keras import optimizers\n",
        "from keras.callbacks import *\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.layers import *\n",
        "from keras.models import Model, load_model, save_model\n",
        "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
        "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHj6cbSD_zZu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.rcParams['figure.figsize'] = (12, 9)\n",
        "# plt.style.use('ggplot')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfejRvXZ_zZw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_coverage(df, masks):\n",
        "    \n",
        "    df = df.copy()\n",
        "    \n",
        "    def cov_to_class(val):\n",
        "        for i in range(0, 11):\n",
        "            if val * 10 <= i:\n",
        "                return i\n",
        "\n",
        "    # Output percentage of area covered by class（クラスがカバーする面積の出力割合）\n",
        "    df['coverage'] = np.mean(masks, axis=(1, 2))\n",
        "    # Coverage must be split into bins, otherwise stratified split will not be possible,\n",
        "    # because each coverage will occur only once.\n",
        "    #カバレッジはビンに分割する必要があります。そうしないと、階層化された分割が不可能になります。\n",
        "    #各カバレッジが1回だけ発生するため。\n",
        "    df['coverage_class'] = df.coverage.map(\n",
        "        cov_to_class)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def create_depth_abs_channels(image_tensor):\n",
        "    image_tensor = image_tensor.astype(np.float32) #画像をテンソル形式に変換\n",
        "    h, w, c = image_tensor.shape\n",
        "    for row, const in enumerate(np.linspace(0, 1, h)):\n",
        "        image_tensor[row, :, 1] = const\n",
        "    image_tensor[:, :, 2] = (\n",
        "        image_tensor[:, :, 0] * image_tensor[:, :, 1])\n",
        "\n",
        "    x_dx = np.diff(image_tensor[:, :, 0], axis=0)\n",
        "    x_dy = np.diff(image_tensor[:, :, 0], axis=1)\n",
        "    x_dx = cv2.copyMakeBorder(x_dx, 1, 0, 0, 0, cv2.BORDER_CONSTANT, 0)\n",
        "    x_dy = cv2.copyMakeBorder(x_dy, 0, 0, 1, 0, cv2.BORDER_CONSTANT, 0)\n",
        "    image_tensor[:, :, 1] = np.abs(x_dx + x_dy)\n",
        "\n",
        "    return image_tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4djhczC_zZx",
        "colab_type": "text"
      },
      "source": [
        "### Data loading & depth merge:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-icqnJYr_zZy",
        "colab_type": "code",
        "outputId": "99f27906-042f-4a57-d4e7-5f576d6fbd1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "train = pd.read_csv('/content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20/input/train.csv')\n",
        "test = pd.read_csv('/content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20/input/sample_submission.csv')\n",
        "depth = pd.read_csv('/content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20/input/depths.csv')\n",
        "\n",
        "train_src = '../input/train/'\n",
        "\n",
        "print('train:\\n{}'.format(train.head()))\n",
        "print('\\ntest:\\n{}'.format(test.head()))\n",
        "\n",
        "\n",
        "train = train.merge(depth, how='left', on='id')\n",
        "test = test.merge(depth, how='left', on='id')\n",
        "\n",
        "print('\\n{}'.format(train.head()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train:\n",
            "           id                                           rle_mask\n",
            "0  575d24d81d                                                NaN\n",
            "1  a266a2a9df                                          5051 5151\n",
            "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...\n",
            "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...\n",
            "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...\n",
            "\n",
            "test:\n",
            "           id rle_mask\n",
            "0  155410d6fa      1 1\n",
            "1  78b32781d1      1 1\n",
            "2  63db2a476a      1 1\n",
            "3  17bfcdb967      1 1\n",
            "4  7ea0fd3c88      1 1\n",
            "\n",
            "           id                                           rle_mask    z\n",
            "0  575d24d81d                                                NaN  843\n",
            "1  a266a2a9df                                          5051 5151  794\n",
            "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...  468\n",
            "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...  727\n",
            "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...  797\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChR8xybw_zZ0",
        "colab_type": "text"
      },
      "source": [
        "### Load images and masks, examine random sample:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOAYUaiN_zZ0",
        "colab_type": "code",
        "outputId": "e76db5ab-97ed-434f-ff45-27208f3cd16a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#画像が保存してあるパスを指定して直接np.arrayを作る\n",
        "X_train = np.asarray(\n",
        "    [cv2.imread('/content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20/images/{}.png'.format(x), 0) for x in train.id.tolist()], \n",
        "    dtype=np.uint8) / 255.\n",
        "y_train = np.asarray(\n",
        "    [cv2.imread('/content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20/masks/{}.png'.format(x), 0) for x in train.id.tolist()],\n",
        "    dtype=np.uint8) / 255.\n",
        "\n",
        "print(X_train.shape, y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4000, 101, 101) (4000, 101, 101)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "jfXs876a_zZ2",
        "colab_type": "code",
        "outputId": "18f4565a-3ae3-4120-fad6-348b3d338b43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        }
      },
      "source": [
        "random_index = np.random.randint(0, X_train.shape[0])\n",
        "\n",
        "fig, ax = plt.subplots(1, 2)\n",
        "\n",
        "ax[0].imshow(X_train[random_index], cmap='gray')\n",
        "ax[1].imshow(y_train[random_index], cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fc0cbb88588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs0AAAFTCAYAAADCyzEvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRvj/AbHE/dNPNQ62AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Xl9Ozlq_zZ4",
        "colab_type": "text"
      },
      "source": [
        "### Compute salt coverage (this will serve as a basis for stratified split):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AslhGujz_zZ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = compute_coverage(train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHSQQxhb_zZ7",
        "colab_type": "text"
      },
      "source": [
        "### Prepare data for training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-zr_oUK_zZ7",
        "colab_type": "code",
        "outputId": "3f8e2df9-9136-450c-a7f8-68cc84ac3f1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "\n",
        "kfold = StratifiedKFold(n_splits=5, random_state=1337)\n",
        "\n",
        "# Add channel features\n",
        "X_train_ch = np.repeat(np.expand_dims(X_train, axis=-1), 3, -1)#一番最後の軸を指定して\n",
        "X_train_ch = np.asarray(list(map(lambda x: create_depth_abs_channels(x), X_train_ch)))\n",
        "\n",
        "# Resize to 224x224, default ResNet50 image size\n",
        "X_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), X_train_ch)))\n",
        "y_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), y_train)))\n",
        "\n",
        "\n",
        "for train_index, valid_index in kfold.split(train.id.values, train.coverage_class.values):\n",
        "    \n",
        "    X_tr, X_val = X_resized[train_index], X_resized[valid_index]\n",
        "    y_tr, y_val = y_resized[train_index], y_resized[valid_index]\n",
        "    \n",
        "    break\n",
        "    \n",
        "\n",
        "y_tr = np.expand_dims(y_tr, axis=-1)\n",
        "y_val = np.expand_dims(y_val, axis=-1)\n",
        "\n",
        "print(X_tr.shape, y_tr.shape)\n",
        "print(X_val.shape, y_val.shape)\n",
        "\n",
        "\n",
        "del X_train_ch, y_resized\n",
        "del X_resized\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3196, 224, 224, 3) (3196, 224, 224, 1)\n",
            "(804, 224, 224, 3) (804, 224, 224, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "94"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Admj7pGi_zZ9",
        "colab_type": "text"
      },
      "source": [
        "### Loss functions & metric:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUtP23gJ_zZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.losses import binary_crossentropy\n",
        "\n",
        "\n",
        "# Dice & combined\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred = K.cast(y_pred, 'float32')\n",
        "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
        "    intersection = y_true_f * y_pred_f\n",
        "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
        "    return score\n",
        "\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = y_true_f * y_pred_f\n",
        "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "    return 1. - score\n",
        "\n",
        "\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
        "\n",
        "\n",
        "def bce_logdice_loss(y_true, y_pred):\n",
        "    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n",
        "\n",
        "\n",
        "\n",
        "# Lovash loss: https://github.com/bermanmaxim/LovaszSoftmax\n",
        "def lovasz_grad(gt_sorted):\n",
        "    \"\"\"\n",
        "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
        "    See Alg. 1 in paper\n",
        "    \"\"\"\n",
        "    gts = tf.reduce_sum(gt_sorted)\n",
        "    intersection = gts - tf.cumsum(gt_sorted)\n",
        "    union = gts + tf.cumsum(1. - gt_sorted)\n",
        "    jaccard = 1. - intersection / union\n",
        "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
        "    return jaccard\n",
        "\n",
        "\n",
        "# --------------------------- BINARY LOSSES ---------------------------\n",
        "\n",
        "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
        "    \"\"\"\n",
        "    Binary Lovasz hinge loss\n",
        "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
        "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
        "      per_image: compute the loss per image instead of per batch\n",
        "      ignore: void class id\n",
        "    \"\"\"\n",
        "    if per_image:\n",
        "        def treat_image(log_lab):\n",
        "            log, lab = log_lab\n",
        "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
        "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
        "            return lovasz_hinge_flat(log, lab)\n",
        "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
        "        loss = tf.reduce_mean(losses)\n",
        "    else:\n",
        "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
        "    return loss\n",
        "\n",
        "\n",
        "def lovasz_hinge_flat(logits, labels):\n",
        "    \"\"\"\n",
        "    Binary Lovasz hinge loss\n",
        "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
        "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
        "      ignore: label to ignore\n",
        "    \"\"\"\n",
        "\n",
        "    def compute_loss():\n",
        "        labelsf = tf.cast(labels, logits.dtype)\n",
        "        signs = 2. * labelsf - 1.\n",
        "        errors = 1. - logits * tf.stop_gradient(signs)\n",
        "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
        "        gt_sorted = tf.gather(labelsf, perm)\n",
        "        grad = lovasz_grad(gt_sorted)\n",
        "        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
        "        return loss\n",
        "\n",
        "    # deal with the void prediction case (only void pixels)\n",
        "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
        "                   lambda: tf.reduce_sum(logits) * 0.,\n",
        "                   compute_loss,\n",
        "                   strict=True,\n",
        "                   name=\"loss\"\n",
        "                   )\n",
        "    return loss\n",
        "\n",
        "\n",
        "def flatten_binary_scores(scores, labels, ignore=None):\n",
        "    \"\"\"\n",
        "    Flattens predictions in the batch (binary case)\n",
        "    Remove labels equal to 'ignore'\n",
        "    \"\"\"\n",
        "    scores = tf.reshape(scores, (-1,))\n",
        "    labels = tf.reshape(labels, (-1,))\n",
        "    if ignore is None:\n",
        "        return scores, labels\n",
        "    valid = tf.not_equal(labels, ignore)\n",
        "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
        "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
        "    return vscores, vlabels\n",
        "\n",
        "\n",
        "def lovasz_loss(y_true, y_pred):\n",
        "    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n",
        "    #logits = K.log(y_pred / (1. - y_pred))\n",
        "    logits = y_pred #Jiaxin\n",
        "    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n",
        "    return loss\n",
        "\n",
        "\n",
        "# IoU metric for observation during training（トレーニング中の観察のためのIoUメトリック）\n",
        "# https://www.kaggle.com/cpmpml/fast-iou-metric-in-numpy-and-tensorflow\n",
        "def get_iou_vector(A, B):\n",
        "    # Numpy version    \n",
        "    batch_size = A.shape[0]\n",
        "    metric = 0.0\n",
        "    for batch in range(batch_size):\n",
        "        t, p = A[batch], B[batch]\n",
        "        true = np.sum(t)\n",
        "        pred = np.sum(p)\n",
        "        \n",
        "        # deal with empty mask first\n",
        "        if true == 0:\n",
        "            metric += (pred == 0)\n",
        "            continue\n",
        "        \n",
        "        # non empty mask case.  Union is never empty \n",
        "        # hence it is safe to divide by its number of pixels\n",
        "        intersection = np.sum(t * p)\n",
        "        union = true + pred - intersection\n",
        "        iou = intersection / union\n",
        "        \n",
        "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
        "        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
        "        \n",
        "        metric += iou\n",
        "        \n",
        "    # teake the average over all images in batch\n",
        "    metric /= batch_size\n",
        "    return metric\n",
        "\n",
        "\n",
        "def my_iou_metric(label, pred):\n",
        "    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n",
        "\n",
        "\n",
        "# For Lovash loss\n",
        "def my_iou_metric_2(label, pred):\n",
        "    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7PXgX4v_zaB",
        "colab_type": "text"
      },
      "source": [
        "### Encoder features - ResNet50:\n",
        "\n",
        "In ResNet50, each block finishes with a pooling layer, so we can extract features from intermediate layers just before the pooling. This way, when first layer is added as additional extractor, we will have features extracted from 5 layers.\n",
        "Default input size will be assumed, which is (224, 224, 3).\n",
        "Layers will be as follows:\n",
        "\n",
        "- 'activation_1', shape: (None, 112, 112, 64)\n",
        "- 'activation_10', shape: (None, 56, 56, 256)\n",
        "- 'activation_22', shape: (None, 28, 28, 512)\n",
        "- 'activation_40', shape: (None, 14, 14, 1024)\n",
        "- 'activation_49', shape: (None, 7, 7, 2048)\n",
        "\n",
        "One thing to keep in mind is that every time a model will be created in the same TF session in the notebook, layer names will change, so above layer names correspond to first creation of the model. In order to reset session, call `K.clear_session()`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwFzEy_b_zaD",
        "colab_type": "text"
      },
      "source": [
        "### Decoder blocks:\n",
        "\n",
        "Features from ResNet50 will serve as a basis for encoder part of the segmentation model, now a decoder part is needed.\n",
        "For this part, we will have to create our own blocks. Let's create a very basic block and a second one, which structure will have a more complicated structure.\n",
        "デコーダ ブロック:\n",
        "ResNet50 の機能は、セグメンテーション モデルのエンコーダ部分の基礎として機能し、デコーダパーツが必要になりました。この部分では、独自のブロックを作成する必要があります。非常に基本的なブロックと2番目のブロックを作成してみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIJSRGOn_zaE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Basic decoder block with Conv, BN and PReLU activation.\n",
        "def decoder_block_simple(\n",
        "        layer_name, block_name,\n",
        "        num_filters=32,\n",
        "        conv_dim=(3, 3)):\n",
        "\n",
        "    x_dec = Conv2D(\n",
        "        num_filters, conv_dim,\n",
        "        padding='same',\n",
        "        name='{}_conv'.format(block_name))(layer_name)\n",
        "    x_dec = BatchNormalization(\n",
        "        name='{}_bn'.format(block_name))(x_dec)\n",
        "    x_dec = PReLU(\n",
        "        name='{}_activation'.format(block_name))(x_dec)\n",
        "\n",
        "    return x_dec\n",
        "\n",
        "# Decoder block with bottleneck architecture, where middle conv layer\n",
        "# is half the size of first and last, in order to compress representation.\n",
        "# This type of architecture is supposed to retain most useful information.\n",
        "# ボトルネックアーキテクチャを備えたデコーダブロック。中間コンバードレイヤー\n",
        "# は、表現を圧縮するために、最初と最後の半分のサイズです。\n",
        "# このタイプのアーキテクチャは、最も有用な情報を保持することになっています。\n",
        "def decoder_block_bottleneck(\n",
        "        layer_name, block_name,\n",
        "        num_filters=32,\n",
        "        conv_dim=(3, 3),\n",
        "        dropout_frac=0.2):\n",
        "\n",
        "    x_dec = Conv2D(\n",
        "        num_filters, conv_dim,\n",
        "        padding='same',\n",
        "        name='{}_conv1'.format(block_name))(layer_name)\n",
        "    x_dec = BatchNormalization(\n",
        "        name='{}_bn1'.format(block_name))(x_dec)\n",
        "    x_dec = PReLU(\n",
        "        name='{}_activation1'.format(block_name))(x_dec)\n",
        "    x_dec = Dropout(dropout_frac)(x_dec)\n",
        "\n",
        "    x_dec2 = Conv2D(\n",
        "        num_filters // 2, conv_dim,\n",
        "        padding='same',\n",
        "        name='{}_conv2'.format(block_name))(x_dec)\n",
        "    x_dec2 = BatchNormalization(\n",
        "        name='{}_bn2'.format(block_name))(x_dec2)\n",
        "    x_dec2 = PReLU(\n",
        "        name='{}_activation2'.format(block_name))(x_dec2)\n",
        "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
        "\n",
        "    x_dec2 = Conv2D(\n",
        "        num_filters, conv_dim,\n",
        "        padding='same',\n",
        "        name='{}_conv3'.format(block_name))(x_dec2)\n",
        "    x_dec2 = BatchNormalization(\n",
        "        name='{}_bn3'.format(block_name))(x_dec2)\n",
        "    x_dec2 = PReLU(\n",
        "        name='{}_activation3'.format(block_name))(x_dec2)\n",
        "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
        "\n",
        "    x_dec2 = Add()([x_dec, x_dec2])\n",
        "\n",
        "    return x_dec2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tC-VuFr_zaG",
        "colab_type": "text"
      },
      "source": [
        "### Model definition:\n",
        "\n",
        "Combine encoder and decoder blocks to create final segmentation model.\n",
        "モデル定義： エンコーダーブロックとデコーダーブロックを組み合わせて、最終的なセグメンテーションモデルを作成します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olXwo4kU_zaG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model is parametrized in a way to enable easy change of decoder_block type,\n",
        "# as this is an argument that can be given a function, like decoder_block_simple.\n",
        "# ＃モデルは、decoder_blockタイプを簡単に変更できるようにパラメーター化されます。\n",
        "# ＃これは、decoder_block_simpleなどの関数を指定できる引数であるためです。\n",
        "def unet_resnet(input_size, decoder_block,\n",
        "                weights='imagenet',\n",
        "                loss_func='binary_crossentropy',\n",
        "                metrics_list=[my_iou_metric],\n",
        "                use_lovash=False):\n",
        "\n",
        "    # Base model - encoder\n",
        "    base_model = ResNet50(\n",
        "        input_shape=input_size, \n",
        "        include_top=False,\n",
        "        weights=weights)\n",
        "    \n",
        "    print(base_model.summary())\n",
        "\n",
        "\n",
        "    # Layers for feature extraction in the encoder part\n",
        "    # エンコーダパーツのフィーチャー抽出用レイヤー\n",
        "    encoder1 = base_model.get_layer('activation_1').output\n",
        "    encoder2 = base_model.get_layer('activation_10').output\n",
        "    encoder3 = base_model.get_layer('activation_22').output\n",
        "    encoder4 = base_model.get_layer('activation_40').output\n",
        "    encoder5 = base_model.get_layer('activation_49').output\n",
        "\n",
        "    # Center block\n",
        "    center = decoder_block(\n",
        "        encoder5, 'center', num_filters=512)\n",
        "    concat5 = concatenate([center, encoder5], axis=-1)\n",
        "\n",
        "    # Decoder part.\n",
        "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
        "    # This creates skip connections.\n",
        "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
        "    #デコーダ部分。\n",
        "    # すべてのデコーダ ブロックは、エンコーダとデコーダ パーツからの連結出力を処理しました。\n",
        "    # これにより、スキップ接続が作成されます。\n",
        "    #その後、デコーダ出力はエンコーダ出力部と等しい寸法にアップサンプリングされます。\n",
        "    decoder4 = decoder_block(\n",
        "        concat5, 'decoder4', num_filters=256)\n",
        "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
        "\n",
        "    decoder3 = decoder_block(\n",
        "        concat4, 'decoder3', num_filters=128)\n",
        "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
        "\n",
        "    decoder2 = decoder_block(\n",
        "        concat3, 'decoder2', num_filters=64)\n",
        "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
        "\n",
        "    decoder1 = decoder_block(\n",
        "        concat2, 'decoder1', num_filters=64)\n",
        "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
        "\n",
        "    # Final upsampling and decoder block for segmentation.\n",
        "    #セグメンテーションのための最終的なアップサンプリングとデコーダブロック。\n",
        "    output = UpSampling2D()(concat1)\n",
        "    output = decoder_block(\n",
        "        output, 'decoder_output', num_filters=32)\n",
        "    output = Conv2D(\n",
        "        1, (1, 1), activation=None, name='prediction')(output)\n",
        "    if not use_lovash:\n",
        "        output = Activation('sigmoid')(output)\n",
        "        \n",
        "    model = Model(base_model.input, output)\n",
        "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsnG2-y7_zaI",
        "colab_type": "text"
      },
      "source": [
        "### Inspect created model:\n",
        "作成したモデルを検査する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "7w-sbg2R_zaJ",
        "colab_type": "code",
        "outputId": "e4b43dbf-4036-478d-a83b-8b8caabad0fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "input_size = (224, 224, 3)\n",
        "\n",
        "\n",
        "K.clear_session()\n",
        "model = unet_resnet(\n",
        "    input_size, decoder_block_simple, weights='imagenet')\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:107: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:111: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94658560/94653016 [==============================] - 3s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From <ipython-input-61-910567864b2d>:153: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "center_conv (Conv2D)            (None, 7, 7, 512)    9437696     activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "center_bn (BatchNormalization)  (None, 7, 7, 512)    2048        center_conv[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "center_activation (PReLU)       (None, 7, 7, 512)    25088       center_bn[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 7, 7, 2560)   0           center_activation[0][0]          \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv (Conv2D)          (None, 7, 7, 256)    5898496     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn (BatchNormalization (None, 7, 7, 256)    1024        decoder4_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation (PReLU)     (None, 7, 7, 256)    12544       decoder4_bn[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           decoder4_activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 14, 14, 1280) 0           up_sampling2d_1[0][0]            \n",
            "                                                                 activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv (Conv2D)          (None, 14, 14, 128)  1474688     concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn (BatchNormalization (None, 14, 14, 128)  512         decoder3_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation (PReLU)     (None, 14, 14, 128)  25088       decoder3_bn[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           decoder3_activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
            "                                                                 activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv (Conv2D)          (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn (BatchNormalization (None, 28, 28, 64)   256         decoder2_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation (PReLU)     (None, 28, 28, 64)   50176       decoder2_bn[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           decoder2_activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
            "                                                                 activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv (Conv2D)          (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn (BatchNormalization (None, 56, 56, 64)   256         decoder1_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation (PReLU)     (None, 56, 56, 64)   200704      decoder1_bn[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           decoder1_activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
            "                                                                 activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv (Conv2D)    (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn (BatchNormali (None, 224, 224, 32) 128         decoder_output_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation (PReL (None, 224, 224, 32) 1605632     decoder_output_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "prediction (Conv2D)             (None, 224, 224, 1)  33          decoder_output_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 224, 224, 1)  0           prediction[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 42,912,065\n",
            "Trainable params: 42,856,833\n",
            "Non-trainable params: 55,232\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wy9xwGTn_zaL",
        "colab_type": "text"
      },
      "source": [
        "### Train model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "zXoiMTSH_zaM",
        "colab_type": "code",
        "outputId": "d8f8523c-00d8-43f3-cfcc-7782caae4142",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "K.clear_session()\n",
        "\n",
        "# Build model:\n",
        "# Here, you can experiment with various losses.\n",
        "# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n",
        "# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n",
        "# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n",
        "# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n",
        "# This is controlled by use_lovash parameter.\n",
        "# ＃モデルの構築：\n",
        "# ＃ここでは、さまざまな損失を試すことができます。\n",
        "# ＃サイコロとBCE（binary_crossentropy）には、my_iou_metricを使用する必要があります。\n",
        "# ＃一方、lovash_lossにはmy_iou_metric2を使用する必要があります。これは、値の範囲が\n",
        "# ロバシュ損失の＃は-infと+ infの間であり、BCEとサイコロのように0と1の間ではありません。\n",
        "# ＃さらに、ロバッシュ損失を使用する場合、最後のレイヤー（シグモイド）を削除する必要があります。\n",
        "# ＃これはuse_lovashパラメーターによって制御されます。\n",
        "\n",
        "model_depth = unet_resnet(\n",
        "    input_size, decoder_block_bottleneck, weights='imagenet',\n",
        "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
        "    use_lovash=False)\n",
        "print(model_depth.summary())\n",
        "\n",
        "\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    'unet_resnet.h5' ,monitor='val_my_iou_metric', mode='max',\n",
        "    save_best_only=True, save_weights_only=True, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_my_iou_metric',\n",
        "    mode='max',\n",
        "    factor=0.5, \n",
        "    patience=5, \n",
        "    min_lr=0.0001, \n",
        "    verbose=1)\n",
        "\n",
        "\n",
        "epochs = 2  # 25\n",
        "batch_size = 16\n",
        "\n",
        "history = model_depth.fit(X_tr, y_tr,\n",
        "                    validation_data=[X_val, y_val], \n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    callbacks=[model_checkpoint,reduce_lr], \n",
        "                    verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "center_conv1 (Conv2D)           (None, 7, 7, 512)    9437696     activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "center_bn1 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_activation1 (PReLU)      (None, 7, 7, 512)    25088       center_bn1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 7, 7, 512)    0           center_activation1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "center_conv2 (Conv2D)           (None, 7, 7, 256)    1179904     dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "center_bn2 (BatchNormalization) (None, 7, 7, 256)    1024        center_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_activation2 (PReLU)      (None, 7, 7, 256)    12544       center_bn2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 7, 7, 256)    0           center_activation2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "center_conv3 (Conv2D)           (None, 7, 7, 512)    1180160     dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "center_bn3 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_activation3 (PReLU)      (None, 7, 7, 512)    25088       center_bn3[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 7, 7, 512)    0           center_activation3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 7, 7, 512)    0           dropout_1[0][0]                  \n",
            "                                                                 dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 7, 7, 2560)   0           add_17[0][0]                     \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv1 (Conv2D)         (None, 7, 7, 256)    5898496     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn1 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation1 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv2 (Conv2D)         (None, 7, 7, 128)    295040      dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn2 (BatchNormalizatio (None, 7, 7, 128)    512         decoder4_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation2 (PReLU)    (None, 7, 7, 128)    6272        decoder4_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 7, 7, 128)    0           decoder4_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv3 (Conv2D)         (None, 7, 7, 256)    295168      dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn3 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation3 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 7, 7, 256)    0           dropout_4[0][0]                  \n",
            "                                                                 dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 14, 14, 1280) 0           up_sampling2d_1[0][0]            \n",
            "                                                                 activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv1 (Conv2D)         (None, 14, 14, 128)  1474688     concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn1 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation1 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv2 (Conv2D)         (None, 14, 14, 64)   73792       dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn2 (BatchNormalizatio (None, 14, 14, 64)   256         decoder3_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation2 (PReLU)    (None, 14, 14, 64)   12544       decoder3_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 14, 14, 64)   0           decoder3_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv3 (Conv2D)         (None, 14, 14, 128)  73856       dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn3 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation3 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 14, 14, 128)  0           dropout_7[0][0]                  \n",
            "                                                                 dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
            "                                                                 activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv1 (Conv2D)         (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn1 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation1 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv2 (Conv2D)         (None, 28, 28, 32)   18464       dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn2 (BatchNormalizatio (None, 28, 28, 32)   128         decoder2_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation2 (PReLU)    (None, 28, 28, 32)   25088       decoder2_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 28, 28, 32)   0           decoder2_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv3 (Conv2D)         (None, 28, 28, 64)   18496       dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn3 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation3 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 28, 28, 64)   0           dropout_10[0][0]                 \n",
            "                                                                 dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
            "                                                                 activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv1 (Conv2D)         (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn1 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation1 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv2 (Conv2D)         (None, 56, 56, 32)   18464       dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn2 (BatchNormalizatio (None, 56, 56, 32)   128         decoder1_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation2 (PReLU)    (None, 56, 56, 32)   100352      decoder1_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 56, 56, 32)   0           decoder1_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv3 (Conv2D)         (None, 56, 56, 64)   18496       dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn3 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation3 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 56, 56, 64)   0           dropout_13[0][0]                 \n",
            "                                                                 dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
            "                                                                 activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 224, 224, 32) 0           dropout_16[0][0]                 \n",
            "                                                                 dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "prediction (Conv2D)             (None, 224, 224, 1)  33          add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 224, 224, 1)  0           prediction[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 48,978,353\n",
            "Trainable params: 48,919,953\n",
            "Non-trainable params: 58,400\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Train on 3196 samples, validate on 804 samples\n",
            "Epoch 1/2\n",
            "3196/3196 [==============================] - 7947s 2s/step - loss: 0.7731 - my_iou_metric: 0.3150 - val_loss: 1.4469 - val_my_iou_metric: 0.4756\n",
            "\n",
            "Epoch 00001: val_my_iou_metric improved from -inf to 0.47562, saving model to unet_resnet.h5\n",
            "Epoch 2/2\n",
            "3196/3196 [==============================] - 7789s 2s/step - loss: 0.6084 - my_iou_metric: 0.4766 - val_loss: 1.3371 - val_my_iou_metric: 0.5019\n",
            "\n",
            "Epoch 00002: val_my_iou_metric improved from 0.47562 to 0.50187, saving model to unet_resnet.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wCL16pt_zaO",
        "colab_type": "text"
      },
      "source": [
        "### Validation set prediction and resizing to original size:\n",
        "検証セットの予測と元のサイズへのサイズ変更"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OisVZ_Vg_zaP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_preds = model_depth.predict(X_val, batch_size=16)\n",
        "\n",
        "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
        "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Opt11xKi_zaQ",
        "colab_type": "text"
      },
      "source": [
        "### Threshold optimization: \n",
        "しきい値の最適化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxPHehP8_zaR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
        "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
        "    labels = y_true_in\n",
        "    y_pred = y_pred_in\n",
        "    \n",
        "    true_objects = 2\n",
        "    pred_objects = 2\n",
        "\n",
        "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
        "\n",
        "    # Compute areas (needed for finding the union between all objects)\n",
        "    # 計算領域（すべてのオブジェクト間の結合を見つけるために必要\n",
        "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
        "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
        "    area_true = np.expand_dims(area_true, -1)\n",
        "    area_pred = np.expand_dims(area_pred, 0)\n",
        "\n",
        "    # Compute union\n",
        "    union = area_true + area_pred - intersection\n",
        "\n",
        "    # Exclude background from the analysis(分析から背景を除外する)\n",
        "    intersection = intersection[1:,1:]\n",
        "    union = union[1:,1:]\n",
        "    union[union == 0] = 1e-9\n",
        "\n",
        "    # Compute the intersection over union(和集合上の交点を計算します)\n",
        "    iou = intersection / union\n",
        "\n",
        "    # Precision helper function\n",
        "    def precision_at(threshold, iou):\n",
        "        matches = iou > threshold #しきい値より大なら１、小なら０\n",
        "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
        "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
        "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
        "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
        "        return tp, fp, fn\n",
        "\n",
        "    # Loop over IoU thresholds(IoUしきい値を超えるループ)\n",
        "    prec = []\n",
        "    if print_table:\n",
        "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
        "    for t in np.arange(0.5, 1.0, 0.05):\n",
        "        tp, fp, fn = precision_at(t, iou)\n",
        "        if (tp + fp + fn) > 0:\n",
        "            p = tp / (tp + fp + fn)\n",
        "        else:\n",
        "            p = 0\n",
        "        if print_table:\n",
        "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
        "        prec.append(p)\n",
        "    \n",
        "    if print_table:\n",
        "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
        "    return np.mean(prec)\n",
        "\n",
        "def iou_metric_batch(y_true_in, y_pred_in):\n",
        "    batch_size = y_true_in.shape[0]\n",
        "    metric = []\n",
        "    for batch in range(batch_size):\n",
        "        value = iou_metric(y_true_in[batch], y_pred_in[\n",
        "                                                       batch])\n",
        "        metric.append(value)\n",
        "    return np.mean(metric)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2VakY9O_zaT",
        "colab_type": "code",
        "outputId": "4f02248f-1229-4727-e8cb-1c78e9b23c3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Threshold range, over which optimization is performed(最適化が実行されるしきい値範囲)\n",
        "thresholds = np.arange(0.2, 0.9, 0.02)\n",
        "\n",
        "# For every threshold, set predictions to binary arrays, \n",
        "# where values above threshold are treated as 1 and the rest as 0.\n",
        "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
        "# すべてのしきい値について、予測をバイナリ配列に設定し、\n",
        "# ＃しきい値を超える値は1として処理され、残りは0として処理されます。\n",
        "# ＃しきい値をループし、上記のIoU関数に基づいてIoUを計算します。\n",
        "ious = np.array(\n",
        "    [iou_metric_batch(y_val_true,\n",
        "                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:38<00:00,  1.11s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ErPbRjV_zaX",
        "colab_type": "code",
        "outputId": "ed1590c4-ecb9-47e0-8248-85fba0d3b35d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "source": [
        "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
        "df_iou['iou'] = ious\n",
        "\n",
        "# Get index of best IoU(最高のIoUのインデックスを取得)\n",
        "best_index = df_iou['iou'].idxmax()\n",
        "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
        "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
        "\n",
        "# Describe IoU DF(IoU DFの説明)\n",
        "df_iou.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best IoU: 0.5515 at threshold: 0.660\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>threshold</th>\n",
              "      <th>iou</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.540000</td>\n",
              "      <td>0.537239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.204939</td>\n",
              "      <td>0.015830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.492910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.370000</td>\n",
              "      <td>0.533769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.540000</td>\n",
              "      <td>0.544154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.710000</td>\n",
              "      <td>0.549192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.551493</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       threshold        iou\n",
              "count  35.000000  35.000000\n",
              "mean    0.540000   0.537239\n",
              "std     0.204939   0.015830\n",
              "min     0.200000   0.492910\n",
              "25%     0.370000   0.533769\n",
              "50%     0.540000   0.544154\n",
              "75%     0.710000   0.549192\n",
              "max     0.880000   0.551493"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYUWiaPT_zaa",
        "colab_type": "code",
        "outputId": "812e741d-6f44-4737-e9e3-7cfc30f4d621",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        }
      },
      "source": [
        "# Plot IoU values over threshold range.(しきい値範囲でIoU値をプロットします。)\n",
        "df_iou.plot(x='threshold', y='iou')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc0ce733550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAswAAAIaCAYAAAA0thsoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/C+ops6gvCCZkwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 864x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IidbFPTF_zad",
        "colab_type": "text"
      },
      "source": [
        "## Conclusions:\n",
        "\n",
        "- Pretrained models can be used for segmentation problems:\n",
        "    - Some of architectures can be easily adapted to the problem (ie ResNet)\n",
        "    - Other architectures may require more experimentation with selection of proper layers for feature extraction and padding (example of using [Xception](https://www.kaggle.com/meaninglesslives/getting-0-87-on-private-lb-using-kaggle-kernel). )\n",
        "    - You can experiment with selection of layers for feature extraction\n",
        "    - For some models, you can also try to experiment with number of encoder/decoder blocks\n",
        "- Threshold optimization is important in problems, where direct metric optimization during training is difficult.\n",
        "    - It it possible to use more involved optimization methods (from [scipy optimize](https://docs.scipy.org/doc/scipy/reference/optimize.html)), although this may not be optimal unless distribution of train and test set are very similar. Overoptimization of threshold or any other parameter on validation set may result in worse test set results.\n",
        "- Experiment with various losses - BCE, Dice, combined BCE with Dice, Lovash loss.\n",
        "    - Models trained with various losses may give different results, which may be advantageous when ensembling.\n",
        "\n",
        "\n",
        "### Possible experiments:\n",
        "\n",
        "- Change type of decoder block in created segmentation model\n",
        "- Create your own decoder blocks\n",
        "- Train with other losses\n",
        "- Train longer\n",
        "- Train with BCE/Dice, save the model, then load weights and finetune with Lovash loss\n",
        "- Try different ranges and intervals for threshold optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWNLYJCQJFc9",
        "colab_type": "text"
      },
      "source": [
        "# ResNetをVGGに変更したU-netを実行"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vf10XaUWEttQ"
      },
      "source": [
        "### Model architecture tuning & score optimization\n",
        "\n",
        "Some ideas and code taken from ealier [kernel](https://www.kaggle.com/wrosinski/clean-workflow-in-keras) and last prepared notebook.\n",
        "\n",
        "Having dealt with data processing & engineering of channel features, next step of modeling is preparation and tuning of model architecture. Earlier notebooks provided a way to create images with three channels, which will facilitate usage of pretrained models.\n",
        "\n",
        "For segmentation tasks, a pretrained model can be used as encoder part of the final architecture. \n",
        "In order to use pretrained models, we will have to extract features from a few intermediate layers, which will then serve as a basis for layers coming afterwards and for skip connections between encoder and decoder part.\n",
        "\n",
        "ResNet50 is a good starting point, because it consists of 4 blocks, where each one of them can serve as feature extractor with first layer serving as the 5th extractor to achieve consistency with standard UNet architecture."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cQtcHspQEttT",
        "colab": {}
      },
      "source": [
        "import gc\n",
        "import glob\n",
        "import os\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from tqdm import tqdm\n",
        "\n",
        "from keras import optimizers\n",
        "from keras.callbacks import *\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.layers import *\n",
        "from keras.models import Model, load_model, save_model\n",
        "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
        "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FjOLCwLbEttX",
        "colab": {}
      },
      "source": [
        "plt.rcParams['figure.figsize'] = (12, 9)\n",
        "# plt.style.use('ggplot')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "woUtXvltEttY",
        "colab": {}
      },
      "source": [
        "def compute_coverage(df, masks):\n",
        "    \n",
        "    df = df.copy()\n",
        "    \n",
        "    def cov_to_class(val):\n",
        "        for i in range(0, 11):\n",
        "            if val * 10 <= i:\n",
        "                return i\n",
        "\n",
        "    # Output percentage of area covered by class（クラスがカバーする面積の出力割合）\n",
        "    df['coverage'] = np.mean(masks, axis=(1, 2))\n",
        "    # Coverage must be split into bins, otherwise stratified split will not be possible,\n",
        "    # because each coverage will occur only once.\n",
        "    #カバレッジはビンに分割する必要があります。そうしないと、階層化された分割が不可能になります。\n",
        "    #各カバレッジが1回だけ発生するため。\n",
        "    df['coverage_class'] = df.coverage.map(\n",
        "        cov_to_class)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def create_depth_abs_channels(image_tensor):\n",
        "    image_tensor = image_tensor.astype(np.float32) #画像をテンソル形式に変換\n",
        "    h, w, c = image_tensor.shape\n",
        "    for row, const in enumerate(np.linspace(0, 1, h)):\n",
        "        image_tensor[row, :, 1] = const\n",
        "    image_tensor[:, :, 2] = (\n",
        "        image_tensor[:, :, 0] * image_tensor[:, :, 1])\n",
        "\n",
        "    x_dx = np.diff(image_tensor[:, :, 0], axis=0)\n",
        "    x_dy = np.diff(image_tensor[:, :, 0], axis=1)\n",
        "    x_dx = cv2.copyMakeBorder(x_dx, 1, 0, 0, 0, cv2.BORDER_CONSTANT, 0)\n",
        "    x_dy = cv2.copyMakeBorder(x_dy, 0, 0, 1, 0, cv2.BORDER_CONSTANT, 0)\n",
        "    image_tensor[:, :, 1] = np.abs(x_dx + x_dy)\n",
        "\n",
        "    return image_tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jwRHx4hjEtta"
      },
      "source": [
        "### Data loading & depth merge:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "82a8efc4-d740-47fc-84cb-52610f3f9de7",
        "id": "HPLw2RHyEtta",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "train = pd.read_csv('/content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20/input/train.csv')\n",
        "test = pd.read_csv('/content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20/input/sample_submission.csv')\n",
        "depth = pd.read_csv('/content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20/input/depths.csv')\n",
        "\n",
        "train_src = '../input/train/'\n",
        "\n",
        "print('train:\\n{}'.format(train.head()))\n",
        "print('\\ntest:\\n{}'.format(test.head()))\n",
        "\n",
        "\n",
        "train = train.merge(depth, how='left', on='id')\n",
        "test = test.merge(depth, how='left', on='id')\n",
        "\n",
        "print('\\n{}'.format(train.head()))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train:\n",
            "           id                                           rle_mask\n",
            "0  575d24d81d                                                NaN\n",
            "1  a266a2a9df                                          5051 5151\n",
            "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...\n",
            "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...\n",
            "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...\n",
            "\n",
            "test:\n",
            "           id rle_mask\n",
            "0  155410d6fa      1 1\n",
            "1  78b32781d1      1 1\n",
            "2  63db2a476a      1 1\n",
            "3  17bfcdb967      1 1\n",
            "4  7ea0fd3c88      1 1\n",
            "\n",
            "           id                                           rle_mask    z\n",
            "0  575d24d81d                                                NaN  843\n",
            "1  a266a2a9df                                          5051 5151  794\n",
            "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...  468\n",
            "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...  727\n",
            "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...  797\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C9H1ye6nEtte"
      },
      "source": [
        "### Load images and masks, examine random sample:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b91dd852-d3cb-4c4c-add0-c1fa4cadf028",
        "id": "MW6DHsZCEttf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#画像が保存してあるパスを指定して直接np.arrayを作る\n",
        "X_train = np.asarray(\n",
        "    [cv2.imread('/content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20/images/{}.png'.format(x), 0) for x in train.id.tolist()], \n",
        "    dtype=np.uint8) / 255.\n",
        "y_train = np.asarray(\n",
        "    [cv2.imread('/content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20/masks/{}.png'.format(x), 0) for x in train.id.tolist()],\n",
        "    dtype=np.uint8) / 255.\n",
        "\n",
        "print(X_train.shape, y_train.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4000, 101, 101) (4000, 101, 101)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab_type": "code",
        "id": "I8jRqylLEtth",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "31d25a50-5278-45a4-d5c4-9a013f2a3524"
      },
      "source": [
        "random_index = np.random.randint(0, X_train.shape[0])\n",
        "\n",
        "fig, ax = plt.subplots(1, 2)\n",
        "\n",
        "ax[0].imshow(X_train[random_index], cmap='gray')\n",
        "ax[1].imshow(y_train[random_index], cmap='gray')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f602137cdd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs0AAAFTCAYAAADCyzEvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niMzgQ7OIiIiIyAz/P6ITlcP78mGpAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OxNCMSusEtti"
      },
      "source": [
        "### Compute salt coverage (this will serve as a basis for stratified split):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wIGY1CnCEttj",
        "colab": {}
      },
      "source": [
        "train = compute_coverage(train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1z3V-vETEttk"
      },
      "source": [
        "### Prepare data for training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iujOjLkyEttl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "9d9fcc46-19e5-4322-a30b-0eb122d680c3"
      },
      "source": [
        "\n",
        "kfold = StratifiedKFold(n_splits=5, random_state=1337)\n",
        "\n",
        "# Add channel features\n",
        "X_train_ch = np.repeat(np.expand_dims(X_train, axis=-1), 3, -1)#一番最後の軸を指定して\n",
        "X_train_ch = np.asarray(list(map(lambda x: create_depth_abs_channels(x), X_train_ch)))\n",
        "\n",
        "# Resize to 224x224, default ResNet50 image size\n",
        "X_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), X_train_ch)))\n",
        "y_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), y_train)))\n",
        "\n",
        "\n",
        "for train_index, valid_index in kfold.split(train.id.values, train.coverage_class.values):\n",
        "    \n",
        "    X_tr, X_val = X_resized[train_index], X_resized[valid_index]\n",
        "    y_tr, y_val = y_resized[train_index], y_resized[valid_index]\n",
        "    \n",
        "    break\n",
        "    \n",
        "\n",
        "y_tr = np.expand_dims(y_tr, axis=-1)\n",
        "y_val = np.expand_dims(y_val, axis=-1)\n",
        "\n",
        "print(X_tr.shape, y_tr.shape)\n",
        "print(X_val.shape, y_val.shape)\n",
        "\n",
        "\n",
        "del X_train_ch, y_resized\n",
        "del X_resized\n",
        "gc.collect()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3196, 224, 224, 3) (3196, 224, 224, 1)\n",
            "(804, 224, 224, 3) (804, 224, 224, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5230"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vVxMSBIKEttn"
      },
      "source": [
        "### Loss functions & metric:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DYjZTIe0Etto",
        "colab": {}
      },
      "source": [
        "from keras.losses import binary_crossentropy\n",
        "\n",
        "\n",
        "# Dice & combined\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred = K.cast(y_pred, 'float32')\n",
        "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
        "    intersection = y_true_f * y_pred_f\n",
        "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
        "    return score\n",
        "\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = y_true_f * y_pred_f\n",
        "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "    return 1. - score\n",
        "\n",
        "\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
        "\n",
        "\n",
        "def bce_logdice_loss(y_true, y_pred):\n",
        "    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n",
        "\n",
        "\n",
        "\n",
        "# Lovash loss: https://github.com/bermanmaxim/LovaszSoftmax\n",
        "def lovasz_grad(gt_sorted):\n",
        "    \"\"\"\n",
        "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
        "    See Alg. 1 in paper\n",
        "    \"\"\"\n",
        "    gts = tf.reduce_sum(gt_sorted)\n",
        "    intersection = gts - tf.cumsum(gt_sorted)\n",
        "    union = gts + tf.cumsum(1. - gt_sorted)\n",
        "    jaccard = 1. - intersection / union\n",
        "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
        "    return jaccard\n",
        "\n",
        "\n",
        "# --------------------------- BINARY LOSSES ---------------------------\n",
        "\n",
        "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
        "    \"\"\"\n",
        "    Binary Lovasz hinge loss\n",
        "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
        "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
        "      per_image: compute the loss per image instead of per batch\n",
        "      ignore: void class id\n",
        "    \"\"\"\n",
        "    if per_image:\n",
        "        def treat_image(log_lab):\n",
        "            log, lab = log_lab\n",
        "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
        "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
        "            return lovasz_hinge_flat(log, lab)\n",
        "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
        "        loss = tf.reduce_mean(losses)\n",
        "    else:\n",
        "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
        "    return loss\n",
        "\n",
        "\n",
        "def lovasz_hinge_flat(logits, labels):\n",
        "    \"\"\"\n",
        "    Binary Lovasz hinge loss\n",
        "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
        "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
        "      ignore: label to ignore\n",
        "    \"\"\"\n",
        "\n",
        "    def compute_loss():\n",
        "        labelsf = tf.cast(labels, logits.dtype)\n",
        "        signs = 2. * labelsf - 1.\n",
        "        errors = 1. - logits * tf.stop_gradient(signs)\n",
        "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
        "        gt_sorted = tf.gather(labelsf, perm)\n",
        "        grad = lovasz_grad(gt_sorted)\n",
        "        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
        "        return loss\n",
        "\n",
        "    # deal with the void prediction case (only void pixels)\n",
        "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
        "                   lambda: tf.reduce_sum(logits) * 0.,\n",
        "                   compute_loss,\n",
        "                   strict=True,\n",
        "                   name=\"loss\"\n",
        "                   )\n",
        "    return loss\n",
        "\n",
        "\n",
        "def flatten_binary_scores(scores, labels, ignore=None):\n",
        "    \"\"\"\n",
        "    Flattens predictions in the batch (binary case)\n",
        "    Remove labels equal to 'ignore'\n",
        "    \"\"\"\n",
        "    scores = tf.reshape(scores, (-1,))\n",
        "    labels = tf.reshape(labels, (-1,))\n",
        "    if ignore is None:\n",
        "        return scores, labels\n",
        "    valid = tf.not_equal(labels, ignore)\n",
        "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
        "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
        "    return vscores, vlabels\n",
        "\n",
        "\n",
        "def lovasz_loss(y_true, y_pred):\n",
        "    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n",
        "    #logits = K.log(y_pred / (1. - y_pred))\n",
        "    logits = y_pred #Jiaxin\n",
        "    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n",
        "    return loss\n",
        "\n",
        "\n",
        "# IoU metric for observation during training\n",
        "# https://www.kaggle.com/cpmpml/fast-iou-metric-in-numpy-and-tensorflow\n",
        "def get_iou_vector(A, B):\n",
        "    # Numpy version    \n",
        "    batch_size = A.shape[0]\n",
        "    metric = 0.0\n",
        "    for batch in range(batch_size):\n",
        "        t, p = A[batch], B[batch]\n",
        "        true = np.sum(t)\n",
        "        pred = np.sum(p)\n",
        "        \n",
        "        # deal with empty mask first\n",
        "        if true == 0:\n",
        "            metric += (pred == 0)\n",
        "            continue\n",
        "        \n",
        "        # non empty mask case.  Union is never empty \n",
        "        # hence it is safe to divide by its number of pixels\n",
        "        intersection = np.sum(t * p)\n",
        "        union = true + pred - intersection\n",
        "        iou = intersection / union\n",
        "        \n",
        "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
        "        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
        "        \n",
        "        metric += iou\n",
        "        \n",
        "    # teake the average over all images in batch\n",
        "    metric /= batch_size\n",
        "    return metric\n",
        "\n",
        "\n",
        "def my_iou_metric(label, pred):\n",
        "    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n",
        "\n",
        "\n",
        "# For Lovash loss\n",
        "def my_iou_metric_2(label, pred):\n",
        "    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EFJY8NnsEttp"
      },
      "source": [
        "### Encoder features - ResNet50:\n",
        "これをVGGに書き換える\n",
        "\n",
        "In ResNet50, each block finishes with a pooling layer, so we can extract features from intermediate layers just before the pooling. This way, when first layer is added as additional extractor, we will have features extracted from 5 layers.\n",
        "Default input size will be assumed, which is (224, 224, 3).\n",
        "Layers will be as follows:\n",
        "\n",
        "- 'activation_1', shape: (None, 112, 112, 64)\n",
        "- 'activation_10', shape: (None, 56, 56, 256)\n",
        "- 'activation_22', shape: (None, 28, 28, 512)\n",
        "- 'activation_40', shape: (None, 14, 14, 1024)\n",
        "- 'activation_49', shape: (None, 7, 7, 2048)\n",
        "\n",
        "One thing to keep in mind is that every time a model will be created in the same TF session in the notebook, layer names will change, so above layer names correspond to first creation of the model. In order to reset session, call `K.clear_session()`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tD21aq5tI4nU",
        "colab_type": "text"
      },
      "source": [
        "### VGGをインポート"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_jpXeeeB3Jo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "06424826-fc78-4d05-a063-af95d08a8182"
      },
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "#model = VGG16(include_top=False, weights='imagenet', input_tensor=None, input_shape=(224,224,3))\n",
        "#include_top=Trueは全結合層を含む input_shape=Noneは(224,224,3)\n",
        "model.summary()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 2s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T8LlGJNPEttq"
      },
      "source": [
        "### Decoder blocks:\n",
        "\n",
        "Features from ResNet50 will serve as a basis for encoder part of the segmentation model, now a decoder part is needed.\n",
        "For this part, we will have to create our own blocks. Let's create a very basic block and a second one, which structure will have a more complicated structure.\n",
        "ResNet50の機能は、セグメンテーションモデルのエンコーダー部分の基盤として機能しますが、現在はデコーダー部分が必要です。この部分では、独自のブロックを作成する必要があります。非常に基本的なブロックと2つ目のブロックを作成してみましょう。この構造はより複雑な構造になります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Pe3M_XSjEttr",
        "colab": {}
      },
      "source": [
        "# Basic decoder block with Conv, BN and PReLU activation.\n",
        "def decoder_block_simple(\n",
        "        layer_name, block_name,\n",
        "        num_filters=32,\n",
        "        conv_dim=(3, 3)):\n",
        "\n",
        "    x_dec = Conv2D(\n",
        "        num_filters, conv_dim,\n",
        "        padding='same',\n",
        "        name='{}_conv'.format(block_name))(layer_name)\n",
        "    x_dec = BatchNormalization(\n",
        "        name='{}_bn'.format(block_name))(x_dec)\n",
        "    x_dec = PReLU(\n",
        "        name='{}_activation'.format(block_name))(x_dec)\n",
        "\n",
        "    return x_dec\n",
        "\n",
        "# Decoder block with bottleneck architecture, where middle conv layer\n",
        "# is half the size of first and last, in order to compress representation.\n",
        "# This type of architecture is supposed to retain most useful information.\n",
        "# ボトルネックアーキテクチャを備えたデコーダブロック。中間コンバードレイヤー\n",
        "# は、表現を圧縮するために、最初と最後の半分のサイズです。\n",
        "# このタイプのアーキテクチャは、最も有用な情報を保持することになっています。\n",
        "def decoder_block_bottleneck(\n",
        "        layer_name, block_name,\n",
        "        num_filters=32,\n",
        "        conv_dim=(3, 3),\n",
        "        dropout_frac=0.2):\n",
        "\n",
        "    x_dec = Conv2D(\n",
        "        num_filters, conv_dim,\n",
        "        padding='same',\n",
        "        name='{}_conv1'.format(block_name))(layer_name)\n",
        "    x_dec = BatchNormalization(\n",
        "        name='{}_bn1'.format(block_name))(x_dec)\n",
        "    x_dec = PReLU(\n",
        "        name='{}_activation1'.format(block_name))(x_dec)\n",
        "    x_dec = Dropout(dropout_frac)(x_dec)\n",
        "\n",
        "    x_dec2 = Conv2D(\n",
        "        num_filters // 2, conv_dim,\n",
        "        padding='same',\n",
        "        name='{}_conv2'.format(block_name))(x_dec)\n",
        "    x_dec2 = BatchNormalization(\n",
        "        name='{}_bn2'.format(block_name))(x_dec2)\n",
        "    x_dec2 = PReLU(\n",
        "        name='{}_activation2'.format(block_name))(x_dec2)\n",
        "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
        "\n",
        "    x_dec2 = Conv2D(\n",
        "        num_filters, conv_dim,\n",
        "        padding='same',\n",
        "        name='{}_conv3'.format(block_name))(x_dec2)\n",
        "    x_dec2 = BatchNormalization(\n",
        "        name='{}_bn3'.format(block_name))(x_dec2)\n",
        "    x_dec2 = PReLU(\n",
        "        name='{}_activation3'.format(block_name))(x_dec2)\n",
        "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
        "\n",
        "    x_dec2 = Add()([x_dec, x_dec2])\n",
        "\n",
        "    return x_dec2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_UplYyRzEttt"
      },
      "source": [
        "### Model definition:\n",
        "\n",
        "Combine encoder and decoder blocks to create final segmentation model.\n",
        "モデル定義： エンコーダーブロックとデコーダーブロックを組み合わせて、最終的なセグメンテーションモデルを作成します。\n",
        "\n",
        "＊ここでVGG１６への書き換えを実施"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ybnmRBFEEttt",
        "colab": {}
      },
      "source": [
        "# Model is parametrized in a way to enable easy change of decoder_block type,\n",
        "# as this is an argument that can be given a function, like decoder_block_simple.\n",
        "# ＃モデルは、decoder_blockタイプを簡単に変更できるようにパラメーター化されます。\n",
        "# ＃これは、decoder_block_simpleなどの関数を指定できる引数であるためです。\n",
        "def unet_resnet(input_size, decoder_block,\n",
        "                weights='imagenet',\n",
        "                loss_func='binary_crossentropy',\n",
        "                metrics_list=[my_iou_metric],\n",
        "                use_lovash=False):\n",
        "\n",
        "    # Base model - encoder\n",
        "    #VGG16に書き換え\n",
        "    base_model = VGG16(\n",
        "        include_top=False, \n",
        "        weights=weights, \n",
        "        input_tensor=None, \n",
        "        input_shape=(224,224,3))\n",
        "    \n",
        "    #print(base_model.summary())\n",
        "\n",
        "    # Layers for feature extraction in the encoder part\n",
        "    #VGG16に合わせた層をデコーダーに接続用に抽出\n",
        "    encoder1 = base_model.get_layer('block1_conv2').output\n",
        "    encoder2 = base_model.get_layer('block2_conv2').output\n",
        "    encoder3 = base_model.get_layer('block3_conv3').output\n",
        "    encoder4 = base_model.get_layer('block4_conv3').output\n",
        "    encoder5 = base_model.get_layer('block5_conv3').output\n",
        "\n",
        "    # Center block\n",
        "    center = decoder_block(\n",
        "        encoder5, 'center', num_filters=512)\n",
        "    concat5 = concatenate([center, encoder5], axis=-1)\n",
        "\n",
        "    # Decoder part.\n",
        "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
        "    # This creates skip connections.\n",
        "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
        "    decoder4 = decoder_block(\n",
        "        concat5, 'decoder4', num_filters=256)\n",
        "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
        "\n",
        "    decoder3 = decoder_block(\n",
        "        concat4, 'decoder3', num_filters=128)\n",
        "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
        "\n",
        "    decoder2 = decoder_block(\n",
        "        concat3, 'decoder2', num_filters=64)\n",
        "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
        "\n",
        "    decoder1 = decoder_block(\n",
        "        concat2, 'decoder1', num_filters=64)\n",
        "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
        "\n",
        "    # Final upsampling and decoder block for segmentation.\n",
        "    # output = UpSampling2D()(concat1)　# 入力サイズに合わせた出力にするため、UPsamplingを１回無効にする\n",
        "    output = decoder_block(\n",
        "        concat1, 'decoder_output', num_filters=32)\n",
        "    output = Conv2D(\n",
        "        1, (1, 1), activation=None, name='prediction')(output)\n",
        "    if not use_lovash:\n",
        "        output = Activation('sigmoid')(output)\n",
        "        \n",
        "    model = Model(base_model.input, output)\n",
        "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n1KKFUZpEttx"
      },
      "source": [
        "### Inspect created model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab_type": "code",
        "id": "iRRvNcBUEttz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "01f1664c-190d-4a7e-aa77-6102340121d8"
      },
      "source": [
        "input_size = (224, 224, 3)\n",
        "\n",
        "\n",
        "K.clear_session()\n",
        "model = unet_resnet(\n",
        "    input_size, decoder_block_simple, weights='imagenet')\n",
        "model.summary()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_conv (Conv2D)            (None, 14, 14, 512)  2359808     block5_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_bn (BatchNormalization)  (None, 14, 14, 512)  2048        center_conv[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "center_activation (PReLU)       (None, 14, 14, 512)  100352      center_bn[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 14, 14, 1024) 0           center_activation[0][0]          \n",
            "                                                                 block5_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv (Conv2D)          (None, 14, 14, 256)  2359552     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn (BatchNormalization (None, 14, 14, 256)  1024        decoder4_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation (PReLU)     (None, 14, 14, 256)  50176       decoder4_bn[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 28, 28, 256)  0           decoder4_activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 28, 28, 768)  0           up_sampling2d_1[0][0]            \n",
            "                                                                 block4_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv (Conv2D)          (None, 28, 28, 128)  884864      concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn (BatchNormalization (None, 28, 28, 128)  512         decoder3_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation (PReLU)     (None, 28, 28, 128)  100352      decoder3_bn[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 56, 56, 128)  0           decoder3_activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 56, 56, 384)  0           up_sampling2d_2[0][0]            \n",
            "                                                                 block3_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv (Conv2D)          (None, 56, 56, 64)   221248      concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn (BatchNormalization (None, 56, 56, 64)   256         decoder2_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation (PReLU)     (None, 56, 56, 64)   200704      decoder2_bn[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 112, 112, 64) 0           decoder2_activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 112, 112, 192 0           up_sampling2d_3[0][0]            \n",
            "                                                                 block2_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv (Conv2D)          (None, 112, 112, 64) 110656      concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn (BatchNormalization (None, 112, 112, 64) 256         decoder1_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation (PReLU)     (None, 112, 112, 64) 802816      decoder1_bn[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2D)  (None, 224, 224, 64) 0           decoder1_activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 224, 224, 128 0           up_sampling2d_4[0][0]            \n",
            "                                                                 block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv (Conv2D)    (None, 224, 224, 32) 36896       concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn (BatchNormali (None, 224, 224, 32) 128         decoder_output_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation (PReL (None, 224, 224, 32) 1605632     decoder_output_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "prediction (Conv2D)             (None, 224, 224, 1)  33          decoder_output_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 224, 224, 1)  0           prediction[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 23,552,001\n",
            "Trainable params: 23,549,889\n",
            "Non-trainable params: 2,112\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3a3ELdzDEtt1"
      },
      "source": [
        "### Train model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab_type": "code",
        "id": "ZmO8h_DLEtt2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4c8cab41-1d4c-4369-fbd7-84cac1cafa53"
      },
      "source": [
        "K.clear_session()\n",
        "\n",
        "# Build model:\n",
        "# Here, you can experiment with various losses.\n",
        "# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n",
        "# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n",
        "# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n",
        "# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n",
        "# This is controlled by use_lovash parameter.\n",
        "model_depth = unet_resnet(\n",
        "    input_size, decoder_block_bottleneck, weights='imagenet',\n",
        "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
        "    use_lovash=False)\n",
        "print(model_depth.summary())\n",
        "\n",
        "\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    'unet_resnet.h5' ,monitor='val_my_iou_metric', mode='max',\n",
        "    save_best_only=True, save_weights_only=True, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_my_iou_metric',\n",
        "    mode='max',\n",
        "    factor=0.5, \n",
        "    patience=5, \n",
        "    min_lr=0.0001, \n",
        "    verbose=1)\n",
        "\n",
        "\n",
        "epochs = 2  # 25\n",
        "batch_size = 8\n",
        "\n",
        "history = model_depth.fit(X_tr, y_tr,\n",
        "                    validation_data=[X_val, y_val], \n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    callbacks=[model_checkpoint,reduce_lr], \n",
        "                    verbose=1)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_bn1 (BatchNormalization) (None, 14, 14, 512)  2048        center_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_activation1 (PReLU)      (None, 14, 14, 512)  100352      center_bn1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 14, 14, 512)  0           center_activation1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "center_conv2 (Conv2D)           (None, 14, 14, 256)  1179904     dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "center_bn2 (BatchNormalization) (None, 14, 14, 256)  1024        center_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_activation2 (PReLU)      (None, 14, 14, 256)  50176       center_bn2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 14, 14, 256)  0           center_activation2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "center_conv3 (Conv2D)           (None, 14, 14, 512)  1180160     dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "center_bn3 (BatchNormalization) (None, 14, 14, 512)  2048        center_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_activation3 (PReLU)      (None, 14, 14, 512)  100352      center_bn3[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 14, 14, 512)  0           center_activation3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 14, 14, 512)  0           dropout_1[0][0]                  \n",
            "                                                                 dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 14, 14, 1024) 0           add_1[0][0]                      \n",
            "                                                                 block5_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv1 (Conv2D)         (None, 14, 14, 256)  2359552     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn1 (BatchNormalizatio (None, 14, 14, 256)  1024        decoder4_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation1 (PReLU)    (None, 14, 14, 256)  50176       decoder4_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 14, 14, 256)  0           decoder4_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv2 (Conv2D)         (None, 14, 14, 128)  295040      dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn2 (BatchNormalizatio (None, 14, 14, 128)  512         decoder4_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation2 (PReLU)    (None, 14, 14, 128)  25088       decoder4_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 14, 14, 128)  0           decoder4_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv3 (Conv2D)         (None, 14, 14, 256)  295168      dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn3 (BatchNormalizatio (None, 14, 14, 256)  1024        decoder4_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation3 (PReLU)    (None, 14, 14, 256)  50176       decoder4_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 14, 14, 256)  0           decoder4_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 14, 14, 256)  0           dropout_4[0][0]                  \n",
            "                                                                 dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 28, 28, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 28, 28, 768)  0           up_sampling2d_1[0][0]            \n",
            "                                                                 block4_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv1 (Conv2D)         (None, 28, 28, 128)  884864      concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn1 (BatchNormalizatio (None, 28, 28, 128)  512         decoder3_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation1 (PReLU)    (None, 28, 28, 128)  100352      decoder3_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 28, 28, 128)  0           decoder3_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv2 (Conv2D)         (None, 28, 28, 64)   73792       dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn2 (BatchNormalizatio (None, 28, 28, 64)   256         decoder3_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation2 (PReLU)    (None, 28, 28, 64)   50176       decoder3_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 28, 28, 64)   0           decoder3_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv3 (Conv2D)         (None, 28, 28, 128)  73856       dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn3 (BatchNormalizatio (None, 28, 28, 128)  512         decoder3_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation3 (PReLU)    (None, 28, 28, 128)  100352      decoder3_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 28, 28, 128)  0           decoder3_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 28, 28, 128)  0           dropout_7[0][0]                  \n",
            "                                                                 dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 56, 56, 128)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 56, 56, 384)  0           up_sampling2d_2[0][0]            \n",
            "                                                                 block3_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv1 (Conv2D)         (None, 56, 56, 64)   221248      concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn1 (BatchNormalizatio (None, 56, 56, 64)   256         decoder2_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation1 (PReLU)    (None, 56, 56, 64)   200704      decoder2_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 56, 56, 64)   0           decoder2_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv2 (Conv2D)         (None, 56, 56, 32)   18464       dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn2 (BatchNormalizatio (None, 56, 56, 32)   128         decoder2_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation2 (PReLU)    (None, 56, 56, 32)   100352      decoder2_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 56, 56, 32)   0           decoder2_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv3 (Conv2D)         (None, 56, 56, 64)   18496       dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn3 (BatchNormalizatio (None, 56, 56, 64)   256         decoder2_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation3 (PReLU)    (None, 56, 56, 64)   200704      decoder2_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 56, 56, 64)   0           decoder2_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 56, 56, 64)   0           dropout_10[0][0]                 \n",
            "                                                                 dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 112, 112, 64) 0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 112, 112, 192 0           up_sampling2d_3[0][0]            \n",
            "                                                                 block2_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv1 (Conv2D)         (None, 112, 112, 64) 110656      concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn1 (BatchNormalizatio (None, 112, 112, 64) 256         decoder1_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation1 (PReLU)    (None, 112, 112, 64) 802816      decoder1_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 112, 112, 64) 0           decoder1_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv2 (Conv2D)         (None, 112, 112, 32) 18464       dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn2 (BatchNormalizatio (None, 112, 112, 32) 128         decoder1_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation2 (PReLU)    (None, 112, 112, 32) 401408      decoder1_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 112, 112, 32) 0           decoder1_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv3 (Conv2D)         (None, 112, 112, 64) 18496       dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn3 (BatchNormalizatio (None, 112, 112, 64) 256         decoder1_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation3 (PReLU)    (None, 112, 112, 64) 802816      decoder1_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 112, 112, 64) 0           decoder1_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 112, 112, 64) 0           dropout_13[0][0]                 \n",
            "                                                                 dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2D)  (None, 224, 224, 64) 0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 224, 224, 128 0           up_sampling2d_4[0][0]            \n",
            "                                                                 block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 36896       concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 224, 224, 32) 0           dropout_16[0][0]                 \n",
            "                                                                 dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "prediction (Conv2D)             (None, 224, 224, 1)  33          add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 224, 224, 1)  0           prediction[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 31,029,489\n",
            "Trainable params: 31,024,209\n",
            "Non-trainable params: 5,280\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Train on 3196 samples, validate on 804 samples\n",
            "Epoch 1/2\n",
            "3196/3196 [==============================] - 351s 110ms/step - loss: 0.9061 - my_iou_metric: 0.1488 - val_loss: 1.8767 - val_my_iou_metric: 0.1504\n",
            "\n",
            "Epoch 00001: val_my_iou_metric improved from -inf to 0.15037, saving model to unet_resnet.h5\n",
            "Epoch 2/2\n",
            "3196/3196 [==============================] - 335s 105ms/step - loss: 0.7924 - my_iou_metric: 0.2292 - val_loss: 0.9970 - val_my_iou_metric: 0.3357\n",
            "\n",
            "Epoch 00002: val_my_iou_metric improved from 0.15037 to 0.33570, saving model to unet_resnet.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FvQ0WZ_mEtt4"
      },
      "source": [
        "### Validation set prediction and resizing to original size:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ul4G_LrTEtt4",
        "colab": {}
      },
      "source": [
        "val_preds = model_depth.predict(X_val, batch_size=8)\n",
        "\n",
        "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
        "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QWdfu8iREtt8"
      },
      "source": [
        "### Threshold optimization: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pQBvaTs2Ett8",
        "colab": {}
      },
      "source": [
        "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
        "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
        "    labels = y_true_in\n",
        "    y_pred = y_pred_in\n",
        "    \n",
        "    true_objects = 2\n",
        "    pred_objects = 2\n",
        "\n",
        "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
        "\n",
        "    # Compute areas (needed for finding the union between all objects)\n",
        "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
        "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
        "    area_true = np.expand_dims(area_true, -1)\n",
        "    area_pred = np.expand_dims(area_pred, 0)\n",
        "\n",
        "    # Compute union\n",
        "    union = area_true + area_pred - intersection\n",
        "\n",
        "    # Exclude background from the analysis\n",
        "    intersection = intersection[1:,1:]\n",
        "    union = union[1:,1:]\n",
        "    union[union == 0] = 1e-9\n",
        "\n",
        "    # Compute the intersection over union\n",
        "    iou = intersection / union\n",
        "\n",
        "    # Precision helper function\n",
        "    def precision_at(threshold, iou):\n",
        "        matches = iou > threshold\n",
        "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
        "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
        "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
        "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
        "        return tp, fp, fn\n",
        "\n",
        "    # Loop over IoU thresholds\n",
        "    prec = []\n",
        "    if print_table:\n",
        "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
        "    for t in np.arange(0.5, 1.0, 0.05):\n",
        "        tp, fp, fn = precision_at(t, iou)\n",
        "        if (tp + fp + fn) > 0:\n",
        "            p = tp / (tp + fp + fn)\n",
        "        else:\n",
        "            p = 0\n",
        "        if print_table:\n",
        "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
        "        prec.append(p)\n",
        "    \n",
        "    if print_table:\n",
        "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
        "    return np.mean(prec)\n",
        "\n",
        "def iou_metric_batch(y_true_in, y_pred_in):\n",
        "    batch_size = y_true_in.shape[0]\n",
        "    metric = []\n",
        "    for batch in range(batch_size):\n",
        "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
        "        metric.append(value)\n",
        "    return np.mean(metric)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KdVPudHWEtt-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1321b883-6368-4cbc-d1f8-91299c49fcaf"
      },
      "source": [
        "# Threshold range, over which optimization is performed\n",
        "thresholds = np.arange(0.2, 0.9, 0.02)\n",
        "\n",
        "# For every threshold, set predictions to binary arrays, \n",
        "# where values above threshold are treated as 1 and the rest as 0.\n",
        "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
        "ious = np.array(\n",
        "    [iou_metric_batch(y_val_true,\n",
        "                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:44<00:00,  1.25s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qDbt2Rt9Ett_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "465a9535-96fa-40f2-d510-b635ff2de60f"
      },
      "source": [
        "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
        "df_iou['iou'] = ious\n",
        "\n",
        "# Get index of best IoU\n",
        "best_index = df_iou['iou'].idxmax()\n",
        "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
        "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
        "\n",
        "# Describe IoU DF\n",
        "df_iou.describe()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best IoU: 0.4286 at threshold: 0.880\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>threshold</th>\n",
              "      <th>iou</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.540000</td>\n",
              "      <td>0.361130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.204939</td>\n",
              "      <td>0.050776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.244403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.370000</td>\n",
              "      <td>0.330100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.540000</td>\n",
              "      <td>0.371269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.710000</td>\n",
              "      <td>0.399316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.428607</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       threshold        iou\n",
              "count  35.000000  35.000000\n",
              "mean    0.540000   0.361130\n",
              "std     0.204939   0.050776\n",
              "min     0.200000   0.244403\n",
              "25%     0.370000   0.330100\n",
              "50%     0.540000   0.371269\n",
              "75%     0.710000   0.399316\n",
              "max     0.880000   0.428607"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6BDfX_HeEtuB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "outputId": "b88f2c46-c8a0-4c08-d5fc-2549e6e6680b"
      },
      "source": [
        "# Plot IoU values over threshold range.\n",
        "df_iou.plot(x='threshold', y='iou')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5fd0307160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtMAAAIaCAYAAADiE8FNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 864x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QaEBD6OVEtuD"
      },
      "source": [
        "## Conclusions:\n",
        "\n",
        "- Pretrained models can be used for segmentation problems:\n",
        "    - Some of architectures can be easily adapted to the problem (ie ResNet)\n",
        "    - Other architectures may require more experimentation with selection of proper layers for feature extraction and padding (example of using [Xception](https://www.kaggle.com/meaninglesslives/getting-0-87-on-private-lb-using-kaggle-kernel). )\n",
        "    - You can experiment with selection of layers for feature extraction\n",
        "    - For some models, you can also try to experiment with number of encoder/decoder blocks\n",
        "- Threshold optimization is important in problems, where direct metric optimization during training is difficult.\n",
        "    - It it possible to use more involved optimization methods (from [scipy optimize](https://docs.scipy.org/doc/scipy/reference/optimize.html)), although this may not be optimal unless distribution of train and test set are very similar. Overoptimization of threshold or any other parameter on validation set may result in worse test set results.\n",
        "- Experiment with various losses - BCE, Dice, combined BCE with Dice, Lovash loss.\n",
        "    - Models trained with various losses may give different results, which may be advantageous when ensembling.\n",
        "\n",
        "\n",
        "### Possible experiments:\n",
        "\n",
        "- Change type of decoder block in created segmentation model\n",
        "- Create your own decoder blocks\n",
        "- Train with other losses\n",
        "- Train longer\n",
        "- Train with BCE/Dice, save the model, then load weights and finetune with Lovash loss\n",
        "- Try different ranges and intervals for threshold optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6cgwWHzFUXB",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}
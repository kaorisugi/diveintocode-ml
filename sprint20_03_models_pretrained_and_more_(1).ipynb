{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "03-models_pretrained_and_more (1).ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaorisugi/diveintocode-ml/blob/master/sprint20_03_models_pretrained_and_more_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvXXlmKbAmWj",
        "colab_type": "code",
        "outputId": "85fad317-d561-4b6e-d57e-673008c75e0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMIuPNXiZe2n",
        "colab_type": "text"
      },
      "source": [
        "# sprint20 セグメンテーション２"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DvtecjtB6kk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv \"/content/drive/My Drive/Colab Notebooks/03-models_pretrained_and_more (1).ipynb\" \"/content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovBDdNHfCWa6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv \"/content/drive/My Drive/Colab Notebooks/clean-workflow-in-keras (1).ipynb\" \"/content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHxbS_JJCqAQ",
        "colab_type": "code",
        "outputId": "2acdab8c-e09f-486d-8f31-62de039a58fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd \"/content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gc_zMC6ppW42",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir .kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NLc1BpPze-Q",
        "colab_type": "code",
        "outputId": "943abde1-b515-44a0-e1e3-db6db1851380",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!ls -a"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'03-models_pretrained_and_more (1).ipynb'   .kaggle\n",
            "'clean-workflow-in-keras (1).ipynb'\t    kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zI-Y6U5Czqsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv \"/content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20/kaggle.json\" \"/content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20/.kaggle\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IDhP0eCq6SS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv \"/content/kaggle.json\" \"/content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0Y_I8q2pzOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!chmod 600 \"/content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20/.kaggle/kaggle.json\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaFsCnWHqPsH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "\n",
        "token = {'username':'kaorisugi','key':'def696cfe4d461409a7f8be05a5941fa'}\n",
        "with open('/content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tl7lg5tG0kKz",
        "colab_type": "code",
        "outputId": "a69d56ae-2e3c-4d3d-fe96-d78b457a44a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /root"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uza4fgWFqPp6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp .kaggle/kaggle.json /root/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4bo_wOHqPnA",
        "colab_type": "code",
        "outputId": "4db3bee4-c56c-4e7c-9aae-70a5832d4dc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "!kaggle competitions download -c tgs-salt-identification-challenge"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading depths.csv to /content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20\n",
            "  0% 0.00/322k [00:00<?, ?B/s]\n",
            "100% 322k/322k [00:00<00:00, 22.0MB/s]\n",
            "Downloading sample_submission.csv to /content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20\n",
            "  0% 0.00/264k [00:00<?, ?B/s]\n",
            "100% 264k/264k [00:00<00:00, 36.3MB/s]\n",
            "Downloading train.csv to /content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20\n",
            "  0% 0.00/922k [00:00<?, ?B/s]\n",
            "100% 922k/922k [00:00<00:00, 60.4MB/s]\n",
            "Downloading test.zip to /content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20\n",
            " 95% 155M/163M [00:02<00:00, 66.0MB/s]\n",
            "100% 163M/163M [00:02<00:00, 62.9MB/s]\n",
            "Downloading train.zip to /content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20\n",
            " 95% 36.0M/37.9M [00:00<00:00, 49.5MB/s]\n",
            "100% 37.9M/37.9M [00:00<00:00, 94.7MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjV3nUcN1D7V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip \"/content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20/train.zip\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXEE5qyG1nd3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip \"/content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20/test.zip\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sd-KfI472kOd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv \"/content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20/train.csv\" \"/content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20/input\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-38I6CtP2vYM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv \"/content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20/depths.csv\" \"/content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20/input\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OaVwL212-UQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv \"/content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20/sample_submission.csv\" \"/content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20/input\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_B0KYbve_zZq",
        "colab_type": "text"
      },
      "source": [
        "## Model architecture tuning & score optimization\n",
        "\n",
        "\n",
        "Some ideas and code taken from ealier [kernel](https://www.kaggle.com/wrosinski/clean-workflow-in-keras) and last prepared notebook.\n",
        "\n",
        "Having dealt with data processing & engineering of channel features, next step of modeling is preparation and tuning of model architecture. Earlier notebooks provided a way to create images with three channels, which will facilitate usage of pretrained models.\n",
        "\n",
        "For segmentation tasks, a pretrained model can be used as encoder part of the final architecture. \n",
        "In order to use pretrained models, we will have to extract features from a few intermediate layers, which will then serve as a basis for layers coming afterwards and for skip connections between encoder and decoder part.\n",
        "\n",
        "ResNet50 is a good starting point, because it consists of 4 blocks, where each one of them can serve as feature extractor with first layer serving as the 5th extractor to achieve consistency with standard UNet architecture."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaFUUL6o_zZr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gc\n",
        "import glob\n",
        "import os\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from tqdm import tqdm\n",
        "\n",
        "from keras import optimizers\n",
        "from keras.callbacks import *\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.layers import *\n",
        "from keras.models import Model, load_model, save_model\n",
        "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
        "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHj6cbSD_zZu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.rcParams['figure.figsize'] = (12, 9)\n",
        "# plt.style.use('ggplot')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfejRvXZ_zZw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_coverage(df, masks):\n",
        "    \n",
        "    df = df.copy()\n",
        "    \n",
        "    def cov_to_class(val):\n",
        "        for i in range(0, 11):\n",
        "            if val * 10 <= i:\n",
        "                return i\n",
        "\n",
        "    # Output percentage of area covered by class（クラスがカバーする面積の出力割合）\n",
        "    df['coverage'] = np.mean(masks, axis=(1, 2))\n",
        "    # Coverage must be split into bins, otherwise stratified split will not be possible,\n",
        "    # because each coverage will occur only once.\n",
        "    #カバレッジはビンに分割する必要があります。そうしないと、階層化された分割が不可能になります。\n",
        "    #各カバレッジが1回だけ発生するため。\n",
        "    df['coverage_class'] = df.coverage.map(\n",
        "        cov_to_class)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def create_depth_abs_channels(image_tensor):\n",
        "    image_tensor = image_tensor.astype(np.float32) #画像をテンソル形式に変換\n",
        "    h, w, c = image_tensor.shape\n",
        "    for row, const in enumerate(np.linspace(0, 1, h)):\n",
        "        image_tensor[row, :, 1] = const\n",
        "    image_tensor[:, :, 2] = (\n",
        "        image_tensor[:, :, 0] * image_tensor[:, :, 1])\n",
        "\n",
        "    x_dx = np.diff(image_tensor[:, :, 0], axis=0)\n",
        "    x_dy = np.diff(image_tensor[:, :, 0], axis=1)\n",
        "    x_dx = cv2.copyMakeBorder(x_dx, 1, 0, 0, 0, cv2.BORDER_CONSTANT, 0)\n",
        "    x_dy = cv2.copyMakeBorder(x_dy, 0, 0, 1, 0, cv2.BORDER_CONSTANT, 0)\n",
        "    image_tensor[:, :, 1] = np.abs(x_dx + x_dy)\n",
        "\n",
        "    return image_tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4djhczC_zZx",
        "colab_type": "text"
      },
      "source": [
        "### Data loading & depth merge:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-icqnJYr_zZy",
        "colab_type": "code",
        "outputId": "99f27906-042f-4a57-d4e7-5f576d6fbd1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "train = pd.read_csv('/content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20/input/train.csv')\n",
        "test = pd.read_csv('/content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20/input/sample_submission.csv')\n",
        "depth = pd.read_csv('/content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20/input/depths.csv')\n",
        "\n",
        "train_src = '../input/train/'\n",
        "\n",
        "print('train:\\n{}'.format(train.head()))\n",
        "print('\\ntest:\\n{}'.format(test.head()))\n",
        "\n",
        "\n",
        "train = train.merge(depth, how='left', on='id')\n",
        "test = test.merge(depth, how='left', on='id')\n",
        "\n",
        "print('\\n{}'.format(train.head()))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train:\n",
            "           id                                           rle_mask\n",
            "0  575d24d81d                                                NaN\n",
            "1  a266a2a9df                                          5051 5151\n",
            "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...\n",
            "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...\n",
            "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...\n",
            "\n",
            "test:\n",
            "           id rle_mask\n",
            "0  155410d6fa      1 1\n",
            "1  78b32781d1      1 1\n",
            "2  63db2a476a      1 1\n",
            "3  17bfcdb967      1 1\n",
            "4  7ea0fd3c88      1 1\n",
            "\n",
            "           id                                           rle_mask    z\n",
            "0  575d24d81d                                                NaN  843\n",
            "1  a266a2a9df                                          5051 5151  794\n",
            "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...  468\n",
            "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...  727\n",
            "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...  797\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChR8xybw_zZ0",
        "colab_type": "text"
      },
      "source": [
        "### Load images and masks, examine random sample:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOAYUaiN_zZ0",
        "colab_type": "code",
        "outputId": "e76db5ab-97ed-434f-ff45-27208f3cd16a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#画像が保存してあるパスを指定して直接np.arrayを作る\n",
        "X_train = np.asarray(\n",
        "    [cv2.imread('/content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20/images/{}.png'.format(x), 0) for x in train.id.tolist()], \n",
        "    dtype=np.uint8) / 255.\n",
        "y_train = np.asarray(\n",
        "    [cv2.imread('/content/drive/My Drive/Colab Notebooks/DIVE/kadai/sprint20/masks/{}.png'.format(x), 0) for x in train.id.tolist()],\n",
        "    dtype=np.uint8) / 255.\n",
        "\n",
        "print(X_train.shape, y_train.shape)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4000, 101, 101) (4000, 101, 101)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "jfXs876a_zZ2",
        "colab_type": "code",
        "outputId": "18f4565a-3ae3-4120-fad6-348b3d338b43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        }
      },
      "source": [
        "random_index = np.random.randint(0, X_train.shape[0])\n",
        "\n",
        "fig, ax = plt.subplots(1, 2)\n",
        "\n",
        "ax[0].imshow(X_train[random_index], cmap='gray')\n",
        "ax[1].imshow(y_train[random_index], cmap='gray')"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fc0cbb88588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs0AAAFTCAYAAADCyzEvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRvj/AbHE/dNPNQ62AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Xl9Ozlq_zZ4",
        "colab_type": "text"
      },
      "source": [
        "### Compute salt coverage (this will serve as a basis for stratified split):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AslhGujz_zZ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = compute_coverage(train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHSQQxhb_zZ7",
        "colab_type": "text"
      },
      "source": [
        "### Prepare data for training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-zr_oUK_zZ7",
        "colab_type": "code",
        "outputId": "3f8e2df9-9136-450c-a7f8-68cc84ac3f1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "\n",
        "kfold = StratifiedKFold(n_splits=5, random_state=1337)\n",
        "\n",
        "# Add channel features\n",
        "X_train_ch = np.repeat(np.expand_dims(X_train, axis=-1), 3, -1)#一番最後の軸を指定して\n",
        "X_train_ch = np.asarray(list(map(lambda x: create_depth_abs_channels(x), X_train_ch)))\n",
        "\n",
        "# Resize to 224x224, default ResNet50 image size\n",
        "X_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), X_train_ch)))\n",
        "y_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), y_train)))\n",
        "\n",
        "\n",
        "for train_index, valid_index in kfold.split(train.id.values, train.coverage_class.values):\n",
        "    \n",
        "    X_tr, X_val = X_resized[train_index], X_resized[valid_index]\n",
        "    y_tr, y_val = y_resized[train_index], y_resized[valid_index]\n",
        "    \n",
        "    break\n",
        "    \n",
        "\n",
        "y_tr = np.expand_dims(y_tr, axis=-1)\n",
        "y_val = np.expand_dims(y_val, axis=-1)\n",
        "\n",
        "print(X_tr.shape, y_tr.shape)\n",
        "print(X_val.shape, y_val.shape)\n",
        "\n",
        "\n",
        "del X_train_ch, y_resized\n",
        "del X_resized\n",
        "gc.collect()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3196, 224, 224, 3) (3196, 224, 224, 1)\n",
            "(804, 224, 224, 3) (804, 224, 224, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "94"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Admj7pGi_zZ9",
        "colab_type": "text"
      },
      "source": [
        "### Loss functions & metric:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUtP23gJ_zZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.losses import binary_crossentropy\n",
        "\n",
        "\n",
        "# Dice & combined\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred = K.cast(y_pred, 'float32')\n",
        "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
        "    intersection = y_true_f * y_pred_f\n",
        "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
        "    return score\n",
        "\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = y_true_f * y_pred_f\n",
        "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "    return 1. - score\n",
        "\n",
        "\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
        "\n",
        "\n",
        "def bce_logdice_loss(y_true, y_pred):\n",
        "    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n",
        "\n",
        "\n",
        "\n",
        "# Lovash loss: https://github.com/bermanmaxim/LovaszSoftmax\n",
        "def lovasz_grad(gt_sorted):\n",
        "    \"\"\"\n",
        "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
        "    See Alg. 1 in paper\n",
        "    \"\"\"\n",
        "    gts = tf.reduce_sum(gt_sorted)\n",
        "    intersection = gts - tf.cumsum(gt_sorted)\n",
        "    union = gts + tf.cumsum(1. - gt_sorted)\n",
        "    jaccard = 1. - intersection / union\n",
        "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
        "    return jaccard\n",
        "\n",
        "\n",
        "# --------------------------- BINARY LOSSES ---------------------------\n",
        "\n",
        "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
        "    \"\"\"\n",
        "    Binary Lovasz hinge loss\n",
        "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
        "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
        "      per_image: compute the loss per image instead of per batch\n",
        "      ignore: void class id\n",
        "    \"\"\"\n",
        "    if per_image:\n",
        "        def treat_image(log_lab):\n",
        "            log, lab = log_lab\n",
        "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
        "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
        "            return lovasz_hinge_flat(log, lab)\n",
        "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
        "        loss = tf.reduce_mean(losses)\n",
        "    else:\n",
        "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
        "    return loss\n",
        "\n",
        "\n",
        "def lovasz_hinge_flat(logits, labels):\n",
        "    \"\"\"\n",
        "    Binary Lovasz hinge loss\n",
        "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
        "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
        "      ignore: label to ignore\n",
        "    \"\"\"\n",
        "\n",
        "    def compute_loss():\n",
        "        labelsf = tf.cast(labels, logits.dtype)\n",
        "        signs = 2. * labelsf - 1.\n",
        "        errors = 1. - logits * tf.stop_gradient(signs)\n",
        "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
        "        gt_sorted = tf.gather(labelsf, perm)\n",
        "        grad = lovasz_grad(gt_sorted)\n",
        "        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
        "        return loss\n",
        "\n",
        "    # deal with the void prediction case (only void pixels)\n",
        "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
        "                   lambda: tf.reduce_sum(logits) * 0.,\n",
        "                   compute_loss,\n",
        "                   strict=True,\n",
        "                   name=\"loss\"\n",
        "                   )\n",
        "    return loss\n",
        "\n",
        "\n",
        "def flatten_binary_scores(scores, labels, ignore=None):\n",
        "    \"\"\"\n",
        "    Flattens predictions in the batch (binary case)\n",
        "    Remove labels equal to 'ignore'\n",
        "    \"\"\"\n",
        "    scores = tf.reshape(scores, (-1,))\n",
        "    labels = tf.reshape(labels, (-1,))\n",
        "    if ignore is None:\n",
        "        return scores, labels\n",
        "    valid = tf.not_equal(labels, ignore)\n",
        "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
        "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
        "    return vscores, vlabels\n",
        "\n",
        "\n",
        "def lovasz_loss(y_true, y_pred):\n",
        "    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n",
        "    #logits = K.log(y_pred / (1. - y_pred))\n",
        "    logits = y_pred #Jiaxin\n",
        "    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n",
        "    return loss\n",
        "\n",
        "\n",
        "# IoU metric for observation during training\n",
        "# https://www.kaggle.com/cpmpml/fast-iou-metric-in-numpy-and-tensorflow\n",
        "def get_iou_vector(A, B):\n",
        "    # Numpy version    \n",
        "    batch_size = A.shape[0]\n",
        "    metric = 0.0\n",
        "    for batch in range(batch_size):\n",
        "        t, p = A[batch], B[batch]\n",
        "        true = np.sum(t)\n",
        "        pred = np.sum(p)\n",
        "        \n",
        "        # deal with empty mask first\n",
        "        if true == 0:\n",
        "            metric += (pred == 0)\n",
        "            continue\n",
        "        \n",
        "        # non empty mask case.  Union is never empty \n",
        "        # hence it is safe to divide by its number of pixels\n",
        "        intersection = np.sum(t * p)\n",
        "        union = true + pred - intersection\n",
        "        iou = intersection / union\n",
        "        \n",
        "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
        "        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
        "        \n",
        "        metric += iou\n",
        "        \n",
        "    # teake the average over all images in batch\n",
        "    metric /= batch_size\n",
        "    return metric\n",
        "\n",
        "\n",
        "def my_iou_metric(label, pred):\n",
        "    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n",
        "\n",
        "\n",
        "# For Lovash loss\n",
        "def my_iou_metric_2(label, pred):\n",
        "    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnVX39Gu_8CE",
        "colab_type": "text"
      },
      "source": [
        "## これをVGGに書き換える"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7PXgX4v_zaB",
        "colab_type": "text"
      },
      "source": [
        "### Encoder features - ResNet50:\n",
        "\n",
        "In ResNet50, each block finishes with a pooling layer, so we can extract features from intermediate layers just before the pooling. This way, when first layer is added as additional extractor, we will have features extracted from 5 layers.\n",
        "Default input size will be assumed, which is (224, 224, 3).\n",
        "Layers will be as follows:\n",
        "\n",
        "- 'activation_1', shape: (None, 112, 112, 64)\n",
        "- 'activation_10', shape: (None, 56, 56, 256)\n",
        "- 'activation_22', shape: (None, 28, 28, 512)\n",
        "- 'activation_40', shape: (None, 14, 14, 1024)\n",
        "- 'activation_49', shape: (None, 7, 7, 2048)\n",
        "\n",
        "One thing to keep in mind is that every time a model will be created in the same TF session in the notebook, layer names will change, so above layer names correspond to first creation of the model. In order to reset session, call `K.clear_session()`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwFzEy_b_zaD",
        "colab_type": "text"
      },
      "source": [
        "### Decoder blocks:\n",
        "\n",
        "Features from ResNet50 will serve as a basis for encoder part of the segmentation model, now a decoder part is needed.\n",
        "For this part, we will have to create our own blocks. Let's create a very basic block and a second one, which structure will have a more complicated structure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIJSRGOn_zaE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Basic decoder block with Conv, BN and PReLU activation.\n",
        "def decoder_block_simple(\n",
        "        layer_name, block_name,\n",
        "        num_filters=32,\n",
        "        conv_dim=(3, 3)):\n",
        "\n",
        "    x_dec = Conv2D(\n",
        "        num_filters, conv_dim,\n",
        "        padding='same',\n",
        "        name='{}_conv'.format(block_name))(layer_name)\n",
        "    x_dec = BatchNormalization(\n",
        "        name='{}_bn'.format(block_name))(x_dec)\n",
        "    x_dec = PReLU(\n",
        "        name='{}_activation'.format(block_name))(x_dec)\n",
        "\n",
        "    return x_dec\n",
        "\n",
        "# Decoder block with bottleneck architecture, where middle conv layer\n",
        "# is half the size of first and last, in order to compress representation.\n",
        "# This type of architecture is supposed to retain most useful information.\n",
        "def decoder_block_bottleneck(\n",
        "        layer_name, block_name,\n",
        "        num_filters=32,\n",
        "        conv_dim=(3, 3),\n",
        "        dropout_frac=0.2):\n",
        "\n",
        "    x_dec = Conv2D(\n",
        "        num_filters, conv_dim,\n",
        "        padding='same',\n",
        "        name='{}_conv1'.format(block_name))(layer_name)\n",
        "    x_dec = BatchNormalization(\n",
        "        name='{}_bn1'.format(block_name))(x_dec)\n",
        "    x_dec = PReLU(\n",
        "        name='{}_activation1'.format(block_name))(x_dec)\n",
        "    x_dec = Dropout(dropout_frac)(x_dec)\n",
        "\n",
        "    x_dec2 = Conv2D(\n",
        "        num_filters // 2, conv_dim,\n",
        "        padding='same',\n",
        "        name='{}_conv2'.format(block_name))(x_dec)\n",
        "    x_dec2 = BatchNormalization(\n",
        "        name='{}_bn2'.format(block_name))(x_dec2)\n",
        "    x_dec2 = PReLU(\n",
        "        name='{}_activation2'.format(block_name))(x_dec2)\n",
        "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
        "\n",
        "    x_dec2 = Conv2D(\n",
        "        num_filters, conv_dim,\n",
        "        padding='same',\n",
        "        name='{}_conv3'.format(block_name))(x_dec2)\n",
        "    x_dec2 = BatchNormalization(\n",
        "        name='{}_bn3'.format(block_name))(x_dec2)\n",
        "    x_dec2 = PReLU(\n",
        "        name='{}_activation3'.format(block_name))(x_dec2)\n",
        "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
        "\n",
        "    x_dec2 = Add()([x_dec, x_dec2])\n",
        "\n",
        "    return x_dec2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tC-VuFr_zaG",
        "colab_type": "text"
      },
      "source": [
        "### Model definition:\n",
        "\n",
        "Combine encoder and decoder blocks to create final segmentation model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olXwo4kU_zaG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model is parametrized in a way to enable easy change of decoder_block type,\n",
        "# as this is an argument that can be given a function, like decoder_block_simple.\n",
        "def unet_resnet(input_size, decoder_block,\n",
        "                weights='imagenet',\n",
        "                loss_func='binary_crossentropy',\n",
        "                metrics_list=[my_iou_metric],\n",
        "                use_lovash=False):\n",
        "\n",
        "    # Base model - encoder\n",
        "    base_model = ResNet50(\n",
        "        input_shape=input_size, \n",
        "        include_top=False,\n",
        "        weights=weights)\n",
        "    \n",
        "    print(base_model.summary())\n",
        "\n",
        "\n",
        "    # Layers for feature extraction in the encoder part\n",
        "    encoder1 = base_model.get_layer('activation_1').output\n",
        "    encoder2 = base_model.get_layer('activation_10').output\n",
        "    encoder3 = base_model.get_layer('activation_22').output\n",
        "    encoder4 = base_model.get_layer('activation_40').output\n",
        "    encoder5 = base_model.get_layer('activation_49').output\n",
        "\n",
        "    # Center block\n",
        "    center = decoder_block(\n",
        "        encoder5, 'center', num_filters=512)\n",
        "    concat5 = concatenate([center, encoder5], axis=-1)\n",
        "\n",
        "    # Decoder part.\n",
        "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
        "    # This creates skip connections.\n",
        "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
        "    decoder4 = decoder_block(\n",
        "        concat5, 'decoder4', num_filters=256)\n",
        "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
        "\n",
        "    decoder3 = decoder_block(\n",
        "        concat4, 'decoder3', num_filters=128)\n",
        "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
        "\n",
        "    decoder2 = decoder_block(\n",
        "        concat3, 'decoder2', num_filters=64)\n",
        "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
        "\n",
        "    decoder1 = decoder_block(\n",
        "        concat2, 'decoder1', num_filters=64)\n",
        "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
        "\n",
        "    # Final upsampling and decoder block for segmentation.\n",
        "    output = UpSampling2D()(concat1)\n",
        "    output = decoder_block(\n",
        "        output, 'decoder_output', num_filters=32)\n",
        "    output = Conv2D(\n",
        "        1, (1, 1), activation=None, name='prediction')(output)\n",
        "    if not use_lovash:\n",
        "        output = Activation('sigmoid')(output)\n",
        "        \n",
        "    model = Model(base_model.input, output)\n",
        "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsnG2-y7_zaI",
        "colab_type": "text"
      },
      "source": [
        "### Inspect created model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "7w-sbg2R_zaJ",
        "colab_type": "code",
        "outputId": "e4b43dbf-4036-478d-a83b-8b8caabad0fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "input_size = (224, 224, 3)\n",
        "\n",
        "\n",
        "K.clear_session()\n",
        "model = unet_resnet(\n",
        "    input_size, decoder_block_simple, weights='imagenet')\n",
        "model.summary()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:107: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:111: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94658560/94653016 [==============================] - 3s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From <ipython-input-61-910567864b2d>:153: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "center_conv (Conv2D)            (None, 7, 7, 512)    9437696     activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "center_bn (BatchNormalization)  (None, 7, 7, 512)    2048        center_conv[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "center_activation (PReLU)       (None, 7, 7, 512)    25088       center_bn[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 7, 7, 2560)   0           center_activation[0][0]          \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv (Conv2D)          (None, 7, 7, 256)    5898496     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn (BatchNormalization (None, 7, 7, 256)    1024        decoder4_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation (PReLU)     (None, 7, 7, 256)    12544       decoder4_bn[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           decoder4_activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 14, 14, 1280) 0           up_sampling2d_1[0][0]            \n",
            "                                                                 activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv (Conv2D)          (None, 14, 14, 128)  1474688     concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn (BatchNormalization (None, 14, 14, 128)  512         decoder3_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation (PReLU)     (None, 14, 14, 128)  25088       decoder3_bn[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           decoder3_activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
            "                                                                 activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv (Conv2D)          (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn (BatchNormalization (None, 28, 28, 64)   256         decoder2_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation (PReLU)     (None, 28, 28, 64)   50176       decoder2_bn[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           decoder2_activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
            "                                                                 activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv (Conv2D)          (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn (BatchNormalization (None, 56, 56, 64)   256         decoder1_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation (PReLU)     (None, 56, 56, 64)   200704      decoder1_bn[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           decoder1_activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
            "                                                                 activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv (Conv2D)    (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn (BatchNormali (None, 224, 224, 32) 128         decoder_output_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation (PReL (None, 224, 224, 32) 1605632     decoder_output_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "prediction (Conv2D)             (None, 224, 224, 1)  33          decoder_output_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 224, 224, 1)  0           prediction[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 42,912,065\n",
            "Trainable params: 42,856,833\n",
            "Non-trainable params: 55,232\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wy9xwGTn_zaL",
        "colab_type": "text"
      },
      "source": [
        "### Train model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "zXoiMTSH_zaM",
        "colab_type": "code",
        "outputId": "d8f8523c-00d8-43f3-cfcc-7782caae4142",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "K.clear_session()\n",
        "\n",
        "# Build model:\n",
        "# Here, you can experiment with various losses.\n",
        "# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n",
        "# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n",
        "# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n",
        "# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n",
        "# This is controlled by use_lovash parameter.\n",
        "model_depth = unet_resnet(\n",
        "    input_size, decoder_block_bottleneck, weights='imagenet',\n",
        "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
        "    use_lovash=False)\n",
        "print(model_depth.summary())\n",
        "\n",
        "\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    'unet_resnet.h5' ,monitor='val_my_iou_metric', mode='max',\n",
        "    save_best_only=True, save_weights_only=True, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_my_iou_metric',\n",
        "    mode='max',\n",
        "    factor=0.5, \n",
        "    patience=5, \n",
        "    min_lr=0.0001, \n",
        "    verbose=1)\n",
        "\n",
        "\n",
        "epochs = 2  # 25\n",
        "batch_size = 16\n",
        "\n",
        "history = model_depth.fit(X_tr, y_tr,\n",
        "                    validation_data=[X_val, y_val], \n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    callbacks=[model_checkpoint,reduce_lr], \n",
        "                    verbose=1)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "center_conv1 (Conv2D)           (None, 7, 7, 512)    9437696     activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "center_bn1 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_activation1 (PReLU)      (None, 7, 7, 512)    25088       center_bn1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 7, 7, 512)    0           center_activation1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "center_conv2 (Conv2D)           (None, 7, 7, 256)    1179904     dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "center_bn2 (BatchNormalization) (None, 7, 7, 256)    1024        center_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_activation2 (PReLU)      (None, 7, 7, 256)    12544       center_bn2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 7, 7, 256)    0           center_activation2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "center_conv3 (Conv2D)           (None, 7, 7, 512)    1180160     dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "center_bn3 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_activation3 (PReLU)      (None, 7, 7, 512)    25088       center_bn3[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 7, 7, 512)    0           center_activation3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 7, 7, 512)    0           dropout_1[0][0]                  \n",
            "                                                                 dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 7, 7, 2560)   0           add_17[0][0]                     \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv1 (Conv2D)         (None, 7, 7, 256)    5898496     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn1 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation1 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv2 (Conv2D)         (None, 7, 7, 128)    295040      dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn2 (BatchNormalizatio (None, 7, 7, 128)    512         decoder4_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation2 (PReLU)    (None, 7, 7, 128)    6272        decoder4_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 7, 7, 128)    0           decoder4_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv3 (Conv2D)         (None, 7, 7, 256)    295168      dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn3 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation3 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 7, 7, 256)    0           dropout_4[0][0]                  \n",
            "                                                                 dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 14, 14, 1280) 0           up_sampling2d_1[0][0]            \n",
            "                                                                 activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv1 (Conv2D)         (None, 14, 14, 128)  1474688     concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn1 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation1 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv2 (Conv2D)         (None, 14, 14, 64)   73792       dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn2 (BatchNormalizatio (None, 14, 14, 64)   256         decoder3_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation2 (PReLU)    (None, 14, 14, 64)   12544       decoder3_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 14, 14, 64)   0           decoder3_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv3 (Conv2D)         (None, 14, 14, 128)  73856       dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn3 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation3 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 14, 14, 128)  0           dropout_7[0][0]                  \n",
            "                                                                 dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
            "                                                                 activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv1 (Conv2D)         (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn1 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation1 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv2 (Conv2D)         (None, 28, 28, 32)   18464       dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn2 (BatchNormalizatio (None, 28, 28, 32)   128         decoder2_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation2 (PReLU)    (None, 28, 28, 32)   25088       decoder2_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 28, 28, 32)   0           decoder2_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv3 (Conv2D)         (None, 28, 28, 64)   18496       dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn3 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation3 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 28, 28, 64)   0           dropout_10[0][0]                 \n",
            "                                                                 dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
            "                                                                 activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv1 (Conv2D)         (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn1 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation1 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv2 (Conv2D)         (None, 56, 56, 32)   18464       dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn2 (BatchNormalizatio (None, 56, 56, 32)   128         decoder1_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation2 (PReLU)    (None, 56, 56, 32)   100352      decoder1_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 56, 56, 32)   0           decoder1_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv3 (Conv2D)         (None, 56, 56, 64)   18496       dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn3 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation3 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 56, 56, 64)   0           dropout_13[0][0]                 \n",
            "                                                                 dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
            "                                                                 activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 224, 224, 32) 0           dropout_16[0][0]                 \n",
            "                                                                 dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "prediction (Conv2D)             (None, 224, 224, 1)  33          add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 224, 224, 1)  0           prediction[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 48,978,353\n",
            "Trainable params: 48,919,953\n",
            "Non-trainable params: 58,400\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Train on 3196 samples, validate on 804 samples\n",
            "Epoch 1/2\n",
            "3196/3196 [==============================] - 7947s 2s/step - loss: 0.7731 - my_iou_metric: 0.3150 - val_loss: 1.4469 - val_my_iou_metric: 0.4756\n",
            "\n",
            "Epoch 00001: val_my_iou_metric improved from -inf to 0.47562, saving model to unet_resnet.h5\n",
            "Epoch 2/2\n",
            "3196/3196 [==============================] - 7789s 2s/step - loss: 0.6084 - my_iou_metric: 0.4766 - val_loss: 1.3371 - val_my_iou_metric: 0.5019\n",
            "\n",
            "Epoch 00002: val_my_iou_metric improved from 0.47562 to 0.50187, saving model to unet_resnet.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wCL16pt_zaO",
        "colab_type": "text"
      },
      "source": [
        "### Validation set prediction and resizing to original size:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OisVZ_Vg_zaP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_preds = model_depth.predict(X_val, batch_size=16)\n",
        "\n",
        "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
        "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Opt11xKi_zaQ",
        "colab_type": "text"
      },
      "source": [
        "### Threshold optimization: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxPHehP8_zaR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
        "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
        "    labels = y_true_in\n",
        "    y_pred = y_pred_in\n",
        "    \n",
        "    true_objects = 2\n",
        "    pred_objects = 2\n",
        "\n",
        "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
        "\n",
        "    # Compute areas (needed for finding the union between all objects)\n",
        "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
        "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
        "    area_true = np.expand_dims(area_true, -1)\n",
        "    area_pred = np.expand_dims(area_pred, 0)\n",
        "\n",
        "    # Compute union\n",
        "    union = area_true + area_pred - intersection\n",
        "\n",
        "    # Exclude background from the analysis\n",
        "    intersection = intersection[1:,1:]\n",
        "    union = union[1:,1:]\n",
        "    union[union == 0] = 1e-9\n",
        "\n",
        "    # Compute the intersection over union\n",
        "    iou = intersection / union\n",
        "\n",
        "    # Precision helper function\n",
        "    def precision_at(threshold, iou):\n",
        "        matches = iou > threshold\n",
        "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
        "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
        "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
        "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
        "        return tp, fp, fn\n",
        "\n",
        "    # Loop over IoU thresholds\n",
        "    prec = []\n",
        "    if print_table:\n",
        "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
        "    for t in np.arange(0.5, 1.0, 0.05):\n",
        "        tp, fp, fn = precision_at(t, iou)\n",
        "        if (tp + fp + fn) > 0:\n",
        "            p = tp / (tp + fp + fn)\n",
        "        else:\n",
        "            p = 0\n",
        "        if print_table:\n",
        "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
        "        prec.append(p)\n",
        "    \n",
        "    if print_table:\n",
        "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
        "    return np.mean(prec)\n",
        "\n",
        "def iou_metric_batch(y_true_in, y_pred_in):\n",
        "    batch_size = y_true_in.shape[0]\n",
        "    metric = []\n",
        "    for batch in range(batch_size):\n",
        "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
        "        metric.append(value)\n",
        "    return np.mean(metric)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2VakY9O_zaT",
        "colab_type": "code",
        "outputId": "4f02248f-1229-4727-e8cb-1c78e9b23c3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Threshold range, over which optimization is performed\n",
        "thresholds = np.arange(0.2, 0.9, 0.02)\n",
        "\n",
        "# For every threshold, set predictions to binary arrays, \n",
        "# where values above threshold are treated as 1 and the rest as 0.\n",
        "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
        "ious = np.array(\n",
        "    [iou_metric_batch(y_val_true,\n",
        "                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:38<00:00,  1.11s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ErPbRjV_zaX",
        "colab_type": "code",
        "outputId": "ed1590c4-ecb9-47e0-8248-85fba0d3b35d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "source": [
        "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
        "df_iou['iou'] = ious\n",
        "\n",
        "# Get index of best IoU\n",
        "best_index = df_iou['iou'].idxmax()\n",
        "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
        "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
        "\n",
        "# Describe IoU DF\n",
        "df_iou.describe()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best IoU: 0.5515 at threshold: 0.660\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>threshold</th>\n",
              "      <th>iou</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.540000</td>\n",
              "      <td>0.537239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.204939</td>\n",
              "      <td>0.015830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.492910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.370000</td>\n",
              "      <td>0.533769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.540000</td>\n",
              "      <td>0.544154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.710000</td>\n",
              "      <td>0.549192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.551493</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       threshold        iou\n",
              "count  35.000000  35.000000\n",
              "mean    0.540000   0.537239\n",
              "std     0.204939   0.015830\n",
              "min     0.200000   0.492910\n",
              "25%     0.370000   0.533769\n",
              "50%     0.540000   0.544154\n",
              "75%     0.710000   0.549192\n",
              "max     0.880000   0.551493"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYUWiaPT_zaa",
        "colab_type": "code",
        "outputId": "812e741d-6f44-4737-e9e3-7cfc30f4d621",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        }
      },
      "source": [
        "# Plot IoU values over threshold range.\n",
        "df_iou.plot(x='threshold', y='iou')"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc0ce733550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAswAAAIaCAYAAAA0thsoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xl8lNWhxvHnZLJvBLJAFiBhCxAW\ngbC7gNYVxd2q1RattbVqN2trV1trbW9b29tFq9a6tbd1Aa24L4iCIoWAbAlbCIFskA0Ssmdmzv2D\nSJEiBDLJO8vv+/nwIfPOOzPPlDR5PHPOeY21VgAAAACOLszpAAAAAIA/ozADAAAAx0BhBgAAAI6B\nwgwAAAAcA4UZAAAAOAYKMwAAAHAMFGYAAADgGCjMAAAAwDFQmAEAAIBjoDADAAAAxxDudIAjpaSk\n2OzsbKdjAAAAIMitWbOm1lqberzz/K4wZ2dnq6CgwOkYAAAACHLGmF3dOY8pGQAAAMAxUJgBAACA\nY6AwAwAAAMfgd3OYAQAA4B86OztVXl6utrY2p6P0SHR0tLKyshQREXFSj6cwAwAA4KjKy8uVkJCg\n7OxsGWOcjnNSrLWqq6tTeXm5cnJyTuo5mJIBAACAo2pra1NycnLAlmVJMsYoOTm5R6PkFGYAAAB8\nqkAuyx/r6XugMAMAAMBvzZo1y+kIFGYAAAD4rxUrVjgdgcIMAAAA/xUfHy/p4OK9O++8U+PGjdP4\n8eP1zDPPSJLeffddXXjhhYfOv+222/TEE0/4NAO7ZAAAAOC4fvpSoYoqG336nGMzEnX3RXndOvf5\n55/XunXrtH79etXW1mrq1Kk6/fTTfZrn0zDCDAAAAL/3/vvv65prrpHL5dLAgQN1xhlnaPXq1X3y\n2owwAwAA4Li6OxLc18LDw+X1eg/d7o2LrDDCDAAAAL932mmn6ZlnnpHH41FNTY2WLVumadOmaejQ\noSoqKlJ7e7v279+vJUuW+Py1GWEGAACA37v00kv14YcfauLEiTLG6Fe/+pUGDRokSbrqqqs0btw4\n5eTkaNKkST5/bWOt9fmT9kR+fr4tKChwOgYAAEDI27x5s8aMGeN0DJ842nsxxqyx1uYf77FMyQAA\nAACOgcIMAAAAHAOFGQAAADgGFv0BAOAHWjs82rynUYWVjSqqbFBhZaOqG9s1b0K6vjAzW0OSY52O\niBBlrZUxxukYPdLTNXsUZgAA+tj+lg4VVR4sx5u6ynFJTZO8Xb/T+8VEKC8jUQOzovXkilI99sFO\nfWbMQN0wK1szhycHfHlB4IiOjlZdXZ2SkwP3+85aq7q6OkVHR5/0c1CYAQDoJdZa7WlsU2HFwXJc\n2FWOK/a3HjonvV+08jISdcH4dOVlJCovI1GZSTGHysmehjb9feUu/WPVbr1VtFe5AxO0YHa2Ljkl\nUzGRLqfeGkJEVlaWysvLVVNT43SUHomOjlZWVtZJP55t5QAA8JHddS1aX77/UDkuqmxUXXOHJMkY\nKSclTnkZ/Q4V47HpiUqOj+rWc7d1erR4faUe/6BUm6salRQboaunDtHnZw5VRlJMb74tIGh1d1s5\nCjMAoFcVVx9QW6dXcVHhiot0KTYqXLERLoWFBebHu4dr6/RoZUmd3t1ao3e3Vqu0rkWSFOEyGjUw\noasYHyzIY9ITFRfV8w92rbVaXbpPj3+wU28U7pExRufmDdSCWTmamt0/YD82B5zQ3cLMlAwAQK9o\naO3UPS8VadHa8qPeHxvpUmxkuOKjDv4dF/Xx7XDFRroOFuyP7+sq2vFR4UqKiVDuoIRuj8z6Wll9\ni5ZurdbSLdX6sKRObZ1eRUeEadbwFN14ao6mDO2vkWkJigzvnY2ojDGaljNA03IGqHxfi/62cpee\nXlWmVzfuUV5GohbMytZFEzMUHcF0DcBXGGEGAPjc0q3V+t6ijappateXTx+miYOT1NLhVnO7Ry0d\nbjW1e9TS7lZzh0fN7e4j7nOrpet4c4dHHu/Rf099PPd37GFTHA6f++sr7W6PVu/cd7Akb61WSU2z\nJCk7OVZzctM0JzdVM4YlO1pQWzs8euGjCj2xYqe27W1Sclykrp0+RNfNGKqBiSe/0AkIdkzJAAD0\nuca2Tv385c16pqBMI9Pidf9VEzUhK+mkn89aq3a397AC7VbtgQ4VVTV0zRP+5O4SSbERn5gGkZeR\nqJyUeLlOcPpHxf5Wvbu1Wku31GjFjlq1dHgUGR6mGcOSNTc3VXNy05STEnfS76u3WGu1YkedHv+g\nVEu27JXLGF0wPl03zM7WpCH9nY7XZ8rqW7S7vkUzhiWf8L89QotPC7Mx5jxJv5fkkvSotfaXR9y/\nQNKvJVV0HfqTtfbRrvs8kjZ2Hd9trZ1/rNeiMANAYFq+vUbfXbhBexrb9OUzhuvrZ43sk1HXo+1f\nvGXPAXW4vZKkmAiXRqf/Zz7xuIx+GjUoXlHh/8nW4faqYFe93ttao6Vbq7Vtb5MkKat/jObmpmnu\n6FTNHJYSULtS7Kpr1lMf7tKzq8t0oN2tiYOTdOPsbJ0/Lr3Xpos4rcPt1cPv7dAflxarw+3VsNQ4\n3XLGcF0yKVMRruB8z+gZnxVmY4xL0jZJZ0sql7Ra0jXW2qLDzlkgKd9ae9tRHt9krY3vbnAKMwAE\nlqZ2t+57dbP+8e/dGp4ap99cOdHx0cxOj1c7appUWPGffY43VzbqQLtbkhQeZjQiLV55Gf3U3O7W\n+8W1amp3K8JlND0nWXO6RpGHp8YF/CK6pna3nl9bric+KFVJbbPSEqJ03YyhumbaEKUmODMPvDf8\nu6ROP/jXJhVXN2ne+HSdNSZNf1m+U5urGpWZFKOvnDFMV+YPZm43PsGXhXmmpJ9Ya8/tuv09SbLW\n/uKwcxaIwgwAIWdFca3uXLhBlQ2t+tJpw/Sts0f5bSHxeq3K9rV8Yj/kwspGRbrCdEZuquaMStWs\nESmK98FOFv7I67Vatr1GT6wo1btbaxTpCtNFEzN0w+xsjcvs53S8k7avuUO/eG2zni0oV2ZSjO69\nZJzmjk6TdHCKytKt1frTO8Vau3u/UuKj9KXTcvS5GUOD9t8ZJ8aXhfkKSedZa2/qun29pOmHl+Ou\nwvwLSTU6OBr9TWttWdd9bknrJLkl/dJa+69jvR6FGQD8X3O7W798bYv+tnKXclLi9JsrJ2jK0AFO\nx0I37ahp0lMrSvXcmnK1dHg0Nbu/FszK0bl5AxUeIFMXrLV6fm2Ffv7qZjW0duqm03L09bNGKjby\nv4uwtVYrS+r1wNJivV9cq34xEbphdrYWzMpWUmykA+nhL/q6MCdLarLWthtjvizps9baM7vuy7TW\nVhhjhkl6R9JZ1todR7zGzZJulqQhQ4ZM2bVr14m8VwBAH1pZUqc7F65X+b5W3Tg7R98+Jzeg5vbi\nPxrbOvVcQbmeXFGq3fUtSu8XretnDtU1U4eof5z/FsmSmib98F+btGJHnSYNSdJ9l47XmPTEbj12\nXdl+PbC0WG8V7VVcpEvXzRiqL56Wo7QEdhMJRX06JeOI812S6q21//X5jjHmCUkvW2sXftrrMcIM\nAP6ppcOtX72+VU+sKNXQ5Fj9+oqJmpbDqHIw8Hitlm6p1uMrduqD4jpFhYfp0kmZWjA7W6MHda+I\n9oV2t0d/fneHHly6Q1ERYfrueaN17bQhJ3URnC17GvXg0h16eUOlwl1hunrqYN18+jBl9Y/theTw\nV74szOE6OM3iLB3cBWO1pGuttYWHnZNura3q+vpSSd+11s4wxvSX1NI18pwi6UNJFx++YPBIFGYA\n8D+rS+t153PrVVrXogWzsvWd83KP+tE3At/WPQf0xIpSvfBRudo6vZo5LFkLZmfrM2MGOrpF24c7\n6vSDf21USU2zLpqYoR9dOMYno8Kltc3687s79PxH5bJWumRSpm6ZM1zDU7u9/AoBzNfbyl0g6X91\ncFu5x6y1PzfG3COpwFq72BjzC0nzdXCecr2kW6y1W4wxsyQ9LMkrKUzS/1pr/3qs16IwA4D/aOv0\n6NdvbNVjH+xUZlKMfn3FRM0cnux0LPSB/S0denp1mZ5aUarKhjZl9Y/RF2Zm66r8weoXG9FnOeqb\nO/TzVzZr0dpyDR4Qo3svGa8zRqX6/HUq97fqkWUlenr1brW7vbpgfLpunTNCYzP8Z4QdvseFSwAA\nPbJm1z7d+dx6ldQ26/oZQ3XX+aMVx84CIcft8eqtor16/INSrSqtV0yES5dPydSCWdkakZbQa69r\nrdVza8p136ub1dTm1s2nD9PtZ47s9fnytU3t+uv7O/W3D3epqd2tM0en6da5IzRlaOhc+CWUUJgB\nACelrdOj3721TX9ZXqL0fjH61RUTNHtEitOx4Ac2VTToiRWlWryuUh0erwYPiFF2cpxyUuL+83dK\nnLL6x/ToQiHF1U36wQsb9e+d9cof2l/3XTZeowb2Xjk/mobWTj21olSPfbBT+1o6NXNYsm6dO0Kz\nRyQH/N7c+A8KMwDghHm9Vlc/slKrSut1zbQh+v4Fo5UQ3XcfvyMw1Da1a+Gacm2qaNCuuhaV1jYf\nuiiMJLnCjLL6H16mY5XdVaqz+sd86tZ1bZ0ePbi0WH9+b4diIlz63gVj9Nn8wSe1qM9Xmtvd+ueq\n3frL8hLtbWzXxMFJum3uCJ01Os3RXPANCjMA4IQ9u7pM31m0QfddOl7XTh/idBwECGut6po7VFrb\nrJ21zSqta1ZpV5EurW1Wc4fn0LnhYUaDB8QeKtE5KXEamhynTrdXP391s3bWNuuSUzL0g3lj/epK\nhO1ujxauKddD7+1QWX2rRg9K0C1zhuvCCRmOLoZEz1CYAQAnpKGlU3Pvf1fDUuL03Fdm8rEzfMJa\nq5qmdpXWthws0l2Femdti3bVNavlsDKdnRyrey8Zr1NH+u8UILfHq5c2VOqBpTtUXN2k7ORY3TJn\nuC6dlKXI8MC46Av+g8IMADghd7+4SX9buUsv3X6q8jIC91LJCBzWWtUcaNfO2mbta+nQnNw0v720\n+pG8Xqs3i/boT0uLtamiUen9onXz6cN09dQhXMgngFCYAQDdVljZoIv++L6umzFU91w8zuk4QMCw\n1mrZ9lo98E6xVpXWKzkuUl88LUfXzxjK/P8AQGEGAHSLtVZXPvShSmqbtfSOOX26xy4QTFbtrNcD\nS4v13rYaJUSHa8GsbN0wO0cD/Pgy46Guu4WZDTUBIMS98FGFCnbt0/9cPp6yDPTAtJwBmpYzTRvL\nG/TA0mL98Z1iPbp8pz43fYi+dPowDUzs+ZUJ4QxGmAEghDW2derM37ynzP4xeuGWWWyTBfjQ9r0H\n9Od3d+jF9ZVyGaMr8rN0yxnDNXhArNPR0IURZgDAcf3+7e2qa27XYwvyKcuAj40cmKDffvYUfeMz\no/TQsh1aWFCuZ1aX6cIJ6Ro1MEHxUeGKjXQpLir84J9Il2IjwxUX1XUsMlzREWHsWOMHKMwAEKK2\n7jmgJ1aU6uqpQzQhK8npOEDQGpIcq/suHa+vnTlSjy4v0T9X7daL6yq79VhjpLiPS3RkuGK7/o77\nuGxHhmtoSqxunJ0TMDuMBCKmZABACLLW6pq/rNSWPQf0zh1zWJQE9CFrrdrdXjW3u9XS4VFzh1vN\n7W41t3vU0nHw7+aOI263u9XccfD8pna3Wjrcauk6b29ju8Zn9tODn5vMdI8TxJQMAMCnemlDlVaW\n1OveS8ZRloE+ZoxRdIRL0REuJfvg+d4s3KM7nluvC//4vn571USdNWagD54Vh+OSNAAQYprb3fr5\nK0Ual5moa6Zx+Wsg0J2TN0gv336qMpNi9MUnC/Sr17fI7fE6HSuoUJgBIMT84Z3t2tvYrp/OHycX\nC/2AoDA0OU7Pf3WWrpk2WA++u0PX/3WVag60Ox0raFCYASCEFFc36bH3d+rKKVmaMrS/03EA+FB0\nhEu/uGyCfnPlRK3dvU/z/rBcq3bWOx0rKFCYASBEWGv105cKFR3h0nfPH+10HAC95IopWfrXrbMV\nG+nSNX9ZqUeW7ZC/bfIQaCjMABAiXt+0R8u31+qOs0cpJT7K6TgAetGY9EQtvv1UnTN2oO57dYu+\n/Lc1amjtdDpWwKIwA0AIaO3w6GcvF2n0oARdN2Oo03EA9IHE6Ag9+LnJ+tGFY/XOlmrN/9P7Kqxs\ncDpWQKIwA0AIeGBpsSob2nTPxeMU7uJHPxAqjDH64qk5evrmGWrr9OiyB1fo2dVlTscKOPzUBIAg\nV1rbrEeWleiSUzI0LWeA03EAOCA/e4Be+dppys/ur+8s2qA7n1uv1g6P07ECBoUZAILYxwv9IlxG\n379gjNNxADgoJT5KT904XV87c4SeW1OuSx/8QKW1zU7HCggUZgAIYks2V2vp1hp94zOjlJYY7XQc\nAA5zhRl965xcPX7DVO1pbNNFf3xfr2/a43Qsv0dhBoAg1dbp0U9fLtTItHgtmJ3tdBwAfmRubppe\nvv1UDUuN01f+vkY/f6VInVwd8FNRmAEgSD38XonK6lv10/l5imChH4AjZPWP1bNfmanPzxyqvyzf\nqWv/slJ7G9ucjuWX+AkKAEGorL5FD75brHkT0jVrRIrTcQD4qahwl+65eJx+f/UpKqxs1Lw/LNey\nbTVOx/I7FGYACEI/e7lIYcboh/NY6Afg+C4+JVOLb5ut/rGR+vxjq/TNZ9aptqnd6Vh+g8IMAEHm\n3a3VerNor24/a4TS+8U4HQdAgBiRlqCXbj9Vt585Qi9vqNRZ97+np1ftltfLZbUpzAAQRNrdHv1k\ncaGGpcTpi6fmOB0HQICJjnDpjnNy9drXT1PuoATd9fxGffaRD7Vt7wGnozmKwgwAQeTR5TtVWtei\nu+fnKSrc5XQcAAFqRFqCnrl5hn51xQRtr27SBb9frl+/sUVtnaF5sRMKMwAEiYr9rfrTO8U6N2+g\nzhiV6nQcAAHOGKOr8gdrybfO0MWnZOqBpTt0zu+W6b0QXBRIYQaAIHHfK5vltVY/nDfW6SgAgkhy\nfJTuv2qi/vGl6QoPM/rCY6t0+z8/UvWB0NmCjsIMAEHg/e21emVjlW6dO0KDB8Q6HQdAEJo1PEWv\nfeM0feMzI/XGpj066/739PeVu0JiUaCx1r/eZH5+vi0oKHA6BgB8wq3/t1Y1Te2am5umObmpGj0o\nQcYYp2NJkjrcXp3/+2Xq9Fi9+c3TFR3B3GUAvWtHTZN++MImfVhSp0lDkvSLy8Zr9KBEp2OdMGPM\nGmtt/nHPozADwLFtqmjQhX98X4MSo7Wn6ypYgxKjNXd0qs4YlaZTR6YoPiq8TzPVHGjX6tJ6rdpZ\nrw931Gnr3gP66xfyddaYgX2aA0DostbqhY8qdO8rm9XQ2qmbTsvR188aqdjIvv152BPdLcyB844A\nwCHPFZQpMjxMb3zjdLV2evTetmq9u7VGL62v0j9XlSnCZTQ1e4Dm5KZqbm6aRqTF+3T02Vqr8n2t\nWrXzYEFeXVqvktpmSVJ0RJgmDe6vey7OoywD6FPGGF02OUtzc9P0y9e26OH3SvTy+irde8k4zR2d\n5nQ8n2KEGQCOod3t0fT7lujUESn607WTP3Ffp8ergtJ9endbtd7dUqOtXfuUZibFHCrPs0Ykn/Bo\ni9drVVzTpH/vrNfqroJc1XBwZDsxOlxTswdoas4ATcsZoHEZ/RQZznIUAM5btbNe339ho4qrm3TB\n+EG6+6I8DUyMdjrWMTElAwB84JUNVbr1H2v15I3TjrtVW8X+Vr23tUZLt1brg+JatXR4FOkK0/Rh\nA3TGqFTNHZ2mYSlx/zX63OnxqrCyUat31uvfO+tVsKte+1s6JUlpCVGamjNA03MGaGr2AOUOTFBY\nmH/MnQaAI3W4vXpk2Q794Z1iRbrCdOe5ubp8SlafT1vrLgozAPjAgsdXaeueA3r/u2fKdQJFtd3t\nUUHpPi3dUq2lW6u1o+bgFIohA2I1JzdVU7MHqKSmWatL67V29z61dBy8GMDQ5FhN6xpBnp4zQEMG\nxPrN4kIA6K7S2mb96MVNWr69VsZIOclxGpuRqLyMfsrLSFReRqKS46OcjklhBoCe2tPQplm/XKJb\n5gzXneeO7tFzldW36N2t1Vq6tUYrdtSqrdMrY6TcgQma1jW9Ymr2AL//+BIAustaqw+K67Rm1z4V\nVjaosLJRFftbD90/KDFa4zITNfawEp2ZFNOngwQs+gOAHnr+o3J5rXTFlME9fq7BA2J1/cxsXT8z\nW22dHm2uatSwlHj1i43wQVIA8D/GGJ06MkWnjkw5dGx/S4cKKxsPFejCyka9s6VaH2/lnBQbobHp\niRqX+Z8SnZMSf0Kf8PUGCjMAHIW1VgsLyjUte4ByUuJ8+tzRES5NGtLfp88JAIEgKTZSs0ekaPaI\n/5To1g6PNu85WJ6Luor0Ex+UqsPjlSTFRLg0Oj2hq0AfLNKjBib06Z7zFGYAOIq1u/eppLZZX5kz\n3OkoABDUYiJdmjykvyYfNpDQ6fGquLrpE6PRL35Uqb+v3C1JCg8zGpEW/4k50WMzEpUQ3Tuf2lGY\nAeAonisoV2ykS/PGpzsdBQBCToQrTGPSEzUmPVFXTMmSdHDLzbJ9LZ8o0cu212jR2vJDjxuaHHto\nJHpsV5FOS+j52hAKMwAcoaXDrZc3VOmC8emK89OtkAAg1ISFGQ1NjtPQ5DhdcNhgRnVj2ydK9KaK\nRr26cc+h+1MTog6NQn88In2iOxDxmwAAjvD6pj1qanfryq5RDQCA/0pLjFZaYvQnri7Y2Napoq5F\nhYWVDSqqbNTy7bXydK0uTIgO19j0xG6/BoUZAI7wXEH5wf2QcwY4HQUAcBISoyM0Y1iyZgxLPnSs\nrdOjbXsPfGI0ursozABwmLL6Fn1YUqc7zh7FBUMAIIhER7g0IStJE7KSDh0zt3bvsWG9lAkAAtLC\nNeUyRrqc6RgAgC4UZgDo4vVaLVxTrlNHpCgjKcbpOAAAP0FhBoAuK0vqVLG/9dAWRgAASBRmADjk\n2YIyJUSH69y8QU5HAQD4EQozAOjgFkSvbdqj+RMz+vRyqwAA/0dhBgBJL6+vUrvbqyvzBzsdBQDg\nZyjMACDpuTVlGjUwXhOz+jkdBQDgZyjMAEJecfUBfbR7v66cMpi9lwEA/4XCDCDkPbemXK4wo0sm\nZTodBQDghyjMAEKa2+PV82srNDc3TakJUU7HAQD4IQozgJC2bHuNag6068p89l4GABwdhRlASHuu\noFzJcZE6c3Sa01EAAH6KwgwgZNU3d+jtzXt1yaRMRbj4cQgAODp+QwAIWS+uq1CnxzIdAwBwTBRm\nACHruYJyjc/sp9GDEp2OAgDwYxRmACGpsLJBRVWNjC4DAI6LwgwgJD1XUK5IV5jmT8xwOgoAwM9R\nmAGEnA63Vy+uq9DZeQOVFBvpdBwAgJ+jMAMIOUs279W+lk5dOYXpGACA4+tWYTbGnGeM2WqMKTbG\n3HWU+xcYY2qMMeu6/tx0xP2JxphyY8yffBUcAE7WswVlGpQYrdNGpjodBQAQAMKPd4IxxiXpAUln\nSyqXtNoYs9haW3TEqc9Ya2/7lKf5maRlPUoKAD6wt7FN722r0S1zhssVZpyOAwAIAN0ZYZ4mqdha\nW2Kt7ZD0tKSLu/sCxpgpkgZKevPkIgKA7zy/tkJeK10xZbDTUQAAAaI7hTlTUtlht8u7jh3pcmPM\nBmPMQmPMYEkyxoRJul/St3ucFAB6yFqr59aUaWp2f+WkxDkdBwAQIHy16O8lSdnW2gmS3pL0ZNfx\nr0p61VpbfqwHG2NuNsYUGGMKampqfBQJAD5p7e79Kqlp1pWMLgMATsBx5zBLqpB0+G+XrK5jh1hr\n6w67+aikX3V9PVPSacaYr0qKlxRpjGmy1t51xOMfkfSIJOXn59sTegcA0E0L15QpJsKlCyakOx0F\nABBAulOYV0saaYzJ0cGifLWkaw8/wRiTbq2t6ro5X9JmSbLWfu6wcxZIyj+yLANAX2jt8Oil9VW6\nYHy64qO686MPAICDjvtbw1rrNsbcJukNSS5Jj1lrC40x90gqsNYulvQ1Y8x8SW5J9ZIW9GJmADhh\nrxdWqandzaWwAQAnzFjrXzMg8vPzbUFBgdMxAASZa/+yUuX7WvXenXNkDNvJAQAkY8waa23+8c7j\nSn8Agl5ZfYtW7KjTFVOyKMsAgBNGYQYQ9BatLZcx0uVcChsAcBIozACCmtdrtXBNuWYPT1FmUozT\ncQAAAYjCDCCordxZp/J9rSz2AwCcNAozgKC2sKBcCdHhOjdvkNNRAAABisIMIGgdaOvUq5uqNH9i\nhqIjXE7HAQAEKAozgKD1yoYqtXV6dWU+l8IGAJw8CjOAoPVsQZlGpsVrYlY/p6MAAAIYhRlAUCqu\nbtLa3ft1ZT57LwMAeua4l8YGgEBSvq9Fr26s0sI15XKFGV0yKdPpSACAAEdhBhDwKva36rWNVXp5\nQ5XWle2XJE3I6qffXjVRaQnRDqcDAAQ6CjOAgFTV0KpXN+7RKxsqtXb3wZI8LjNR3z1vtOaNT9eQ\n5FiHEwIAggWFGUDA2NPQplc3VunVjVUq2LVPkjQ2PVF3npureePTlZ0S53BCAEAwojAD8Gt7G9v0\n2sYqvbKxSqtLD5bkMV0l+YLx6cqhJAMAehmFGYDfqT7Qptc37dHLG6q0urRe1kqjByXojrNH6YIJ\n6RqeGu90RABACKEwA3Bch9urbXsPaO3ufXp1Y5X+vfNgSR41MF7fOGuU5k0YpBFpCU7HBACEKAoz\ngD7V3O7W5qpGFVY2qrCyQYWVjdq294A6PVaSNCItXl87c6TmTUjXqIGUZACA8yjMAHpNfXOHCisb\ntKniYDkuqmzUzrpm2YPdWAPiIpWXkagbT81RXkY/jc/sp+zkWC40AgDwKxRmAD1mrVXF/tauUeNG\nFXWNHFc1tB06JzMpRnkZibr4lEzlZSQqLzNRgxKjKccAAL9HYQZwUprb3frr+zv17511Kqxs1P6W\nTklSmJGGpcZrWs4A5WUkalxGP43NSFRSbKTDiQEAODkUZgAn7O2ivbp7caEq9rdqfGY/nT9ukMZm\n9FNeRqLGDEpUTKTL6YgAAPgMhRlAt+1paNNPFhfq9cI9GjUwXs99ZaamZg9wOhYAAL2KwgzguDxe\nq6c+LNX9b25Tp8erO8/N1Zcb/DokAAAgAElEQVROG6bI8DCnowEA0OsozACOaVNFg77/wkZtKG/Q\n6aNSde/F4zQkOdbpWAAA9BkKM4Cjamp367dvbtMTK3ZqQFyU/nDNJF00IZ1dLQAAIYfCDDjEWquG\n1k7VHGhX9YH2rr/bjrjdrna3R2eMStW88RmaljNArrDeL6xvFO7RTxYXak9jm66dNkTfOW+0+sVE\n9PrrAgDgjyjMgI91eryqbWpXdWP7MctwTVO7Otze/3p8VHiY0hKjlJYQrRGp8fJaq0VrKvT3lbuV\nEh+lC8YP0rzx6crP9n15rtzfqrsXF+qtor0aPShBD3xusiYP6e/T1wAAINBQmAEf2lHTpM8+vFK1\nTe3/dV//2AilJUQrNSFKw1LilJoQpdSEKKUlRis1PkppiQdvJ0SF/9e0h5YOt5ZuqdErGyv1bEGZ\nnvpwl9ISonTB+HTNm5CuKUP6K6wH5dnt8eqJFaX67Vvb5LVW3zt/tG48NUcRLhb1AQBg7MfXqPUT\n+fn5tqCgwOkYwAk70NapSx74QPtaOvWts0dpYGK00rpKcUp8lM92lGhud+udLdV6ZUOVlm6tVrvb\nq4GJXeV5fLomn2B5Xl+2X99/YaMKKxs1NzdV91w8ToMHsKgPABD8jDFrrLX5xz2Pwgz0nNdr9eW/\nr9E7W6r19y9O18zhyX3yuk3tbi3ZvFevbKjSu9tq1OH2alBi9KGR50mDkz61PB9o69Rv3tiqp1bu\nUmp8lH4yP0/njxvEoj4AQMjobmFmSgbgA398p1hvFe3V3ReN7bOyLEnxUeG6+JRMXXxKpg60deqd\nLdV6eUOV/r5ylx77YKcy+v2nPJ8yOEnGGFlr9fqmPfrJS4WqPtCuz88YqjvOzVViNIv6AAA4GkaY\ngR56q2ivvvRUgS6bnKn7r5zoFyO0jW2dh0ae39tWo06PVWZSjC4YP0glNc1asqVaY9MTdd9l43XK\n4CSn4wIA4AimZAB9oLi6SZc88IFyUuL03FdmKjrC5XSk/9LQ2qm3i/bqlY1VWr69RhGuMH3r7FFa\nMCtb4SzqAwCEMKZkAL2ssa1TNz9VoKjwMD18/RS/LMuS1C8mQpdPydLlU7LU0NopY8T0CwAATgCF\nGTgJXq/VN59ep931Lfq/m6YrIynG6UjdwsVHAAA4cXweC5yE/12yXUu2VOtHF47V9GF9t8gPAAD0\nPQozcIJe37RHf1iyXVdOydLnZw51Og4AAOhlFGbgBGzfe0B3PLtOEwcn6WeXjPOLHTEAAEDvojAD\n3dTQ2qmb/7ZGMZEuPXTdZL9d5AcAAHyLRX9AN3i8Vt94+iOV1bfonzfPUHq/wFjkBwAAeo4RZqAb\nfvfWNi3dWqO75+dpavYAp+MAAIA+RGEGjuO1jVX609JifTZ/sK6bPsTpOAAAoI9RmIFj2LrngO54\nbr0mDUnSPZfkscgPAIAQRGEGPkVDS6du/luB4qLC9dB1UxQVziI/AABCEYUZOAqP1+r2pz9S5f5W\nPXTdZA1MjHY6EgAAcAi7ZABH8Zs3t2rZthrdd+l4TRnKIj8AAEIZI8zAEV7eUKk/v7tD10wbomtZ\n5AcAQMijMAOH2VzVqDuf26DJQ5L0k/ljnY4DAAD8AIUZ6LK/pUM3/61ACdEs8gMAAP/BHGZAktvj\n1e3//Eh7G9r19JdnKI1FfgAAoAuFGZD06ze2avn2Wv3ysvGaPKS/03EAAIAfYUoGQt5L6yv18LIS\nXTdjiK6exiI/AADwSRRmhDSv1+qXr23RhKx++vGFeU7HAQAAfojCjJC2cmedKva36oun5igynP87\nAACA/0ZDQEhbuKZcCVHhOjdvkNNRAACAn6IwI2Q1t7v1+qY9unBiuqIj2EIOAAAcHYUZIeu1TXvU\n0uHR5ZOznI4CAAD8GIUZIWvhmjJlJ8dqylC2kQMAAJ+OwoyQVFbfopUl9bp8cpaMMU7HAQAAfozC\njJD0wkcVkqRLJ2c6nAQAAPg7CjNCjrVWi9aWa+awZGX1j3U6DgAA8HMUZoScgl37tKuuRVdMYbEf\nAAA4PgozQs7CgnLFRrp03jj2XgYAAMdHYUZIae3w6JWNVTp/XLriosKdjgMAAAIAhRkh5c2iPWpq\ndzMdAwAAdBuFGSFl4ZpyZSbFaHrOAKejAACAAEFhRsioamjV+8W1unxypsLC2HsZAAB0T7cKszHm\nPGPMVmNMsTHmrqPcv8AYU2OMWdf156au40ONMWu7jhUaY77i6zcAdNcLH1XIWulypmMAAIATcNxV\nT8YYl6QHJJ0tqVzSamPMYmtt0RGnPmOtve2IY1WSZlpr240x8ZI2dT220hfhge6y1mrhmnJNze6v\noclxTscBAAABpDsjzNMkFVtrS6y1HZKelnRxd57cWtthrW3vuhnVzdcDfG5d2X6V1DSz2A8AAJyw\n7hTYTEllh90u7zp2pMuNMRuMMQuNMYM/PmiMGWyM2dD1HP/D6DKcsGhtuaIjwnTB+HSnowAAgADj\nqxHflyRlW2snSHpL0pMf32GtLes6PkLSF4wxA498sDHmZmNMgTGmoKamxkeRgIPaOj1avK5S5+YN\nUkJ0hNNxAABAgOlOYa6QNPiw21ldxw6x1tYdNvXiUUlTjnySrpHlTZJOO8p9j1hr8621+ampqd3N\nDnTLks3Vamxj72UAAHByulOYV0saaYzJMcZESrpa0uLDTzDGHP4593xJm7uOZxljYrq+7i/pVElb\nfREc6K5Fa8s1KDFas4anOB0FAAAEoOPukmGtdRtjbpP0hiSXpMestYXGmHskFVhrF0v6mjFmviS3\npHpJC7oePkbS/cYYK8lI+o21dmMvvA/gqKoPtOm9bTW6+fRhcrH3MgAAOAnHLcySZK19VdKrRxz7\n8WFff0/S947yuLckTehhRuCkvfhRpTxeq8snMx0DAACcHLZ5Q9D6eO/lUwYnaURavNNxAABAgKIw\nI2gVVjZq694DXNkPAAD0CIUZQWvhmnJFusI0f0KG01EAAEAAozAjKHW4vXpxXYXOHjtQ/WLZexkA\nAJw8CjOC0tKt1drX0qnLpxztopQAAADdR2FGUFq0plwp8VE6fSQXwgEAAD1DYUbQqWtq1ztbqnXp\npAyFu/gWBwAAPUObQNBZvL5Sbq9ldwwAAOATFGYEnUVryzUuM1GjByU6HQUAAAQBCjOCypY9jdpU\n0ciV/QAAgM9QmBFUFq0pV3iY0fyJ7L0MAAB8g8KMoOH2ePXCR5U6c3SakuOjnI4DAACCBIUZQWPZ\n9hrVNrWz2A8AAPgUhRlBY9GaCvWPjdDc3DSnowAAgCBCYUZQ2N/SobeK9uriUzIVGc63NQAA8B2a\nBYLCSxuq1OHx6gqmYwAAAB+jMCMoLFpTrtyBCcrLYO9lAADgWxRmBLzi6iatK9uvK6ZkyRjjdBwA\nABBkKMwIeIvWlssVZnTxJPZeBgAAvkdhRkDzeK1eWFuhM0alKi0h2uk4AAAgCFGYEdA+KK7VnsY2\nLoUNAAB6DYUZAW3R2nIlRofrrDHsvQwAAHoHhRkBq7GtU28U7tH8UzIUHeFyOg4AAAhSFGYErFc3\nVKmt08t0DAAA0KsozAhYi9aWa1hqnE4ZnOR0FAAAEMQozAhIpbXNWl26j72XAQBAr6MwIyA9v7Zc\nxkiXTsp0OgoAAAhyFGYEHK/XatHaCp06IkXp/WKcjgMAAIIchRkBZ8WOOlXsb9UVU1jsBwAAeh+F\nGQFlT0Ob7ly4XoMSo3XO2EFOxwEAACGAwoyA0dTu1g1PrFZja6f+uiBfMZHsvQwAAHpfuNMBgO5w\ne7y69f/WatveA/rrF/KVl9HP6UgAACBEMMIMv2et1Y9eLNR722r0s4vHaU4ul8EGAAB9h8IMv/fQ\neyX656rdumXOcF07fYjTcQAAQIihMMOvvbS+Uv/z+hZdNDFDd56T63QcAAAQgijM8FurS+t1x7Pr\nNTW7v359xQSFhXFFPwAA0PcozPBLJTVN+tJTBcrqH6NHrs9XdAQ7YgAAAGdQmOF36prateDx1Qoz\nRo/fMFX94yKdjgQAAEIYhRl+pa3To5ueKtDexjY9+oV8DU2OczoSAAAIcezDDL/h9Vp985l1Wle2\nXw9eO1mTh/R3OhIAAAAjzPAfv3hts17btEc/uGCMzh+f7nQcAAAASRRm+ImnPizVX5bv1BdmDtUX\nT81xOg4AAMAhFGY47u2ivfrJ4kJ9ZkyafnxRnoxh+zgAAOA/KMxw1MbyBt3+z4+Ul9FPf7hmklzs\ntQwAAPwMhRmOKd/XohufXK0BcZH664J8xUayBhUAAPgfGgoc0dDaqRseX622To/+cdN0pSVEOx0J\nAADgqBhhRp/rcHv1lb+tUWldsx6+fopGDkxwOhIAAMCnYoQZfcpaq7ue36APS+r026smatbwFKcj\nAQAAHBMjzOhT//v2dj2/tkLf/MwoXTY5y+k4AAAAx0VhRp9ZuKZcv1+yXVdMydLXzhrhdBwAAIBu\noTCjT3xQXKu7Fm3Q7BHJuu/S8ey1DAAAAgaFGb1ud12LvvL3NRqWGqcHPzdFkeF82wEAgMBBc0Gv\n8nitvvXsOslKf/3CVPWLiXA6EgAAwAlhlwz0qoeX7VDBrn363WcnavCAWKfjAAAAnDBGmNFrNlU0\n6HdvbdO88em65JRMp+MAAACcFAozekVbp0fffGad+sdG6t5LxrHIDwAABCymZKBX/PqNrdpe3aQn\nb5ym/nGRTscBAAA4aYwww+c+KK7VX9/fqc/PHKozRqU6HQcAAKBHKMzwqYbWTn37ufUalhKn750/\nxuk4AAAAPcaUDPjU3S9uUvWBdj1/yyzFRLqcjgMAANBjjDDDZ15aX6l/ravU184cqYmDk5yOAwAA\n4BMUZvjEnoY2/fBfmzRxcJJunTvc6TgAAAA+Q2FGj3m9VncuXK8Ot1e/u2qiwl18WwEAgOBBs0GP\n/W3lLi3fXqsfzBujYanxTscBAADwKQozeqS4ukn3vbpZc3JT9bnpQ5yOAwAA4HMUZpy0To9X33xm\nnWIjXfrV5RO4mh8AAAhKbCuHk/bHJdu1saJBD103WWmJ0U7HAQAA6BXdGmE2xpxnjNlqjCk2xtx1\nlPsXGGNqjDHruv7c1HX8FGPMh8aYQmPMBmPMZ339BuCMtbv36U9Li3X55CydNy7d6TgAAAC95rgj\nzMYYl6QHJJ0tqVzSamPMYmtt0RGnPmOtve2IYy2SPm+t3W6MyZC0xhjzhrV2vy/CwxnN7W5965l1\nSu8Xo7vnj3U6DgAAQK/qzgjzNEnF1toSa22HpKclXdydJ7fWbrPWbu/6ulJStaTUkw0L//DzVzdr\nV32L7r9qohKjI5yOAwAA0Ku6U5gzJZUddru869iRLu+adrHQGDP4yDuNMdMkRUracVJJ4Rfe2bJX\n//j3bt182jDNGJbsdBwAAIBe56tdMl6SlG2tnSDpLUlPHn6nMSZd0t8k3WCt9R75YGPMzcaYAmNM\nQU1NjY8iwdfqmtr1nYUbNXpQgr51ziin4wAAAPSJ7hTmCkmHjxhndR07xFpbZ61t77r5qKQpH99n\njEmU9IqkH1hrVx7tBay1j1hr8621+ampzNjwR9Zafe/5jWps7dTvPnuKosJdTkcCAADoE90pzKsl\njTTG5BhjIiVdLWnx4Sd0jSB/bL6kzV3HIyW9IOkpa+1C30SGExauKdebRXv17XNHaUx6otNxAAAA\n+sxxd8mw1rqNMbdJekOSS9Jj1tpCY8w9kgqstYslfc0YM1+SW1K9pAVdD79K0umSko0xHx9bYK1d\n59u3gd5UVt+in75UpOk5A/TFU4c5HQcAAKBPGWut0xk+IT8/3xYUFDgdA108XqtrHlmpoqpGvf6N\n05TVP9bpSAAAAD5hjFljrc0/3nlc6Q/H9OjyEq0qrdf9V06kLAMAgJDkq10yEISKKhv1mze36vxx\ng3TZ5KPtJAgAABD8KMw4qrZOj7717DolxUbq55eOlzHG6UgAAACOYEoGjuq3b23Tlj0H9PgNUzUg\nLtLpOAAAAI5hhBn/ZXNVox5dXqJrpg3W3Nw0p+MAAAA4isKMT7DW6scvblK/mAh997zRTscBAABw\nHIUZn/DiukqtLt2n7543WkmxTMUAAACgMOOQA22d+vmrmzUxq5+uyh98/AcAAACEABb94ZDfv71d\ntU3tevTz+QoLY1cMAAAAiRFmdNm294AeX1Gqq6cO1sTBSU7HAQAA8BsUZshaq7tfLFR8VLjuPJeF\nfgAAAIejMEOvbKzShyV1+va5uey5DAAAcAQKc4hrbnfr3pc3Ky8jUddOG+J0HAAAAL/Dor8Q96el\nxdrT2KYHPjdJLhb6AQAA/BdGmEPYjpomPbq8RJdPztKUoQOcjgMAAOCXKMwhylqrnywuVHS4S3ed\nz0I/AACAT0NhDlFvFO7V8u21+ubZo5SaEOV0HAAAAL9FYQ5BrR0e/ezlIo0elKDPzxzqdBwAAAC/\nxqK/EPTnd4tVsb9Vz9w8Q+Eu/psJAADgWGhLIWZXXbMeWlaii0/J0PRhyU7HAQAA8HsU5hBzz0tF\niggz+v4FY5yOAgAAEBAozCFkyea9WrKlWl//zEgNTIx2Og4AAEBAoDCHiLZOj376UpFGpMXrhtk5\nTscBAAAIGCz6CxGPLCvR7voW/d9N0xXBQj8AAIBuozmFgLL6Fj2wtFjzxqdr9ogUp+MAAAAEFApz\nCLj3lSKFGaMfzGOhHwAAwImiMAe597bV6I3CvbrtzBHKSIpxOg4AAEDAoTAHsXa3Rz9dXKiclDjd\ndBoL/QAAAE4GhTmI/fX9nSqpbdbdF41VVLjL6TgAAAABicIcpKoaWvXHJcU6Z+xAzclNczoOAABA\nwKIwB6l7X9ksr7X60YVjnY4CAAAQ0CjMQWhFca1e2VClr84ZocEDYp2OAwAAENAozEGm0+PV3YsL\nNXhAjL58xjCn4wAAAAQ8CnOQeXJFqbZXN+nuC/MUHcFCPwAAgJ6iMAeR6sY2/e/b2zU3N1VnjWGh\nHwAAgC9QmIPIL17bog63V3dflCdjjNNxAAAAggKFOUis2lmvFz6q0M2nD1N2SpzTcQAAAIIGhTkI\ntHV6dNfzG5SZFKNb545wOg4AAEBQCXc6AHruj+9sV0lNs566cZpiIlnoBwAA4EuMMAe4TRUNeui9\nEl0xJUunj0p1Og4AAEDQoTAHsE6PV99ZuEED4iL1o3lc0Q8AAKA3MCUjgD2yrERFVY166Lop6hcb\n4XQcAACAoMQIc4Aqrj6g37+9XfPGp+u8cYOcjgMAABC0KMwByOO1+s7CDYqNcukn8/OcjgMAABDU\nKMwB6MkVpVq7e79+fOFYpSZEOR0HAAAgqFGYA0xZfYt+/cZWzclN1aWTMp2OAwAAEPQozAHEWqvv\nPb9RrjCj+y4dz+WvAQAA+gCFOYA8W1Cm94trddf5o5WRFON0HAAAgJBAYQ4QexvbdO8rmzU9Z4Cu\nnTbE6TgAAAAhg8IcAKy1+sELm9Th9uqXl09QWBhTMQAAAPoKhTkAvLShSm9v3qs7zhmlnJQ4p+MA\nAACEFAqzn6tv7tBPFhdqYlY/3Tg7x+k4AAAAIYfC7Od++lKhDrR16ldXTFS4i38uAACAvkYD82NL\nNu/Vi+sqdevcEcodlOB0HAAAgJBEYfZTjW2d+sELmzR6UIK+OmeE03EAAABCVrjTAXB0v3h1s6oP\ntOnh66coMpz/rgEAAHAKTcwPrSiu1T9Xlemm04Zp4uAkp+MAAACENAqzn2npcOu7z29QdnKsvvmZ\nUU7HAQAACHlMyfAz97+5TWX1rXrm5hmKiXQ5HQcAACDkMcLsR9bu3qfHPtip62YM0fRhyU7HAQAA\ngCjMfqPd7dF3Fm5QemK0vnveaKfjAAAAoAtTMvzEn94pVnF1kx6/YaoSoiOcjgMAAIAujDD7gaLK\nRv353R26bFKm5uamOR0HAAAAh6EwO8zt8eo7i9YrKTZCP7pwrNNxAAAAcASmZDjsL8t3alNFox78\n3GT1j4t0Og4AAACOwAizg3bUNOl3b2/TeXmDdMH4dKfjAAAA4CgozA7xeq3uWrRBMREu3XNJntNx\nAAAA8Cm6VZiNMecZY7YaY4qNMXcd5f4FxpgaY8y6rj83HXbf68aY/caYl30ZPNC9uL5Cq0v36Yfz\nxigtIdrpOAAAAPgUx53DbIxxSXpA0tmSyiWtNsYsttYWHXHqM9ba247yFL+WFCvpyz0NGyw6PV79\n7q3tGpueqMsnZzkdBwAAAMfQnRHmaZKKrbUl1toOSU9Luri7L2CtXSLpwEnmC0rPFpRpd32L7jw3\nV2Fhxuk4AAAAOIbuFOZMSWWH3S7vOnaky40xG4wxC40xg32SLgi1dXr0hyXbNWVof83JTXU6DgAA\nAI7DV4v+XpKUba2dIOktSU+eyIONMTcbYwqMMQU1NTU+iuSf/r5yl/Y2tuvb5+TKGEaXAQAA/F13\nCnOFpMNHjLO6jh1ira2z1rZ33XxU0pQTCWGtfcRam2+tzU9NDd5R16Z2tx58d4dOG5mimcOTnY4D\nAACAbuhOYV4taaQxJscYEynpakmLDz/BGHP4JsLzJW32XcTg8dj7O1Xf3KE7zsl1OgoAAAC66bi7\nZFhr3caY2yS9Ickl6TFrbaEx5h5JBdbaxZK+ZoyZL8ktqV7Sgo8fb4xZLmm0pHhjTLmkL1pr3/D9\nW/Fv+1s69JdlJTpn7ECdMjjJ6TgAAADopm5dGtta+6qkV4849uPDvv6epO99ymNP60nAYPHQeyVq\n6nAzugwAABBguNJfH6g+0KYnVuzUxRMzlDsowek4AAAAOAEU5j7wwDvF6vRYfeMzo5yOAgAAgBNE\nYe5l5fta9I9Vu3VV/mBlp8Q5HQcAAAAniMLcy37/9nYZY/S1s0Y4HQUAAAAngcLci3bUNGnR2nJd\nP2Oo0vvFOB0HAAAAJ4HC3It++9Y2RUe4dMuc4U5HAQAAwEmiMPeSwsoGvbKhSl88NUcp8VFOxwEA\nAMBJojD3kvvf3KbE6HDddNowp6MAAACgByjMvWDNrnq9s6VaX5kzXP1iIpyOAwAAgB6gMPuYtVa/\nfmOrUuKjtGBWttNxAAAA0EMUZh/7oLhOK0vqddvc4YqN7NaVxwEAAODHKMw+dHB0eYsyk2J0zfQh\nTscBAACAD1CYfeitor1aX96gr581UlHhLqfjAAAAwAcozD7i8Vrd/+Y2DUuJ02WTM52OAwAAAB+h\nMPvIyxsqtXXvAX3j7FEKd/E/KwAAQLCg2flAp8er3761TaMHJejC8elOxwEAAIAPUZh9YOGacu2q\na9G3z8lVWJhxOg4AAAB8iMLcQ22dHv1hyXZNGpKks8akOR0HAAAAPkZh7qH/+/duVTW06c5zcmUM\no8sAAADBhsLcA83tbj24tFizRyRr1ogUp+MAAACgF1CYe+DxD3aqrrlD3z4n1+koAAAA6CUU5pPU\n0NKph5eV6DNjBmrSkP5OxwEAAEAvoTCfpIeX7VBTu1t3nDPK6SgAAADoRRTmk1BzoF2Pf1CqiyZk\naEx6otNxAAAA0IsozCfhgaXF6vB49c2zGV0GAAAIdhTmE1Sxv1X/+PduXTklSzkpcU7HAQAAQC+j\nMJ+gP7y9XZJ0+1kjHU4CAACAvkBhPgElNU1auLZcn5sxRJlJMU7HAQAAQB+gMHeTx2v1P69vUaQr\nTF+dM8LpOAAAAOgj4U4HCAR1Te36xjPrtHx7re48N1epCVFORwIAAEAfoTAfx5pd+3TbP9aqrrlD\n/9/evQfLWdd3HH9/c5KQBA65QZBLIAkimnI1MYfaqaVWlGqNThksVFszRanQSMdLp1gddHCmI946\n05YypQ7q1Aso9RIFixS1VjQnCTeBILdzAiRoCGcTEggJuXz7x3lij6ew2UP27PPs7vs1k8nus8+z\n+z3nN7v7med8n9/vinNO5m2L55ZdkiRJklrIwPwCMpPP37qOv7/xPo6aMZVvXPRqTjp6etllSZIk\nqcUMzM9j245dXPofd3PD3b/krIVH8OlzT2X61ElllyVJkqQSGJhH+cWvtnLxl27nkdp2PvSHL+fC\n1ywgIsouS5IkSSUxMI/wjdvX83ffvJveKZP4yrv66Fswu+ySJEmSVDIDM7Bj1x4u/+5avtL/KGcs\nmMU/nn86c3qnlF2WJEmSKqDrA/Njte1c9OXbuGfDVi4683g+cNbLmNjj9NSSJEka1tWB+b/WbuT9\nX7sTgM/9+WJet/CIkiuSJElS1XRlYN69Zy+fufkBrvrRw5x09KFc9fZFzJ01reyyJEmSVEFdF5if\n2LaDS756BysHavxp37Fc9kcLmTKpp+yyJEmSVFFdFZj7B4ZY/tU72LZjF59926n88SuPKbskSZIk\nVVxXBObM5OofD/DJm+7nuFnT+NIFfZz4kt6yy5IkSVIb6PjA/NSzu/jg1+/i5rUbedPJR/KJc06m\nd4qr9kmSJKkxHR2YH9y4jQu+uIbHtzzLR9+8kGWvnueqfZIkSRqTjg7Mn/7+/WzdsYvr/vK3WXTc\nzLLLkSRJUhvq2BU69u5N+gdrvO4VRxiWJUmS9KJ1bGB+4IltbNm+i775s8ouRZIkSW2sYwPzqsEa\nAGcsmF1yJZIkSWpnHRuY+wdqHDV9CsfMnFp2KZIkSWpjHRmYM5P+wSH6Fsx2VgxJkiQdkI4MzA9v\neoYnn36OJfYvS5Ik6QB1ZGDuHxwC8II/SZIkHbCODMyrBmsc3nsQ8w87uOxSJEmS1OY6LjBnJv0D\nNfrmz7J/WZIkSQes4wLzo7Xt/GrrDvqcTk6SJElN0HGBuX+gmH/Z/mVJkiQ1QccF5pWDQ8w6eDIv\nnXNI2aVIkiSpA3RcYF41WGPJPPuXJUmS1BwdFZg3bHmW9ZufpW+B7RiSJElqjo4KzP0D++Zf9oI/\nSZIkNUeHBeYah06ZyMtf0lt2KZIkSeoQnRWYB4dYMn8WEybYvyxJkqTm6JjAvHHrDtYNbbcdQ5Ik\nSU3VMYG5f3B4/mUv+KVFV5YAAA30SURBVJMkSVIzdU5gHhjikIMmsvDIQ8suRZIkSR2kcwLzYI3F\n82YysadjfiRJkiRVQEekyyef3slDTzzNEpfDliRJUpM1FJgj4uyIuD8iHoqIS5/n8WURsSki7iz+\nvWvEY++MiAeLf+9sZvH7rN7Xv+wFf5IkSWqyifvbISJ6gCuBs4D1wOqIWJGZa0ftel1mLh917Czg\no8BiIIHbimM3N6X6Qv9gjamTejjlmOnNfFpJkiSpoTPMS4CHMnMgM58DrgXe0uDzvwG4OTNrRUi+\nGTj7xZX6wlYODLHouJlMsn9ZkiRJTdZIwjwaeGzE/fXFttHOiYifR8T1ETF3jMe+aFu2P8f9G7fR\nZ/+yJEmSxkGzTsl+B5iXmacwfBb5i2M5OCIujIg1EbFm06ZNY3rhVYM1MvGCP0mSJI2LRgLzBmDu\niPvHFNt+LTOHMnNncfdzwKJGjy2OvzozF2fm4sMPP7zR2oHh/uXJEydw6twZYzpOkiRJakQjgXk1\ncEJEzI+IycB5wIqRO0TEkSPuLgXuK27fBLw+ImZGxEzg9cW2plk1WOP0uTOYMqmnmU8rSZIkAQ3M\nkpGZuyNiOcNBtwe4JjPvjYjLgTWZuQK4JCKWAruBGrCsOLYWER9nOHQDXJ6ZtWYVv3XHLu59/CmW\nv/aEZj2lJEmS9Bv2G5gBMvNG4MZR2y4bcftDwIde4NhrgGsOoMYXdNu6zexNOMP+ZUmSJI2Ttp6H\nbeXgEJN6gtOPnVl2KZIkSepQbR2Y+wdqnHLMDKZOtn9ZkiRJ46NtA/MzO3dzz4annH9ZkiRJ46pt\nA/Ptj25m996kb8HsskuRJElSB2vbwNw/UKNnQrDoOPuXJUmSNH7aNzAPDnHS0dM55KCGJvqQJEmS\nXpS2DMw7du3hrsfsX5YkSdL4a8vAfMejW3huz14DsyRJksZdWwbm/sEhImDxPAOzJEmSxld7BuaB\nGguPPJTpUyeVXYokSZI6XNsF5p2793D7o5vpm+90cpIkSRp/bReYf77+KXbu3ssS+5clSZLUAm0X\nmFcN1gAMzJIkSWqJtgvMKweGOPGIXmYdPLnsUiRJktQF2iow79qzl9se2UzfAs8uS5IkqTXaKjDf\ns+Eptj+3xwv+JEmS1DJtFZj7i/7lV82fWXIlkiRJ6hZtFZhXDdZYcPjBzOmdUnYpkiRJ6hJtE5j3\n7E1WD9Zsx5AkSVJLtU1gvu+XW9m2czdneMGfJEmSWqhtAvPKgSHA+ZclSZLUWm0TmPsHaxw7axpH\nTp9adimSJEnqIm0RmPfuTVavq9Hn2WVJkiS1WFsE5gee2MaW7bvoW+AFf5IkSWqttgjM/QPD8y97\nhlmSJEmt1h6BeXCIo2dMZe6saWWXIkmSpC5T+cCcmawarDk7hiRJkkpR+cD88KZnePLp52zHkCRJ\nUikqH5j7B4fnX/aCP0mSJJWh+oF5oMac3oOYN9v+ZUmSJLVepQNzZtI/OETfgtlERNnlSJIkqQtV\nOjA/MrSdjVt32r8sSZKk0lQ6MP+6f9nALEmSpJJUPDDXmH3wZF4655CyS5EkSVKXqnZgHhief9n+\nZUmSJJWlsoF5/ebtbNjyrO0YkiRJKlVlA3P/QA1w/mVJkiSVq7qBeXCI6VMnceIRvWWXIkmSpC5W\n2cC8arDGq+bNYsIE+5clSZJUnkoG5o1bd7BuaDtnLLB/WZIkSeWqZGBeObBv/mX7lyVJklSuSgbm\n/sEahxw0kYVHHVp2KZIkSepy1QzMA0MsnjeTHvuXJUmSVLLKBebde5OHNz1jO4YkSZIqoXKB+Zmd\nuwHo84I/SZIkVUAlA/O0yT2cfPT0skuRJEmSqhiY97DouJlM6qlcaZIkSepClUulO3bvYck82zEk\nSZJUDZULzAB9C7zgT5IkSdVQucA8d+Y0Tp1r/7IkSZKqoXKBeca0SRw0safsMiRJkiSggoFZkiRJ\nqhIDsyRJklSHgVmSJEmqw8AsSZIk1WFgliRJkuowMEuSJEl1GJglSZKkOgzMkiRJUh0GZkmSJKkO\nA7MkSZJUh4FZkiRJqsPALEmSJNVhYJYkSZLqMDBLkiRJdRiYJUmSpDoMzJIkSVIdDQXmiDg7Iu6P\niIci4tI6+50TERkRi4v7kyPi8xFxd0TcFRFnNqluSZIkqSUm7m+HiOgBrgTOAtYDqyNiRWauHbVf\nL/DXQP+Ize8GyMyTI2IO8L2IeFVm7m3WDyBJkiSNp0bOMC8BHsrMgcx8DrgWeMvz7Pdx4Apgx4ht\nC4EfAGTmE8AWYPEBVSxJkiS1UCOB+WjgsRH31xfbfi0iXgnMzcwbRh17F7A0IiZGxHxgETD3AOqV\nJEmSWmq/LRn7ExETgM8Cy57n4WuAVwBrgEeAnwJ7nuc5LgQuLO7ujIh7DrQuNcVhwJNlFyHHoUIc\ni2pwHKrDsagGx+HFO66RnRoJzBv4zbPCxxTb9ukFTgJ+FBEALwFWRMTSzFwDvG/fjhHxU+CB0S+Q\nmVcDVxf7rMlM2zYqwLGoBsehOhyLanAcqsOxqAbHYfw10pKxGjghIuZHxGTgPGDFvgcz86nMPCwz\n52XmPGAlsDQz10TEtIg4GCAizgJ2j75YUJIkSaqy/Z5hzszdEbEcuAnoAa7JzHsj4nJgTWauqHP4\nHOCmiNjL8FnpP2tG0ZIkSVKrNNTDnJk3AjeO2nbZC+x75ojb64ATx1jT1WPcX+PHsagGx6E6HItq\ncByqw7GoBsdhnEVmll2DJEmSVFkujS1JkiTVUVpg3t9y2xHx/ohYGxE/j4hbIqKhaT80dg2MxXuK\n5c3vjIifRMTCMursdC92CXo1XwPviWURsal4T9wZEe8qo85O18h7IiLeVnxX3BsRX2l1jd2ggffD\nP4x4LzwQEVvKqLMbNDAWx0bEDyPijiI/vbGMOjtRKS0ZxXLbDzBiuW3g/JEzaETE7wP9mbk9Ii4C\nzszMP2l5sR2uwbE4NDO3FreXAhdn5tll1NupGhmHYr9e4AZgMrC8mLpRTdTge2IZsDgzl5dSZBdo\ncBxOAL4GvDYzN0fEnGJVWTVJo59NI/Z/L3B6Zv5F66rsDg2+J64G7sjMq4qTWzcWM5jpAJV1hnm/\ny21n5g8zc3txdyXD8z+r+RoZi60j7h4M2PjefAeyBL2aq9Gx0PhqZBzeDVyZmZsBDMvjYqzvh/OB\nr7aksu7TyFgkcGhxezrweAvr62hlBeb9Lrc9ygXA98a1ou7V0FhExF9FxMPAJ4FLWlRbNzmQJejV\nXI1+Pp1T/Mnz+oiY+zyP68A0Mg4vA14WEbdGxMqI8C9fzdfw93XROjkf+EEL6upGjYzFx4B3RMR6\nhmc3e29rSut8lb/oLyLeASwGPlV2Ld0sM6/MzOOBvwU+UnY93WbEEvQfKLsWAfAdYF5mngLcDHyx\n5Hq61UTgBOBMhs9s/ltEzCi1ou52HnB9Zu4pu5Audj7whcw8Bngj8O/F94cOUFm/xP0ttw1ARLwO\n+DDDKwfubFFt3aahsRjhWuCt41pRdxrLEvTrgDMYXoLeC/+ab7/vicwcGvGZ9DlgUYtq6yaNfDat\nB1Zk5q7MHGS4v/OEFtXXLcbyHXEetmOMp0bG4gKG+/rJzJ8BU4DDWlJdhysrMNddbhsgIk4H/pXh\nsGxf2vhpZCxGfgG9CXiwhfV1ixe9BH055Xa0Rt4TR464uxS4r4X1dYv9jgPwLYbPLhMRhzHcojHQ\nyiK7QCPjQES8HJgJ/KzF9XWTRsbiUeAPACLiFQwH5k0trbJDNbTSX7M1uNz2p4BDgK9HBMCjmbm0\njHo7WYNjsbw4278L2Ay8s7yKO9MBLkGvJmpwLC4pZozZDdSAZaUV3KEaHIebgNdHxFpgD/A3mTlU\nXtWdZwyfTecB16aroY2bBsfiAwy3Jr2P4QsAlzkmzeFKf5IkSVIdNoJLkiRJdRiYJUmSpDoMzJIk\nSVIdBmZJkiSpDgOzJEmSVIeBWZJaJCJmRMTFxe0zI+K74/AayyLin8d4zLpiHuPR2z8WER9sXnWS\n1J4MzJLUOjOAi8dyQET0jFMtkqQGGZglqXU+ARwfEXdSLM4UEddHxC8i4stRrNJUnPG9IiJuB86N\niOMj4j8j4raI+J9iVTUi4tyIuCci7oqIH494naOK/R+MiE/u2xgR50fE3cUxVzxfgRHx4Yh4ICJ+\nApw4Xr8ISWonpaz0J0ld6lLgpMw8LSLOBL4N/BbwOHAr8DvAT4p9hzLzlQARcQvwnsx8MCL6gH8B\nXgtcBrwhMzdExIwRr3MacDqwE7g/Iv6J4ZXwrgAWMbxi5/cj4q2Z+a19B0XEIoZXbDuN4e+H24Hb\nmv9rkKT2YmCWpPKsysz1AMVZ53n8X2C+rth+CPBq4OvFCWiAg4r/bwW+EBFfA74x4nlvycyniuPX\nAscBs4EfZeamYvuXgdcA3xpx3O8C38zM7cU+LskuSRiYJalMO0fc3sNvfiY/U/w/AdiSmaeNPjgz\n31OccX4TcFtxhnh/zytJGiN7mCWpdbYBvWM5IDO3AoMRcS5ADDu1uH18ZvZn5mXAJmBunadaBfxe\nRBxWXEh4PvDfo/b5MfDWiJgaEb3Am8dSqyR1Ks86SFKLZOZQRNwaEfcAzwIbGzz07cBVEfERYBJw\nLXAX8KmIOAEI4JZi2/87E1289i8j4lLgh8X+N2Tmt0ftc3tEXFc8zxPA6rH+jJLUiSIzy65BkiRJ\nqixbMiRJkqQ6DMySJElSHQZmSZIkqQ4DsyRJklSHgVmSJEmqw8AsSZIk1WFgliRJkuowMEuSJEl1\n/C+ops6gvCCZkwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 864x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IidbFPTF_zad",
        "colab_type": "text"
      },
      "source": [
        "## Conclusions:\n",
        "\n",
        "- Pretrained models can be used for segmentation problems:\n",
        "    - Some of architectures can be easily adapted to the problem (ie ResNet)\n",
        "    - Other architectures may require more experimentation with selection of proper layers for feature extraction and padding (example of using [Xception](https://www.kaggle.com/meaninglesslives/getting-0-87-on-private-lb-using-kaggle-kernel). )\n",
        "    - You can experiment with selection of layers for feature extraction\n",
        "    - For some models, you can also try to experiment with number of encoder/decoder blocks\n",
        "- Threshold optimization is important in problems, where direct metric optimization during training is difficult.\n",
        "    - It it possible to use more involved optimization methods (from [scipy optimize](https://docs.scipy.org/doc/scipy/reference/optimize.html)), although this may not be optimal unless distribution of train and test set are very similar. Overoptimization of threshold or any other parameter on validation set may result in worse test set results.\n",
        "- Experiment with various losses - BCE, Dice, combined BCE with Dice, Lovash loss.\n",
        "    - Models trained with various losses may give different results, which may be advantageous when ensembling.\n",
        "\n",
        "\n",
        "### Possible experiments:\n",
        "\n",
        "- Change type of decoder block in created segmentation model\n",
        "- Create your own decoder blocks\n",
        "- Train with other losses\n",
        "- Train longer\n",
        "- Train with BCE/Dice, save the model, then load weights and finetune with Lovash loss\n",
        "- Try different ranges and intervals for threshold optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_9Eh_wg_zad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KRkbZ7YZsCC",
        "colab_type": "text"
      },
      "source": [
        "### 【問題1】コードレビュー\n",
        "転移学習を使用してセグメンテーションの精度を改善したコードを提示するので、レビューを行ってください。\n",
        "\n",
        "《視点例》\n",
        "\n",
        "前回使用した実装とはどのように違うのか\n",
        "転移学習をどのように行っているか"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiwE2mU4oG-G",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "前回のUnetの実装と違う点\n",
        "*   BatchNormalizationで過学習を防いでいる\n",
        "*   ReduceLROnPlateauメソッドを使い、学習率の最適化を行っている\n",
        "*   エンコーダーのResNet50は50層あるため、前回のシンプルなUnetよりもたくさんの畳み込み層を行うことで精度を高めている。\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ws--iEUFZZRB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-e-WdvUx1XHT",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsws2CWkZ2n6",
        "colab_type": "text"
      },
      "source": [
        "### 【問題2】コードの書き換え\n",
        "エンコーダーにResNetが使用されていたコードをVGGに変更してください。\n",
        "\n",
        "【問題3】学習・推定\n",
        "ResNetとVGG双方のコードで学習・推定を行い、結果を比較してください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RePk9jeGZzML",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SMHRYzoZzIq",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint 機械学習スクラッチ　線形回帰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split # testとtrain分割\n",
    "\n",
    "# データの読み込み\n",
    "df = pd.read_csv('./train.csv')\n",
    "X = df.loc[:,['GrLivArea','YearBuilt']].values\n",
    "y = df.SalePrice.values\n",
    "\n",
    "# データの前処理\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=0)\n",
    "# 標準化\n",
    "X_train_std = (X_train - X_train.mean()) / X_train.std()\n",
    "X_test_std = (X_test -X_test.mean()) / X_test.std()\n",
    "y_train_std = (y_train - y_train.mean()) / y_train.std()\n",
    "y_test_std = (y_test - y_test.mean()) / y_test.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題1】仮定関数\n",
    "以下の数式で表される線形回帰の仮定関数を実装してください。メソッドの雛形を用意してあります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _linear_hypothesis(X, theta_array):\n",
    "    \"\"\"\n",
    "    線形の仮定関数を計算する\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      学習データ\n",
    "    theta_array : 次の形のndarray, shape(n_samples, 1)\n",
    "     パラメータベクトル\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "      Y:次の形のndarray, shape (n_samples, 1)\n",
    "      線形の仮定関数による推定結果\n",
    "\n",
    "    \"\"\"\n",
    "    # 仮定関数\n",
    "    Y = np.dot(X,theta_array)\n",
    "    return Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_1_shape : (365, 3)\n",
      "coef_shape： 　 (3,)\n"
     ]
    }
   ],
   "source": [
    "#仮データを作成（HousePrise）\n",
    "# バイアス項の追加\n",
    "X_1 = np.insert(X_test_std, 0, 1, axis=1)\n",
    "# シータの初期値\n",
    "coef = np.random.rand(X_1.shape[1])\n",
    "# パラメータ\n",
    "lr = 0.001\n",
    "\n",
    "# shapeの確認\n",
    "print('X_1_shape :',X_1.shape)\n",
    "print('coef_shape： 　',coef.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hypothesis_shape： (365,) \n",
      "\n",
      "[0.4512232  0.29614398 0.25713514 0.41216549 0.27303397 0.17193245\n",
      " 0.37897929 0.26174752 0.78403466 0.32382807]\n"
     ]
    }
   ],
   "source": [
    "hypothesis = _linear_hypothesis(X_1,coef)\n",
    "print('hypothesis_shape：',hypothesis.shape,'\\n')\n",
    "print(hypothesis[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題2】最急降下法\n",
    "最急降下法により学習させる実装を行なってください。以下の式で表されるパラメータの更新式のメソッド_gradient_descentを追加し、fitメソッドから呼び出すようにしてください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def _gradient_descent(X,error,lr,coef):\n",
    "    \"\"\"\n",
    "    最急降下法によるパラメータの更新．\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "    データの特徴量\n",
    "    error : 次の形のndarray, shape (n_samples,)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "      次の形のndarray, shape (n_features,)\n",
    "      線形回帰式の切片と重み\n",
    "\n",
    "    \"\"\"\n",
    "    coef = coef - lr/len(X) * np.dot(error,X)\n",
    "    return coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error_shape： (365,)\n",
      "error [ 0.21567671  0.89287055  1.13693103  0.28275769  1.42359183  1.3594124\n",
      " -0.86943848  0.76001519 -6.15134436  0.72609832]\n"
     ]
    }
   ],
   "source": [
    "# 仮データで予測値と実測値の差（error)を確認\n",
    "error = (_linear_hypothesis(X_1,coef)) - y_test_std\n",
    "print('error_shape：',error.shape)\n",
    "print(\"error\",error[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題3】推定\n",
    "推定する仕組みを実装してください。ScratchLinearRegressionクラスの雛形に含まれるpredictメソッドに書き加えてください。\n",
    "\n",
    "仮定関数 hθ(x)の出力が推定結果です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X,theta_array):\n",
    "    \"\"\"\n",
    "    線形回帰を使い推定する。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "        サンプル\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        次の形のndarray, shape (n_samples, 1)\n",
    "        線形回帰による推定結果\n",
    "    \"\"\"\n",
    "    y_pred = np.dot(X,theta_array).reshape(-1,1)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_shape： (365, 1)\n",
      "y_test_shape： (365,)\n",
      "\n",
      "predict：\n",
      " [[0.4512232 ]\n",
      " [0.29614398]\n",
      " [0.25713514]\n",
      " [0.41216549]\n",
      " [0.27303397]\n",
      " [0.17193245]\n",
      " [0.37897929]\n",
      " [0.26174752]\n",
      " [0.78403466]\n",
      " [0.32382807]]\n"
     ]
    }
   ],
   "source": [
    "#仮データで確認\n",
    "y_pred = predict(X_1,coef)\n",
    "print('y_pred_shape：',y_pred.shape)\n",
    "print('y_test_shape：',y_test_std.shape)\n",
    "print('\\npredict：\\n',y_pred[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題4】平均二乗誤差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.1193429939353083\n"
     ]
    }
   ],
   "source": [
    "def MSE(y_pred, y):\n",
    "    \"\"\"\n",
    "    平均二乗誤差の計算\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_pred : 次の形のndarray, shape (n_samples,)\n",
    "      推定した値\n",
    "    y : 次の形のndarray, shape (n_samples,)\n",
    "      正解値\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    mse : numpy.float\n",
    "      平均二乗誤差\n",
    "    \"\"\"\n",
    "    mse = (np.mean((y_pred - y)**2))\n",
    "    \n",
    "    return mse\n",
    "\n",
    "print(\"MSE:\", MSE(y_pred, y_train_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題5】目的関数\n",
    "以下の数式で表される線形回帰の 目的関数（損失関数） を実装してください。そして、これをself.loss, self.val_lossに記録するようにしてください。\n",
    "目的関数（損失関数） J(θ)は次の式です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mse = MSE(y_pred,y_test_std)/2\n",
    "\n",
    "#問題６のクラス内に実装(128行、１６３行)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題6】学習と推定\n",
    "機械学習スクラッチ入門のSprintで用意したHouse Pricesコンペティションのデータに対してスクラッチ実装の学習と推定を行なってください。\n",
    "scikit-learnによる実装と比べ、正しく動いているかを確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchLinearRegression():\n",
    "    \"\"\"\n",
    "    線形回帰のスクラッチ実装\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_iter : int\n",
    "      イテレーション数\n",
    "    lr : float\n",
    "      学習率\n",
    "    no_bias : bool\n",
    "      バイアス項を入れない場合はTrue\n",
    "    verbose : bool\n",
    "      学習過程を出力する場合はTrue\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    self.coef_ : 次の形のndarray, shape (n_features,)\n",
    "      パラメータ\n",
    "    self.loss : 次の形のndarray, shape (self.iter,)\n",
    "      学習用データに対する損失の記録\n",
    "    self.val_loss : 次の形のndarray, shape (self.iter,)\n",
    "      検証用データに対する損失の記録\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_iter, lr, bias, verbose):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.iter = num_iter\n",
    "        self.lr = lr\n",
    "        self.bias = bias\n",
    "        self.verbose = verbose\n",
    "        # 損失を記録する配列を用意\n",
    "        self.loss = np.zeros(self.iter)\n",
    "        self.val_loss = np.zeros(self.iter)\n",
    "\n",
    "        \n",
    "    def _linear_hypothesis(self,X,coef):\n",
    "        \"\"\"\n",
    "        線形の仮定関数を計算する\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "          学習データ\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "          次の形のndarray, shape (n_samples, 1)\n",
    "          線形の仮定関数による推定結果\n",
    "\n",
    "        \"\"\"\n",
    "        hypothesis = np.dot(X,coef)\n",
    "        return hypothesis\n",
    "    \n",
    "    \n",
    "    def _gradient_descent(self,X,coef,error):\n",
    "        \"\"\"\n",
    "        最急降下法によるパラメータの更新．\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "        データの特徴量\n",
    "        error : 次の形のndarray, shape (n_samples,)\n",
    "        \"\"\"\n",
    "        coef = coef - self.lr/len(X) * np.dot(error,X)\n",
    "        return coef\n",
    "    \n",
    "    \n",
    "    def MSE(self,y_pred, y):\n",
    "        \"\"\"\n",
    "        平均二乗誤差の計算\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_pred : 次の形のndarray, shape (n_samples,)\n",
    "          推定した値\n",
    "        y : 次の形のndarray, shape (n_samples,)\n",
    "          正解値\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        mse : numpy.float\n",
    "          平均二乗誤差\n",
    "        \"\"\"\n",
    "        mse = np.mean((y_pred - y)**2)\n",
    "        return mse\n",
    "\n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        線形回帰を学習する。検証用データが入力された場合はそれに対する損失と精度もイテレーションごとに計算する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            学習用データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            学習用データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証用データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証用データの正解値\n",
    "        \"\"\"\n",
    "        \n",
    "        # trainデータ\n",
    "        #バイアス項を入れる場合はXの０列目に１を挿入する\n",
    "        if self.bias is False:\n",
    "            X_new = np.insert(X, 0, 1, axis=1)\n",
    "        #バイアス項を入れない場合はXの０列目に０を挿入する\n",
    "        else:\n",
    "            X_new = np.insert(X, 0, 0, axis=1)\n",
    "\n",
    "        # シータの初期化\n",
    "        self.coef_ = np.random.rand(X_new.shape[1])\n",
    "        # num_iter回更新\n",
    "        for i in range(self.iter):\n",
    "            # 仮定関数\n",
    "            hypothesis = self._linear_hypothesis(X_new,self.coef_)\n",
    "            \n",
    "            # 予測と実測値との誤差\n",
    "            error = hypothesis - y\n",
    "            \n",
    "            # 最急降下法\n",
    "            self.coef_ = self._gradient_descent(X_new,self.coef_,error)\n",
    "            \n",
    "            # lossを記録 （【問題５】目的関数の実装箇所）\n",
    "            self.loss[i] = self.MSE(self._linear_hypothesis(X_new,self.coef_),y)/2\n",
    "        \n",
    "            # 学習過程の出力\n",
    "            if self.verbose is True:\n",
    "                map_result = map(str, self.loss)\n",
    "                result = ',\\n'.join(map_result)                \n",
    "                print('Train Data Loss Iteration{0}: \\n{1}'.format(self.iter,result))\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        \n",
    "        \n",
    "        # 検証用データがある場合\n",
    "        if X_val is not None:\n",
    "            #バイアス項を入れる場合はXの０列目に１を挿入する\n",
    "            if self.bias is False:\n",
    "                X_val_new = np.insert(X_val, 0, 1, axis=1)\n",
    "            #バイアス項を入れない場合、0を挿入する\n",
    "            else:\n",
    "                X_val_new = np.insert(X_val, 0, 0, axis=1)\n",
    "                \n",
    "        # シータの初期化\n",
    "        self.coef_val_ = np.random.rand(X_val_new.shape[1])\n",
    "        # num_iter回更新\n",
    "        for i in range(self.iter):\n",
    "            # 仮定関数\n",
    "            hypothesis_val = self._linear_hypothesis(X_val_new,self.coef_val_)\n",
    "            \n",
    "            # 予測と実測値との誤差\n",
    "            error_val = hypothesis_val - y_val\n",
    "            \n",
    "            # 最急降下法\n",
    "            self.coef_val_ = self._gradient_descent(X_val_new,self.coef_val_,error_val)\n",
    "            \n",
    "            # lossを記録　 （【問題５】目的関数の実装箇所）\n",
    "            self.val_loss[i] = self.MSE(self._linear_hypothesis(X_val_new,self.coef_val_),y_val)/2\n",
    "        \n",
    "            # 学習過程の出力\n",
    "            if self.verbose is True:\n",
    "                map_result_val = map(str, self.val_loss)\n",
    "                result_val = ',\\n'.join(map_result_val)                \n",
    "                print('\\nTest Data Loss Iteration{0}: \\n{1}'.format(self.iter,result_val))\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "            \n",
    "    def predict(self,X):\n",
    "        \"\"\"\n",
    "        線形回帰を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "        サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        次の形のndarray, shape (n_samples, 1)\n",
    "        線形回帰による推定結果\n",
    "        \"\"\"\n",
    "        #バイアス項を入れる場合はXの０列目に１を挿入する\n",
    "        if self.bias is False:\n",
    "            X_add = np.insert(X, 0, 1, axis=1)\n",
    "        #バイアス項を入れない場合、0を挿入する\n",
    "        else:\n",
    "            X_add = np.insert(X, 0, 0, axis=1)\n",
    "            \n",
    "        y_pred = np.dot(X_add,self.coef_).reshape(-1,1)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初期化，学習\n",
    "slr=ScratchLinearRegression(num_iter=5000, lr=0.001, bias=False ,verbose=False)\n",
    "slr.fit(X=X_train_std, y=y_train_std, X_val=X_test_std, y_val=y_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred:\n",
      " [[ 1.33989710e+00]\n",
      " [ 9.00106658e-02]\n",
      " [-3.96774481e-01]\n",
      " [ 7.07061744e-01]\n",
      " [-5.24868613e-01]\n",
      " [-6.70410180e-01]\n",
      " [-2.78759648e-03]\n",
      " [-1.81241299e-01]\n",
      " [ 3.96053148e+00]\n",
      " [-4.82892826e-01]]\n"
     ]
    }
   ],
   "source": [
    "# 推定\n",
    "y_pred_train = slr.predict(X_train_std)\n",
    "y_pred = slr.predict(X_test_std)\n",
    "print('y_pred:\\n',y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_MSE： 1.532636986644203\n",
      "Test_MSE： 1.536583533200892\n",
      "切片： 0.11783911168929005\n",
      "係数： [0.60181832 0.39798896]\n"
     ]
    }
   ],
   "source": [
    "print('Train_MSE：',slr.MSE(y_pred_train,y_train_std))\n",
    "print('Test_MSE：',slr.MSE(y_pred,y_test_std))\n",
    "print('切片：',slr.coef_[0])\n",
    "print('係数：',slr.coef_[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SKlean　LinearRegressionと比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_MSE： 0.3230340002216025\n",
      "Test_MSE： 0.41002698832759593\n",
      "切片： -2.690696506883759\n",
      "係数： [0.53730804 5.67444994]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# 初期化，学習，推定\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_std,y_train_std)\n",
    "y_train_pred_sk = model.predict(X_train_std)\n",
    "y_pred_sk = model.predict(X_test_std)\n",
    "\n",
    "print('Train_MSE：',mean_squared_error(y_train_std,y_train_pred_sk))\n",
    "print('Test_MSE：',mean_squared_error(y_test_std,y_pred_sk))\n",
    "print('切片：',model.intercept_)\n",
    "print('係数：',model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題7】学習曲線のプロット\n",
    "学習曲線を表示する関数を作成し、実行してください。グラフを見て損失が適切に下がっているかどうか確認してください。\n",
    "線形回帰クラスの雛形ではself.loss, self.val_lossに損失を記録しておくようになっているため、入力にはこれを利用してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(np.array(range(slr.iter)), slr.loss, label=\"loss\")\n",
    "plt.scatter(np.array(range(slr.iter)), slr.val_loss, label=\"val_loss\")\n",
    "\n",
    "plt.title(\"model loss\")\n",
    "plt.xlabel(\"iter\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sprint ディープラーニングフレームワーク２"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6751, 0.1172, 0.0151],\n",
      "        [0.7519, 0.5183, 0.5196],\n",
      "        [0.9554, 0.7281, 0.8209],\n",
      "        [0.9737, 0.1615, 0.0451],\n",
      "        [0.2109, 0.0674, 0.3450]])\n"
     ]
    }
   ],
   "source": [
    "#pytorchをインポート\n",
    "from __future__ import print_function\n",
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】公式Exampleを分担して実行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "映画レビューのテキスト分類{こちらを発表}\n",
    "https://www.tensorflow.org/tutorials/keras/basic_text_classification\n",
    "\n",
    "ファッションMNIST\n",
    "https://www.tensorflow.org/tutorials/keras/basic_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】Iris（2値分類）をKerasで学習\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0909 19:36:54.631028 4522440128 deprecation.py:506] From /Users/suginokaori/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0909 19:36:54.755372 4522440128 deprecation.py:323] From /Users/suginokaori/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 5\n",
      "Trainable params: 5\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "80/80 [==============================] - 0s 6ms/sample - loss: 0.7326 - acc: 0.5125\n",
      "Epoch 2/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.7223 - acc: 0.4875\n",
      "Epoch 3/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.6845 - acc: 0.5000\n",
      "Epoch 4/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.6323 - acc: 0.6125\n",
      "Epoch 5/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.6367 - acc: 0.6375\n",
      "Epoch 6/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.6196 - acc: 0.6375\n",
      "Epoch 7/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.6078 - acc: 0.6875\n",
      "Epoch 8/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.5923 - acc: 0.6875\n",
      "Epoch 9/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.5900 - acc: 0.7125\n",
      "Epoch 10/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.5577 - acc: 0.8000\n",
      "Epoch 11/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.5386 - acc: 0.7875\n",
      "Epoch 12/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.5228 - acc: 0.7750\n",
      "Epoch 13/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.5181 - acc: 0.7875\n",
      "Epoch 14/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.5181 - acc: 0.8375\n",
      "Epoch 15/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.4880 - acc: 0.8625\n",
      "Epoch 16/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.4682 - acc: 0.8625\n",
      "Epoch 17/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.4683 - acc: 0.9000\n",
      "Epoch 18/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.4514 - acc: 0.8875\n",
      "Epoch 19/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.4487 - acc: 0.8750\n",
      "Epoch 20/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.4439 - acc: 0.8875\n",
      "Epoch 21/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.4297 - acc: 0.8500\n",
      "Epoch 22/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.4199 - acc: 0.8750\n",
      "Epoch 23/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.3978 - acc: 0.9500\n",
      "Epoch 24/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.3954 - acc: 0.9125\n",
      "Epoch 25/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.3877 - acc: 0.9250\n",
      "Epoch 26/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.3782 - acc: 0.9250\n",
      "Epoch 27/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.3780 - acc: 0.9500\n",
      "Epoch 28/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.3618 - acc: 0.9375\n",
      "Epoch 29/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.3720 - acc: 0.9000\n",
      "Epoch 30/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.3527 - acc: 0.9375\n",
      "Epoch 31/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.3422 - acc: 0.9250\n",
      "Epoch 32/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.3388 - acc: 0.9250\n",
      "Epoch 33/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.3397 - acc: 0.9125\n",
      "Epoch 34/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.3149 - acc: 0.9500\n",
      "Epoch 35/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.3387 - acc: 0.9375\n",
      "Epoch 36/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.3249 - acc: 0.9375\n",
      "Epoch 37/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.3073 - acc: 0.9375\n",
      "Epoch 38/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.3014 - acc: 0.9375\n",
      "Epoch 39/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.3091 - acc: 0.9375\n",
      "Epoch 40/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2944 - acc: 0.9250\n",
      "Epoch 41/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2929 - acc: 0.9375\n",
      "Epoch 42/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2870 - acc: 0.9375\n",
      "Epoch 43/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2781 - acc: 0.9125\n",
      "Epoch 44/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2770 - acc: 0.9500\n",
      "Epoch 45/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2798 - acc: 0.9500\n",
      "Epoch 46/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2688 - acc: 0.9375\n",
      "Epoch 47/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2644 - acc: 0.9750\n",
      "Epoch 48/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2610 - acc: 0.9250\n",
      "Epoch 49/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2586 - acc: 0.9500\n",
      "Epoch 50/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2532 - acc: 0.9500\n",
      "Epoch 51/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2456 - acc: 0.9500\n",
      "Epoch 52/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2447 - acc: 0.9375\n",
      "Epoch 53/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2461 - acc: 0.9750\n",
      "Epoch 54/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2367 - acc: 0.9375\n",
      "Epoch 55/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2400 - acc: 0.9500\n",
      "Epoch 56/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2333 - acc: 0.9625\n",
      "Epoch 57/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2287 - acc: 0.9625\n",
      "Epoch 58/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2276 - acc: 0.9625\n",
      "Epoch 59/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2280 - acc: 0.9625\n",
      "Epoch 60/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2194 - acc: 0.9625\n",
      "Epoch 61/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2211 - acc: 0.9500\n",
      "Epoch 62/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2161 - acc: 0.9750\n",
      "Epoch 63/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2115 - acc: 0.9625\n",
      "Epoch 64/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2188 - acc: 0.9250\n",
      "Epoch 65/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2099 - acc: 0.9625\n",
      "Epoch 66/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2108 - acc: 0.9500\n",
      "Epoch 67/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2065 - acc: 0.9500\n",
      "Epoch 68/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2042 - acc: 0.9625\n",
      "Epoch 69/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2039 - acc: 0.9625\n",
      "Epoch 70/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2033 - acc: 0.9625\n",
      "Epoch 71/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2003 - acc: 0.9625\n",
      "Epoch 72/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1987 - acc: 0.9625\n",
      "Epoch 73/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.2012 - acc: 0.9500\n",
      "Epoch 74/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1857 - acc: 0.9500\n",
      "Epoch 75/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1955 - acc: 0.9500\n",
      "Epoch 76/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1956 - acc: 0.9500\n",
      "Epoch 77/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1857 - acc: 0.9750\n",
      "Epoch 78/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1935 - acc: 0.9375\n",
      "Epoch 79/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1834 - acc: 0.9625\n",
      "Epoch 80/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1855 - acc: 0.9500\n",
      "Epoch 81/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1797 - acc: 0.9500\n",
      "Epoch 82/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1825 - acc: 0.9625\n",
      "Epoch 83/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1833 - acc: 0.9625\n",
      "Epoch 84/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1825 - acc: 0.9250\n",
      "Epoch 85/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1778 - acc: 0.9500\n",
      "Epoch 86/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1631 - acc: 0.9875\n",
      "Epoch 87/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1728 - acc: 0.9500\n",
      "Epoch 88/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1721 - acc: 0.9500\n",
      "Epoch 89/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1731 - acc: 0.9500\n",
      "Epoch 90/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1715 - acc: 0.9500\n",
      "Epoch 91/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1705 - acc: 0.9625\n",
      "Epoch 92/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1654 - acc: 0.9750\n",
      "Epoch 93/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1625 - acc: 0.9625\n",
      "Epoch 94/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1601 - acc: 0.9625\n",
      "Epoch 95/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1598 - acc: 0.9625\n",
      "Epoch 96/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1653 - acc: 0.9500\n",
      "Epoch 97/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1598 - acc: 0.9500\n",
      "Epoch 98/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1591 - acc: 0.9500\n",
      "Epoch 99/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1553 - acc: 0.9625\n",
      "Epoch 100/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1567 - acc: 0.9750\n",
      "Epoch 101/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1600 - acc: 0.9625\n",
      "Epoch 102/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1552 - acc: 0.9500\n",
      "Epoch 103/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1563 - acc: 0.9500\n",
      "Epoch 104/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1521 - acc: 0.9500\n",
      "Epoch 105/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1504 - acc: 0.9500\n",
      "Epoch 106/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1570 - acc: 0.9625\n",
      "Epoch 107/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1478 - acc: 0.9750\n",
      "Epoch 108/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1523 - acc: 0.9625\n",
      "Epoch 109/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1588 - acc: 0.9500\n",
      "Epoch 110/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1470 - acc: 0.9500\n",
      "Epoch 111/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1461 - acc: 0.9500\n",
      "Epoch 112/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1451 - acc: 0.9375\n",
      "Epoch 113/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1423 - acc: 0.9625\n",
      "Epoch 114/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1490 - acc: 0.9625\n",
      "Epoch 115/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1529 - acc: 0.9500\n",
      "Epoch 116/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1405 - acc: 0.9625\n",
      "Epoch 117/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1364 - acc: 0.9625\n",
      "Epoch 118/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1382 - acc: 0.9500\n",
      "Epoch 119/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1435 - acc: 0.9625\n",
      "Epoch 120/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1422 - acc: 0.9625\n",
      "Epoch 121/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1422 - acc: 0.9750\n",
      "Epoch 122/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1425 - acc: 0.9500\n",
      "Epoch 123/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1341 - acc: 0.9625\n",
      "Epoch 124/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1321 - acc: 0.9500\n",
      "Epoch 125/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1298 - acc: 0.9625\n",
      "Epoch 126/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1448 - acc: 0.9625\n",
      "Epoch 127/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1363 - acc: 0.9750\n",
      "Epoch 128/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1311 - acc: 0.9625\n",
      "Epoch 129/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1301 - acc: 0.9500\n",
      "Epoch 130/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1350 - acc: 0.9625\n",
      "Epoch 131/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1283 - acc: 0.9625\n",
      "Epoch 132/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1336 - acc: 0.9625\n",
      "Epoch 133/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1392 - acc: 0.9625\n",
      "Epoch 134/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1242 - acc: 0.9500\n",
      "Epoch 135/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1272 - acc: 0.9625\n",
      "Epoch 136/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1283 - acc: 0.9500\n",
      "Epoch 137/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1259 - acc: 0.9500\n",
      "Epoch 138/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1243 - acc: 0.9625\n",
      "Epoch 139/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1285 - acc: 0.9750\n",
      "Epoch 140/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1249 - acc: 0.9625\n",
      "Epoch 141/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1235 - acc: 0.9625\n",
      "Epoch 142/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1260 - acc: 0.9500\n",
      "Epoch 143/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1228 - acc: 0.9500\n",
      "Epoch 144/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1209 - acc: 0.9625\n",
      "Epoch 145/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1198 - acc: 0.9625\n",
      "Epoch 146/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1215 - acc: 0.9500\n",
      "Epoch 147/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1207 - acc: 0.9625\n",
      "Epoch 148/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1198 - acc: 0.9500\n",
      "Epoch 149/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1111 - acc: 0.9750\n",
      "Epoch 150/150\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.1289 - acc: 0.9750\n",
      "y_pred_proba [0.11507636 0.99411976 0.09593958 0.99557865 0.85903966 0.9948893\n",
      " 0.2166327  0.8519713  0.9955282  0.9858818  0.94800913 0.97199416\n",
      " 0.9934791  0.15098354 0.00865546 0.02715629 0.616374   0.02224818\n",
      " 0.79660237 0.03675196]\n",
      "y_pred [0 1 0 1 1 1 0 1 1 1 1 1 1 0 0 0 1 0 1 0]\n",
      "y_test [[0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "Train loss: 0.11270956695079803\n",
      "Train accuracy: 0.975\n"
     ]
    }
   ],
   "source": [
    "# ANDゲートの学習データを用意\n",
    "\n",
    "# データセットの読み込み\n",
    "dataset_path =\"Iris.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "# データフレームから条件抽出\n",
    "df = df[(df[\"Species\"] == \"Iris-versicolor\")|(df[\"Species\"] == \"Iris-virginica\")]\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "# ラベルを数値に変換\n",
    "y[y=='Iris-versicolor'] = 0\n",
    "y[y=='Iris-virginica'] = 1\n",
    "y = y.astype(np.int)[:, np.newaxis]\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "model = tf.keras.Sequential([tf.keras.layers.Dense(1, activation = tf.nn.sigmoid, input_shape=(4,))])\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.train.AdamOptimizer(learning_rate=0.01),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=1,\n",
    "                    epochs=150,\n",
    "                    verbose=1)\n",
    "y_pred_proba = model.predict(X_test)[:, 0]\n",
    "\n",
    "# 確率を0, 1に変換\n",
    "y_pred = np.where(y_pred_proba >0.5, 1, 0)\n",
    "\n",
    "print(\"y_pred_proba\", y_pred_proba)\n",
    "print(\"y_pred\", y_pred)\n",
    "print(\"y_test\", y_test)\n",
    "\n",
    "score = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Train loss:', score[0])\n",
    "print('Train accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題3】Iris（多値分類）をKerasで学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functional API 4層のニューラルネットワーク"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                50        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 303\n",
      "Trainable params: 303\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "120/120 [==============================] - 0s 3ms/sample - loss: 0.7601 - acc: 0.6417\n",
      "Epoch 2/20\n",
      "120/120 [==============================] - 0s 1ms/sample - loss: 0.2793 - acc: 0.8750\n",
      "Epoch 3/20\n",
      "120/120 [==============================] - 0s 1ms/sample - loss: 0.4843 - acc: 0.7917\n",
      "Epoch 4/20\n",
      "120/120 [==============================] - 0s 1ms/sample - loss: 0.2743 - acc: 0.8917\n",
      "Epoch 5/20\n",
      "120/120 [==============================] - 0s 1ms/sample - loss: 0.1967 - acc: 0.9250\n",
      "Epoch 6/20\n",
      "120/120 [==============================] - 0s 1ms/sample - loss: 0.1688 - acc: 0.9250\n",
      "Epoch 7/20\n",
      "120/120 [==============================] - 0s 1ms/sample - loss: 0.1866 - acc: 0.9250\n",
      "Epoch 8/20\n",
      "120/120 [==============================] - 0s 1ms/sample - loss: 0.2085 - acc: 0.9000\n",
      "Epoch 9/20\n",
      "120/120 [==============================] - 0s 1ms/sample - loss: 0.0900 - acc: 0.9833\n",
      "Epoch 10/20\n",
      "120/120 [==============================] - 0s 1ms/sample - loss: 0.1653 - acc: 0.9333\n",
      "Epoch 11/20\n",
      "120/120 [==============================] - 0s 1ms/sample - loss: 0.1838 - acc: 0.9250\n",
      "Epoch 12/20\n",
      "120/120 [==============================] - 0s 1ms/sample - loss: 0.2118 - acc: 0.9333\n",
      "Epoch 13/20\n",
      "120/120 [==============================] - 0s 1ms/sample - loss: 0.1091 - acc: 0.9583\n",
      "Epoch 14/20\n",
      "120/120 [==============================] - 0s 1ms/sample - loss: 0.1251 - acc: 0.9333\n",
      "Epoch 15/20\n",
      "120/120 [==============================] - 0s 1ms/sample - loss: 0.1116 - acc: 0.9583\n",
      "Epoch 16/20\n",
      "120/120 [==============================] - 0s 1ms/sample - loss: 0.1072 - acc: 0.9583\n",
      "Epoch 17/20\n",
      "120/120 [==============================] - 0s 1ms/sample - loss: 0.1006 - acc: 0.9500\n",
      "Epoch 18/20\n",
      "120/120 [==============================] - 0s 1ms/sample - loss: 0.2222 - acc: 0.9083\n",
      "Epoch 19/20\n",
      "120/120 [==============================] - 0s 1ms/sample - loss: 0.1460 - acc: 0.9417\n",
      "Epoch 20/20\n",
      "120/120 [==============================] - 0s 1ms/sample - loss: 0.1320 - acc: 0.9417\n",
      "y_pred_proba [[8.19363073e-03 9.91806388e-01 2.69978417e-09]\n",
      " [9.85064805e-01 1.38417641e-02 1.09338749e-03]\n",
      " [8.01077113e-06 5.99940080e-08 9.99991894e-01]\n",
      " [1.40519431e-02 9.85948086e-01 1.65151715e-08]\n",
      " [4.08177330e-05 2.76966517e-07 9.99958873e-01]\n",
      " [2.77244928e-03 9.97227490e-01 7.20649165e-11]\n",
      " [4.73412292e-05 3.35594592e-07 9.99952316e-01]\n",
      " [9.57212806e-01 4.05436754e-02 2.24345131e-03]\n",
      " [9.06269491e-01 9.09217969e-02 2.80866190e-03]\n",
      " [9.86401379e-01 1.26420939e-02 9.56513453e-04]\n",
      " [1.09057337e-01 8.90935540e-01 7.08548805e-06]\n",
      " [9.75789309e-01 2.24270746e-02 1.78363197e-03]\n",
      " [9.63764727e-01 3.41644660e-02 2.07073847e-03]\n",
      " [8.92609358e-01 1.04523085e-01 2.86759599e-03]\n",
      " [9.19950485e-01 7.73687661e-02 2.68079434e-03]\n",
      " [2.56460444e-05 1.55277803e-07 9.99974251e-01]\n",
      " [9.23934042e-01 7.34006837e-02 2.66523217e-03]\n",
      " [9.59544301e-01 3.82796898e-02 2.17597513e-03]\n",
      " [1.07456726e-04 7.05379989e-07 9.99891877e-01]\n",
      " [3.33320313e-05 2.56516870e-07 9.99966383e-01]\n",
      " [6.02478087e-02 9.39750552e-01 1.66326856e-06]\n",
      " [9.26063597e-01 7.12798908e-02 2.65659788e-03]\n",
      " [2.25259137e-04 1.71281022e-06 9.99773085e-01]\n",
      " [1.54232286e-04 1.01066132e-06 9.99844790e-01]\n",
      " [2.90756077e-01 7.09150374e-01 9.35324351e-05]\n",
      " [2.85630085e-05 2.02002497e-07 9.99971271e-01]\n",
      " [4.25566977e-04 3.82291546e-06 9.99570549e-01]\n",
      " [9.83768404e-01 1.50030078e-02 1.22853648e-03]\n",
      " [9.91166413e-01 8.31310824e-03 5.20531961e-04]\n",
      " [2.32990991e-04 1.79608105e-06 9.99765217e-01]]\n",
      "y_pred [1 0 2 1 2 1 2 0 0 0 1 0 0 0 0 2 0 0 2 2 1 0 2 2 1 2 2 0 0 2]\n",
      "y_test [1 0 2 1 2 1 2 0 0 0 1 0 0 0 0 2 0 0 2 2 1 0 2 2 1 2 2 0 0 2]\n",
      "Train loss: 0.039987143129110336\n",
      "Train accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "#セッションクリア\n",
    "K.clear_session()\n",
    "\n",
    "# データセットの読み込み\n",
    "dataset_path =\"Iris.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "# データフレームから条件抽出\n",
    "#df = df[(df[\"Species\"] == \"Iris-versicolor\")|(df[\"Species\"] == \"Iris-virginica\")]\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "# ラベルを数値に変換\n",
    "y[y=='Iris-versicolor'] = 0\n",
    "y[y=='Iris-virginica'] = 1\n",
    "y[y=='Iris-setosa'] = 2\n",
    "y = y.astype(np.int)#[:, np.newaxis]\n",
    "#print(y.shape)\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# # さらにtrainとvalに分割\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "# print(X_test.shape)\n",
    "\n",
    "# yをone-hot表現に変換\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "#y_val_one_hot = enc.transform(y_val[:, np.newaxis])\n",
    "#print(y_train_one_hot.shape)\n",
    "\n",
    "# Functional API 4層のニューラルネットワーク\n",
    "input_data = tf.keras.layers.Input(shape=(4,))\n",
    "X = tf.keras.layers.Dense(10, activation=tf.nn.relu)(input_data)\n",
    "X = tf.keras.layers.Dense(10, activation=tf.nn.relu)(X)\n",
    "X = tf.keras.layers.Dense(10, activation=tf.nn.relu)(X)\n",
    "output = tf.keras.layers.Dense(3, activation=tf.nn.softmax)(X)\n",
    "model = tf.keras.Model(inputs=input_data, outputs=output)\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.train.AdamOptimizer(learning_rate=0.01),\n",
    "              metrics=['accuracy']) #多値分類なのでカテゴリカルクロスエントロピー\n",
    "history = model.fit(X_train, y_train_one_hot,\n",
    "                    batch_size=1,\n",
    "                    epochs=20,\n",
    "                    verbose=1)\n",
    "y_pred_proba = model.predict(X_test)#[:, 0]\n",
    "\n",
    "# 最大値のインデックスで推定値を求める\n",
    "y_pred = np.argmax(y_pred_proba,axis=1)\n",
    "\n",
    "print(\"y_pred_proba\", y_pred_proba)\n",
    "print(\"y_pred\", y_pred)\n",
    "print(\"y_test\", y_test)\n",
    "\n",
    "score = model.evaluate(X_test, y_test_one_hot, verbose=0)\n",
    "print('Train loss:', score[0])\n",
    "print('Train accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題4】House PricesをKerasで学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0909 21:55:46.179713 4440098240 deprecation_wrapper.py:119] From /Users/suginokaori/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0909 21:55:46.182718 4440098240 deprecation_wrapper.py:119] From /Users/suginokaori/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0909 21:55:46.210266 4440098240 deprecation_wrapper.py:119] From /Users/suginokaori/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test(292, 2)\n",
      "X_train(934, 2)\n",
      "y_train(934, 1)\n",
      "X_val(934, 2)\n",
      "y_val(234, 1)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 3\n",
      "Trainable params: 3\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 69.1448 - mean_squared_error: 69.1448\n",
      "Epoch 2/10\n",
      "934/934 [==============================] - 1s 831us/step - loss: 7.1056 - mean_squared_error: 7.1056\n",
      "Epoch 3/10\n",
      "934/934 [==============================] - 1s 824us/step - loss: 0.2270 - mean_squared_error: 0.2270\n",
      "Epoch 4/10\n",
      "934/934 [==============================] - 1s 843us/step - loss: 0.0479 - mean_squared_error: 0.0479\n",
      "Epoch 5/10\n",
      "934/934 [==============================] - 1s 831us/step - loss: 0.0480 - mean_squared_error: 0.0480\n",
      "Epoch 6/10\n",
      "934/934 [==============================] - 1s 817us/step - loss: 0.0487 - mean_squared_error: 0.0487\n",
      "Epoch 7/10\n",
      "934/934 [==============================] - 1s 860us/step - loss: 0.0496 - mean_squared_error: 0.0496\n",
      "Epoch 8/10\n",
      "934/934 [==============================] - 1s 823us/step - loss: 0.0496 - mean_squared_error: 0.0496\n",
      "Epoch 9/10\n",
      "934/934 [==============================] - 1s 827us/step - loss: 0.0518 - mean_squared_error: 0.0518\n",
      "Epoch 10/10\n",
      "934/934 [==============================] - 1s 838us/step - loss: 0.0499 - mean_squared_error: 0.0499\n",
      "y_pred_proba：推定値\n",
      " [12.444006  11.84497   11.691387  12.287783  11.748488  11.369219\n",
      " 12.152148  11.712205  13.728542  11.938512  12.085649  12.0962105\n",
      " 12.389631  11.621705  11.6144    11.790903  12.317849  11.8216715\n",
      " 11.794477  11.834401 ]\n",
      "y_test：正解値\n",
      " [[12.20918779]\n",
      " [11.79810441]\n",
      " [11.60823564]\n",
      " [12.16525065]\n",
      " [11.38509209]\n",
      " [11.35040654]\n",
      " [12.55292652]\n",
      " [11.85651517]\n",
      " [13.5211395 ]\n",
      " [11.9103584 ]\n",
      " [12.24961095]\n",
      " [11.82704253]\n",
      " [12.32385568]\n",
      " [11.71993963]\n",
      " [11.68855803]\n",
      " [11.88448902]\n",
      " [12.15477935]\n",
      " [11.72480582]\n",
      " [11.91404782]\n",
      " [11.9511804 ]]\n",
      "Train loss: 0.05235465706926342\n",
      "Train mse: 0.05235465706926342\n"
     ]
    }
   ],
   "source": [
    "#ラッパーとしてのkeras Sequentialモデルは以下のように書けます。ロジスティック回帰の例です。\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "#データの読み込み\n",
    "Ames = pd.read_csv(\"train.csv\")\n",
    "Ames.head(4)\n",
    "\n",
    "# GrLivAreaとYearBuiltと目的変数SalePriceを抜き出す\n",
    "Ames = Ames.loc[:, [\"GrLivArea\", \"YearBuilt\", \"SalePrice\"]]\n",
    "Ames.head()\n",
    "\n",
    "# データフレームから条件抽出\n",
    "X = Ames.loc[:, [\"GrLivArea\", \"YearBuilt\"]]\n",
    "y = Ames[\"SalePrice\"]\n",
    "y = np.array(y)[:, np.newaxis]\n",
    "X = np.array(X)\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "print(\"X_test{}\".format(X_test.shape))\n",
    "print(\"X_train{}\".format(X_train.shape))\n",
    "print(\"y_train{}\".format(y_train.shape))\n",
    "print(\"X_val{}\".format(X_train.shape))\n",
    "print(\"y_val{}\".format(y_val.shape))\n",
    "\n",
    "# 特徴量データを正規化する\n",
    "mean_train = X_train.mean(axis=0)\n",
    "std_train = X_train.std(axis=0)\n",
    "X_train = (X_train - mean_train) / std_train\n",
    "mean_test = X_test.mean(axis=0)\n",
    "std_test = X_test.std(axis=0)\n",
    "X_test = (X_test - mean_test) / std_test\n",
    "mean_val = X_val.mean(axis=0)\n",
    "std_val = X_val.std(axis=0)\n",
    "X_val = (X_val - mean_val) / std_val\n",
    "\n",
    "y_test = np.log(y_test)\n",
    "y_train = np.log(y_train)\n",
    "y_val = np.log(y_val)\n",
    "\n",
    "\n",
    "input_data = tf.keras.layers.Input(shape=(2,)) # 入力層\n",
    "output = tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)(input_data) # 出力層\n",
    "\n",
    "model = tf.keras.Model(inputs=input_data, outputs=output)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_shape=(2,)))\n",
    "#model.add(Activation('sigmoid'))#不要？\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=Adam(lr=0.01),\n",
    "              metrics=['mse'])\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=1,\n",
    "                    epochs=10,\n",
    "                    verbose=1)\n",
    "\n",
    "y_pred_proba = model.predict(X_test)[:, 0]\n",
    "\n",
    "\n",
    "print(\"y_pred_proba：推定値\\n\", y_pred_proba[:20])\n",
    "print(\"y_test：正解値\\n\", y_test[:20])\n",
    "\n",
    "score = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Train loss:', score[0])\n",
    "print('Train mse:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題5】MNISTをKerasで学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                7850      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                110       \n",
      "=================================================================\n",
      "Total params: 8,180\n",
      "Trainable params: 8,180\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 4s 75us/sample - loss: 0.5012 - acc: 0.8502\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 3s 69us/sample - loss: 0.3606 - acc: 0.8986\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 3s 69us/sample - loss: 0.3341 - acc: 0.9057\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 3s 70us/sample - loss: 0.3165 - acc: 0.9108\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 3s 71us/sample - loss: 0.3116 - acc: 0.9144\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 4s 82us/sample - loss: 0.3006 - acc: 0.9163\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 4s 79us/sample - loss: 0.3000 - acc: 0.9180\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.2905 - acc: 0.9208\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 4s 83us/sample - loss: 0.2890 - acc: 0.9211\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 4s 78us/sample - loss: 0.2835 - acc: 0.9217\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 4s 77us/sample - loss: 0.2805 - acc: 0.9243\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 4s 75us/sample - loss: 0.2789 - acc: 0.9244\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 3s 71us/sample - loss: 0.2792 - acc: 0.9256\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 3s 72us/sample - loss: 0.2736 - acc: 0.9265\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 3s 73us/sample - loss: 0.2706 - acc: 0.9267\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 3s 73us/sample - loss: 0.2706 - acc: 0.9290\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 3s 70us/sample - loss: 0.2673 - acc: 0.9301\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 3s 72us/sample - loss: 0.2675 - acc: 0.9280\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 3s 71us/sample - loss: 0.2656 - acc: 0.9306\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 3s 71us/sample - loss: 0.2673 - acc: 0.9300\n",
      "y_pred_proba\n",
      " [[4.06276911e-07 7.69309736e-06 6.97001087e-05 ... 9.99591410e-01\n",
      "  1.81299722e-08 3.25012399e-04]\n",
      " [1.15315453e-03 1.05795695e-03 9.57722068e-01 ... 1.10740412e-03\n",
      "  1.02824150e-02 1.21509656e-05]\n",
      " [2.01631565e-07 9.98508275e-01 8.92022763e-06 ... 2.62519211e-06\n",
      "  1.25102396e-03 1.20442555e-05]\n",
      " ...\n",
      " [6.17339319e-05 1.49271344e-07 9.60285179e-05 ... 3.59650527e-04\n",
      "  2.55364540e-07 1.10527046e-03]\n",
      " [1.16970725e-02 7.14208232e-03 1.14883035e-02 ... 9.70175006e-06\n",
      "  1.62777044e-02 2.25322624e-03]\n",
      " [4.24565573e-04 3.18841671e-07 1.76959438e-04 ... 1.29670458e-11\n",
      "  3.38487844e-05 4.52333088e-10]]\n",
      "y_pred(予測値)[7 2 1 0 4 1 4 9 4 9 0 6 9 0 1 5 9 7 2 4]\n",
      "y_test（正解） [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4]\n",
      "Train loss: 0.24099342575172583\n",
      "Train accuracy: 0.93572915\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "KerasのFunctional API 4層のニューラルネットワークで実装したニューラルネットワークを使いMNISTを多値分類する\n",
    "\"\"\"\n",
    "K.clear_session()\n",
    "# データセットの読み込み\n",
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# データセットを確認\n",
    "# print(X_train.shape) # (60000, 28, 28)\n",
    "# print(X_test.shape) # (10000, 28, 28)\n",
    "# print(X_train[0].dtype) # uint8\n",
    "#print(X_train[0])\n",
    "\n",
    "#平滑化\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "#２２５で割る\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255 # 全て２５５で割っている\n",
    "X_test /= 255\n",
    "\n",
    "#trainをさらに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "# print(X_train.shape) # (48000, 784)\n",
    "# print(X_val.shape) # (12000, 784)\n",
    "\n",
    "# yをone-hot表現に変換\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "y_val_one_hot = enc.transform(y_val[:, np.newaxis])\n",
    "# print(y_train.shape) # (60000,)\n",
    "# print(y_train_one_hot.shape) # (60000, 10)\n",
    "# print(y_test_one_hot.dtype) # float64\n",
    "# print(y_val_one_hot.dtype) # float64\n",
    "    \n",
    "# Functional API 4層のニューラルネットワーク\n",
    "input_data = tf.keras.layers.Input(shape=(784,))\n",
    "X = tf.keras.layers.Dense(10, activation=tf.nn.relu)(input_data)\n",
    "X = tf.keras.layers.Dense(10, activation=tf.nn.relu)(X)\n",
    "X = tf.keras.layers.Dense(10, activation=tf.nn.relu)(X)\n",
    "output = tf.keras.layers.Dense(10, activation=tf.nn.softmax)(X)\n",
    "model = tf.keras.Model(inputs=input_data, outputs=output)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.train.AdamOptimizer(learning_rate=0.01),\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train_one_hot,\n",
    "                    batch_size=20,\n",
    "                    epochs=20,\n",
    "                    verbose=1)\n",
    "y_pred_proba = model.predict(X_test)\n",
    "\n",
    "#最大値のインデックスを取る\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "print(\"y_pred_proba\\n\", y_pred_proba)\n",
    "print(\"y_pred(予測値)\", y_pred[:20],sep=\"\")\n",
    "print(\"y_test（正解）\", y_test[:20])\n",
    "\n",
    "score = model.evaluate(X_train, y_train_one_hot, verbose=0)\n",
    "print('Train loss:', score[0])\n",
    "print('Train accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題6】（アドバンス課題）PyTorchへの書き換え"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 【問題3】Iris（多値分類）をKerasで学習 →PyTorchに書き換え"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自力で書くのは時間がかかりそうだったので、下記のサイトを写経して、何をしているか読み解きをしてコメントをつけて学習しました m(_ _)m\n",
    "\n",
    "http://aidiary.hatenablog.com/entry/20180225/1519520981"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n",
      "[[6.3 2.5 5.  1.9]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "[2 0 0 0 0 1 1 1 1 2]\n",
      "[-2.47274423e-15 -3.31956684e-16 -2.31481501e-16 -1.90125693e-16]\n",
      "[1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# データセットの読み込み（下のやり方より簡単）\n",
    "iris = load_iris()\n",
    "X = iris.data #.dataでデータ本体を取得\n",
    "y = iris.target # .targetでクラスラベルが取得できる\n",
    "print(X.shape)  # (150, 4)\n",
    "print(y.shape)  # (150, )\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=5)\n",
    "\n",
    "print(X_train[:10])\n",
    "print(y_train[:10])\n",
    "\n",
    "# データの標準化\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "print(np.mean(X_train, axis=0))  # [ -2.47274423e-15   3.85247390e-16  -4.26603197e-16  -7.66053887e-17]\n",
    "print(np.std(X_train, axis=0))   # [ 1.  1.  1.  1.]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss: 1.3813 val_loss: 1.3212 val_acc: 0.0200\n",
      "epoch 1000, loss: 0.3441 val_loss: 0.3418 val_acc: 0.9200\n",
      "epoch 2000, loss: 0.2640 val_loss: 0.2714 val_acc: 0.9200\n",
      "epoch 3000, loss: 0.2190 val_loss: 0.2345 val_acc: 0.9400\n",
      "epoch 4000, loss: 0.1893 val_loss: 0.2102 val_acc: 0.9400\n",
      "epoch 5000, loss: 0.1682 val_loss: 0.1927 val_acc: 0.9400\n",
      "epoch 6000, loss: 0.1524 val_loss: 0.1794 val_acc: 0.9400\n",
      "epoch 7000, loss: 0.1401 val_loss: 0.1689 val_acc: 0.9400\n",
      "epoch 8000, loss: 0.1303 val_loss: 0.1604 val_acc: 0.9400\n",
      "epoch 9000, loss: 0.1222 val_loss: 0.1534 val_acc: 0.9400\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "input_size = 4\n",
    "num_classes = 3 \n",
    "num_epochs = 10000\n",
    "learning_rate = 0.01\n",
    "\n",
    "#ロジスティック回帰クラス\n",
    "class LogisticRegression(nn.Module):　# nn.Module:すべてのニューラルネットワークモジュールの基本クラス\n",
    "\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(LogisticRegression, self).__init__()#super関数\n",
    "        self.linear = nn.Linear(input_size, num_classes)#nn.Liner入力に重みとバイアスによる線形変換を行う関数\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "# modelの定義\n",
    "model = LogisticRegression(input_size, num_classes)\n",
    "\n",
    "# loss関数の定義\n",
    "criterion = nn.CrossEntropyLoss()#この中にsoftmaxが含まれている\n",
    "\n",
    "# 最適化手法のパラメータ設定\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# lossを求める \n",
    "def train(X_train, y_train):\n",
    "    inputs = torch.from_numpy(X_train).float()#numpyからTensorを生成。データタイプ指定\n",
    "    targets = torch.from_numpy(y_train).long()\n",
    "        \n",
    "    # 勾配の初期化\n",
    "    optimizer.zero_grad()\n",
    "    # 順伝播\n",
    "    outputs = model(inputs)\n",
    "    # ロスの計算\n",
    "    loss = criterion(outputs, targets)\n",
    "    loss.backward()# 勾配の計算\n",
    "    \n",
    "    # パラメータ(重み・バイアス）の更新\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()#.item()はtapleの値のみを取り出すっぽい\n",
    "\n",
    "#検証\n",
    "def valid(X_test, y_test):\n",
    "    inputs = torch.from_numpy(X_test).float()\n",
    "    targets = torch.from_numpy(y_test).long()\n",
    "\n",
    "    outputs = model(inputs)\n",
    "    val_loss = criterion(outputs, targets)#誤差\n",
    "    \n",
    "    # 精度を求める\n",
    "    _, predicted = torch.max(outputs, 1)#最大値のインデックス\n",
    "    correct = (predicted == targets).sum().item()\n",
    "    val_acc = float(correct) / targets.size(0)#正解数をサンプル数で割って正解率を出す\n",
    "\n",
    "    return val_loss.item(), val_acc\n",
    "\n",
    "loss_list = []\n",
    "val_loss_list = []\n",
    "val_acc_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    perm = np.arange(X_train.shape[0])\n",
    "    np.random.shuffle(perm)#trainデータをepocごとにシャッフルしている。この人独自の手法？\n",
    "    X_train = X_train[perm]\n",
    "    y_train = y_train[perm]\n",
    "    \n",
    "    loss = train(X_train, y_train)\n",
    "    val_loss, val_acc = valid(X_test, y_test)\n",
    "    \n",
    "    if epoch % 1000 == 0:#epoc1000回ごとにプリントする\n",
    "        print('epoch %d, loss: %.4f val_loss: %.4f val_acc: %.4f'\n",
    "              % (epoch, loss, val_loss, val_acc))\n",
    "    \n",
    "    # logging\n",
    "    loss_list.append(loss)\n",
    "    val_loss_list.append(val_loss)\n",
    "    val_acc_list.append(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a43175f60>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot learning curve　学習曲線とアキュラシー\n",
    "plt.figure()\n",
    "plt.plot(range(num_epochs), loss_list, 'r-', label='train_loss')\n",
    "plt.plot(range(num_epochs), val_loss_list, 'b-', label='val_loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(num_epochs), val_acc_list, 'g-', label='val_acc')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題7】（アドバンス課題）フレームワークの比較"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "それぞれのフレームワークにはどのような違いがあるかをまとめてください。\n",
    "\n",
    "TensorFlow:\n",
    "    ・計算速度　＝　BAD：TensorFlowだと、行列演算において最先端のディープラーニングツールの4倍の時間が掛かる\n",
    "                BAD：計算グラフは単なるPythonなため、遅い。\n",
    "    ・コードの行数・可読性　＝　BAD:計算グラフの定義と、実行・学習を行うセッションが別々でややわかりにくい\n",
    "                        BAD：書き方に個人差が出やすい\n",
    "    ・用意されている機能　＝　GOOD：TensorBoardを使用して視覚化することができる。\n",
    "                        GOOD：ニューラルネットに特化したライブラリが豊富\n",
    "Pytorch\n",
    "    ・計算速度　＝　GOOD：３つの中で最速\n",
    "    ・コードの行数・可読性　＝　GOOD:pythonを書くようにかける。直感的で可読性も良い\n",
    "    ・用意されている機能　＝　GOOD：簡単に組み合わせることのできるモジュールのピースが多くある。\n",
    "                        GOOD:前もってトレーニングされたモデルが多くある。\n",
    "                        BAD：日本語の文献がまだ少ない\n",
    "Keras\n",
    "    ・計算速度　＝　BAD：TensorFlowよりわずかに速いくらい、Pytorchにかなり劣る\n",
    "    ・コードの行数・可読性　＝　GOOD：直感的なAPI。行数が少なく初心者でも書きやすく理解しやすい\n",
    "    ・用意されている機能　＝　GOOD：フレームワークが急速な成長を続けている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

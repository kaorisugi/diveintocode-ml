{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sprint15 論文読解入門"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.論文読解\n",
    "以下の論文を読み問題に答えてください。CNNを使った物体検出（Object Detection）の代表的な研究です。\n",
    "\n",
    "[8]Ren, S., He, K., Girshick, R., Sun, J.: Faster r-cnn: Towards real-time object detection with region proposal networks. In: Advances in neural information processing systems. (2015) 91–99\n",
    "\n",
    "https://arxiv.org/pdf/1506.01497.pdf\n",
    "\n",
    "条件\n",
    "\n",
    "答える際は論文のどの部分からそれが分かるかを書く。\n",
    "必要に応じて先行研究（引用されている論文）も探しにいく。最低2つは他の論文を利用して回答すること。\n",
    "論文の紹介記事を見ても良い。ただし、答えは論文内に根拠を探すこと"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) 物体検出の分野にはどういった手法が存在したか。"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "【P１の要約Abstract ２行目】\n",
    "SPPnetやFast R-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Fasterとあるが、どういった仕組みで高速化したのか。"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "【P１の1 INTRODUCTION内】\n",
    "大きく２つの仕組みが高速化に寄与している。\n",
    "１つ目は、物体領域提案(Region Proposals)を既存手法よりも効率的に行うRegion Proposal Network(RPN)である。先行モデルのFast R-CNNでは、物体領域提案を既存手法のSelective Searchで行っており、その計算コストがネットワーク全体のボトルネックとなっていたが、Faster R-CNNでは、物体領域提案をRPNで行うことによって、計算コストがほぼゼロになった。（問４に高速化の詳細を記載）\n",
    "２つ目は、Faster R-CNN内の２つのモジュール間で畳み込み層を共有する仕組みである。２つのモジュールとは物体領域を提案する完全な畳み込みネットワーク（RPN）と、提案された領域を使用して物体検出を行う、既存手法のfaster R-CNNである。これらは、画像を畳み込んで作った特徴マップを、４段階のトレーニングの中で共有するため、畳み込みの計算コストが効率化される。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) One-Stageの手法とTwo-Stageの手法はどう違うのか。"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "【P10】\n",
    "one-stageの検出手法であるOverFeatは、畳み込み特徴マップ上で、１つのアスペクト比のスライドウインドウから、オブジェクトの場所とクラスを同時に決定する。\n",
    "一方Two-Stageの手法であるfaster R-CNNは、第１段階で、複数のスケールとアスペクト比のアンカーに基づき物体領域を予測し、第2段階で物体のクラス分類を行う。このように、物体領域予測のボックスの形が単一かそうでないかという点と、物体領域とクラス分類を１度に決定するか２段階に分けるか、という点が２つの手法の違いである。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) RPNとは何か。"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "【P3　3.1 Region Proposal Networksより】\n",
    "RPN（Region Proposal Network）とは、入力画像から、(1)物体かどうかを表すスコアと(2)物体の領域の２つを同時に検出するネットワークである。画像を畳み込んだfeature maps上にウインドウをスライドさせ、ウインドウ位置ごとに３つのスケールと３つのアスペクト比の計９つの固定枠(Anchor)を用いて特徴を抽出したものを使用し、トレーニングを行って物体候補を提案する。複数のアンカーを使うことで物体の形に忠実な物体領域提案を行い、Fast-RCNNよりも正確な物体予測が可能となった。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) RoIプーリングとは何か。"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "【P6】\n",
    "Fast R-CNNのRoIプーリング層は、畳み込み特徴マップとRPNからの物体領域提案を入力として受け取り、様々なサイズ、アスペクト比の物体領域提案を固定サイズにして出力する。複数の物体領域提案に対して共通の特徴マップを使用することで、計算コストの効率化が行える。\n",
    "\n",
    "【論文引用】\n",
    "[2]R. Girshick、「Fast R-CNN」、IEEE International Conference on Computer Vision（ICCV）、2015年。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (6) Anchorのサイズはどうするのが適切か。"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "【P６冒頭】\n",
    "ZFネットを使用した各アンカーの学習平均提案サイズ（sの数値= 600）。\n",
    "アンカー　　|128^2、2：1 | 128^2、1：1 | 128^2、1：2 | 256^2、2：1 | 256^2、1：1 | 256^2、1：2 | 512^2、2：1 | 512^2、1：1 | 512^2、1：2 |\n",
    "Proposal　|188×111   | 113×114   | 70×92     | 416×229   | 261×284   | 174×332   | 768×437   | 499×501   | 355×715  |\n",
    "\n",
    "アンカーには、128^2、256^2、512^2ピクセルの3つのスケールを持つボックス領域と、1：1、1：2、2：1の3つのアスペクト比を持つボックス領域を使用。つまり、１つの画像につき３×３の９つのボックスを使う。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (7) 何というデータセットを使い、先行研究に比べどういった指標値が得られているか。"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "【P11】\n",
    "データセット：MS COCO dataset\n",
    "先行研究：Fast R-CNN\n",
    "MS COCOデータセットのオブジェクト検出結果（％）。モデルはVGG-16。\n",
    "                                                             COCO val                   COCO test-dev\n",
    "method 　　　　　                  proposals   training data   mAP@.5     mAP@[.5, .95]   mAP@.5    mAP@[.5, .95]\n",
    "Fast R-CNN [2] 　　               SS, 2000    COCO train      -           -              35.9      19.7\n",
    "Fast R-CNN [impl. in this paper] SS, 2000     COCO train     38.6       18.9            39.3       19.3\n",
    "Faster R-CNN                     RPN,300      COCO train     41.5       21.2            42.1       21.5\n",
    "Faster R-CNN                     RPN, 300     COCO trainval   -          -              42.7       21.9\n",
    "\n",
    "Faster R-CNNは、先行研究：Fast R-CNN [impl. in this paper]よりも、mAP@0.5（平均適合率の全クラス平均）が2.8%高かった。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (8) （アドバンス課題）Faster R-CNNよりも新しい物体検出の論文では、Faster R-CNNがどう引用されているか。"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "YOLO（予め画像全体をグリッド分割しておき、各領域ごとに物体のクラスとbounding boxを求める高速モデル）の論文において、「3他の検出システムとの比較」の章でFaster R-CNNが引用されている。\n",
    "YOLOとR-CNNの類似点についての記述に続き、Faster R-CNNはそのモデル内でCNN計算を複数のプロセスで共有し、選択的探索ではない物体領域の提案を行うことでRーCNNの高速化を行っている手法の一例として引用されている。\n",
    "\n",
    "【引用】\n",
    "You Only Look Once: Unified, Real-Time Object Detection\n",
    "Joseph Redmon, Santosh Divvala, Ross Girshick, Ali Farhadi\n",
    "(Submitted on 8 Jun 2015 (v1), last revised 9 May 2016 (this version, v5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
